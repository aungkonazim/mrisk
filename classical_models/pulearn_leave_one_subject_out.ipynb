{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21812, 92), (21812,), (21812,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pulearn import BaggingPuClassifier\n",
    "from pulearn import WeightedElkanotoPuClassifier\n",
    "from pulearn import ElkanotoPuClassifier\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import parfit.parfit as pf\n",
    "from sklearn.base import clone, is_classifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "# from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix,f1_score,precision_score,recall_score,accuracy_score,classification_report\n",
    "import itertools\n",
    "from sklearn.model_selection import ParameterGrid, cross_val_predict, GroupKFold,GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# from imblearn.pipeline import Pipeline\n",
    "import warnings\n",
    "from sklearn.model_selection import check_cv\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, ParameterSampler, ParameterGrid\n",
    "from sklearn.utils.validation import _num_samples, indexable\n",
    "from sklearn import metrics\n",
    "\n",
    "def convert_to_lapsers_only(df):\n",
    "    def helper(df):\n",
    "        if df.Label.sum()==0:\n",
    "            return pd.DataFrame([],columns=list(df.columns))\n",
    "        return df\n",
    "    return df.groupby('user',as_index=False).apply(helper)\n",
    "\n",
    "data  = pickle.load(open('./data/parsed_data/with_non_lapsers_observation_60_prediction_60.p','rb'))\n",
    "data_feature_label = convert_to_lapsers_only(data)\n",
    "\n",
    "X = np.concatenate(list(data_feature_label['feature_final']))\n",
    "\n",
    "y = data_feature_label['Label'].values\n",
    "y = np.int64(np.array(y))\n",
    "y[y>0] = 1\n",
    "y[y<1] = -1\n",
    "\n",
    "groups = data_feature_label['user'].values\n",
    "\n",
    "X1 = np.float64(X[:,2:])\n",
    "\n",
    "from sklearn import preprocessing\n",
    "X_time = X[:,0].reshape(-1,1)\n",
    "X_time = preprocessing.OneHotEncoder().fit_transform(X_time).todense()\n",
    "X_gender = X[:,1].reshape(-1,1)\n",
    "X_gender = preprocessing.OneHotEncoder().fit_transform(X_gender).todense()\n",
    "X = np.concatenate([X_time,X_gender,X1],axis=1)\n",
    "\n",
    "X.shape,y.shape,groups.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##please write participant specific normalization here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 53 folds for each of 6 candidates, totalling 318 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done   4 out of   6 | elapsed:   21.2s remaining:   10.6s\n",
      "[Parallel(n_jobs=40)]: Done   6 out of   6 | elapsed:   23.2s finished\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.751065124771759 0.10861719919021214\n",
      "0.18978775761304215 1.0124186191282007\n"
     ]
    }
   ],
   "source": [
    "def cv_fit_and_score(estimator, X, y, scorer, parameters, cv,parameters_pulearn):\n",
    "    if str(estimator)[0] != 'B':\n",
    "        temp = estimator.estimator\n",
    "        estimator.set_params(**parameters_pulearn)\n",
    "        estimator.set_params(**{'estimator__'+key:parameters[key] for key in parameters.keys()})\n",
    "        parameters_pulearn.update({'estimator__'+key:parameters[key] for key in parameters.keys()})\n",
    "        final_params = parameters_pulearn\n",
    "    else:\n",
    "        temp = estimator.base_estimator\n",
    "        parameters_pulearn = {'n_estimators':parameters_pulearn['n_estimators']}\n",
    "        estimator.set_params(**parameters_pulearn)\n",
    "        estimator.set_params(**{'base_estimator__'+key:parameters[key] for key in parameters.keys()})\n",
    "        parameters_pulearn.update({'base_estimator__'+key:parameters[key] for key in parameters.keys()})\n",
    "        final_params = parameters_pulearn\n",
    "    \n",
    "    cv_probs_ = cross_val_probs(estimator, X, y, cv)\n",
    "    score = scorer(cv_probs_, y)\n",
    "    return [score, final_params]\n",
    "   \n",
    "def cross_val_probs(estimator, X, y, cv):\n",
    "    probs = np.zeros(len(y))\n",
    "    for train, test in cv:\n",
    "#         print(np.unique(y[train]))\n",
    "        temp = estimator.fit(X[train], y[train]).predict_proba(X[test]).reshape(len(test),-1)\n",
    "        if temp.shape[1]==1:\n",
    "            temp = temp[:,0]\n",
    "        else:\n",
    "            temp = temp[:,1]        \n",
    "        probs[test] = temp\n",
    "    return probs\n",
    "\n",
    "def f1Bias_scorer_CV(probs, y, ret_bias=False):\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(y, probs)\n",
    "\n",
    "    f1,bias = 0.0,.5\n",
    "    for i in range(0, len(thresholds)):\n",
    "        if not (precision[i] == 0 and recall[i] == 0) and recall[i]>min_recall:\n",
    "            f = 2 * (precision[i] * recall[i]) / (precision[i] + recall[i])\n",
    "            if f > f1:\n",
    "                f1 = f\n",
    "                bias = thresholds[i]\n",
    "\n",
    "    if ret_bias:\n",
    "        return f1, bias\n",
    "    else:\n",
    "        return f1\n",
    "\n",
    "class ModifiedGridSearchCV(GridSearchCV):\n",
    "    def __init__(self, estimator, param_grid, scoring=None, fit_params=None,\n",
    "                 n_jobs=1, iid=True, refit=True, cv=None, verbose=0,\n",
    "                 pre_dispatch='2*n_jobs', error_score='raise',param_grid_pulearn = None):\n",
    "\n",
    "        super(ModifiedGridSearchCV, self).__init__(\n",
    "                estimator=estimator, param_grid=param_grid, scoring=scoring,  n_jobs=n_jobs, \n",
    "                refit=refit, cv=cv, verbose=verbose, pre_dispatch=pre_dispatch, error_score=error_score)\n",
    "        self.parameter_iterable_pulearn = ParameterGrid(param_grid_pulearn)\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Actual fitting,  performing the search over parameters.\"\"\"\n",
    "\n",
    "        parameter_iterable = ParameterGrid(self.param_grid)\n",
    "        parameter_iterable_pulearn = self.parameter_iterable_pulearn\n",
    "\n",
    "        estimator = self.estimator\n",
    "        cv = self.cv\n",
    "\n",
    "        n_samples = _num_samples(X)\n",
    "        X, y = indexable(X, y)\n",
    "\n",
    "        if y is not None:\n",
    "            if len(y) != n_samples:\n",
    "                raise ValueError('Target variable (y) has a different number '\n",
    "                                 'of samples (%i) than data (X: %i samples)'\n",
    "                                 % (len(y), n_samples))\n",
    "        if self.verbose > 0:\n",
    "            n_candidates = len(parameter_iterable)*len(parameter_iterable_pulearn)\n",
    "            print(\"Fitting {0} folds for each of {1} candidates, totalling\"\n",
    "                  \" {2} fits\".format(len(cv), n_candidates,\n",
    "                                     n_candidates * len(cv)))\n",
    "\n",
    "        base_estimator = clone(self.estimator)\n",
    "\n",
    "        pre_dispatch = self.pre_dispatch\n",
    "\n",
    "        out = Parallel(\n",
    "                n_jobs=self.n_jobs, verbose=self.verbose,\n",
    "                pre_dispatch=pre_dispatch\n",
    "        )(\n",
    "                delayed(cv_fit_and_score)(clone(base_estimator), X, y, self.scoring,\n",
    "                                          parameters, cv=cv, parameters_pulearn=params_pulearn)\n",
    "                for parameters in parameter_iterable for params_pulearn in parameter_iterable_pulearn)\n",
    "#         out = [cv_fit_and_score(clone(base_estimator), X, y, self.scoring,\n",
    "#                                           parameters, cv=cv, parameters_pulearn=params_pulearn)\n",
    "#                 for parameters in parameter_iterable for params_pulearn in parameter_iterable_pulearn]\n",
    "        best = sorted(out,key=lambda x: x[0], reverse=True)[0]\n",
    "        self.best_params_ = best[1]\n",
    "        self.best_score_ = best[0]\n",
    "#         print(best[1])\n",
    "        if self.refit:\n",
    "            best_estimator = clone(base_estimator).set_params(\n",
    "                    **best[1])\n",
    "            self.best_estimator_ = best_estimator\n",
    "\n",
    "        return None\n",
    "X1 = X.copy()\n",
    "y = y.copy()\n",
    "y[y==-1] = 0\n",
    "groups = groups.copy()\n",
    "gkf = GroupKFold(n_splits=len(np.unique(groups)))\n",
    "delta = 0.2\n",
    "\n",
    "# parameters = {'rf__kernel': ['rbf'],\n",
    "#               'rf__C': [10],\n",
    "#               'rf__gamma': np.logspace(-3,3,10),\n",
    "#               'rf__class_weight': [{0: w, 1: 1 - w} for w in np.arange(0.0, .50, delta)],\n",
    "#               'rf__probability':[True],\n",
    "#               'rf__verbose':[False],\n",
    "#               'rf__cache_size':[2000]}\n",
    "# parameters = {\n",
    "#     'rf__min_samples_leaf': [4],\n",
    "#     'rf__max_features': [3,5,10],\n",
    "#     'rf__n_estimators': [30,100,200],\n",
    "#     'rf__n_jobs': [-1],\n",
    "#     'rf__criterion':['gini','entropy'],\n",
    "#     'rf__class_weight': [{0: w, 1: 1 - w} for w in np.arange(0.01, .6, delta)],\n",
    "#     'rf__random_state': [42]\n",
    "#        }\n",
    "parameters = {\n",
    "    'pca__n_components':[2,3],\n",
    "    'rf__C':np.logspace(-3,3,1),\n",
    "    'rf__n_jobs': [-1],\n",
    "    'rf__class_weight': [{0: w, 1: 1 - w} for w in np.arange(0.01, .6, delta)],\n",
    "}\n",
    "\n",
    "## Pay close attention to the fields you populate here, only include 'labeled' and 'unlabeled' when using weighted PU learn\n",
    "## when using bagging classifier it just only have one field 'n_estimators'\n",
    "parameters_pulearn_weighted = {'hold_out_ratio':[.1],'labeled':[10],'unlabeled':[20]}\n",
    "parameters_pulearn_simple = {'hold_out_ratio':[.1]}\n",
    "parameters_pulearn_bagging = {'n_estimators':[2]}\n",
    "# svc = Pipeline([('pca',PCA(n_components=10)),('rf',RandomForestClassifier())])\n",
    "svc = Pipeline([('pca',PCA(n_components=10)),('rf',LogisticRegression())])\n",
    "# svc = Pipeline([('sts',preprocessing.StandardScaler()),('pca',PCA(n_components=10)),('rf',SVC())])\n",
    "# svc = RandomForestClassifier()\n",
    "# grid_search = GridSearchCV(svc,parameters, cv=gkf.split(X1,y,groups=groups),\n",
    "#              n_jobs=-1, scoring='f1', verbose=1, iid=False)\n",
    "# clf = Pipeline([('sts',StandardScaler()),('clf',svc)])\n",
    "min_recall = .6\n",
    "pu_estimator = WeightedElkanotoPuClassifier(estimator=svc,labeled=10,unlabeled=20)\n",
    "pu_estimator = BaggingPuClassifier(base_estimator=svc)\n",
    "pu_estimator = ElkanotoPuClassifier(estimator=svc)\n",
    "grid_search = ModifiedGridSearchCV(pu_estimator, parameters, cv=list(gkf.split(X1,y,groups=groups)),\n",
    "                                   n_jobs=40, scoring=f1Bias_scorer_CV, verbose=1, iid=False,\n",
    "                                   param_grid_pulearn=parameters_pulearn_simple)\n",
    "grid_search.fit(X1,y)\n",
    "clf = grid_search.best_estimator_\n",
    "m = len(np.where(y==-1)[0])\n",
    "n = len(np.where(y>0)[0])\n",
    "CV_probs = cross_val_probs(clf, X1, y, gkf.split(X1,y,groups=groups))\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(CV_probs,50)\n",
    "plt.show()\n",
    "score, bias = f1Bias_scorer_CV(CV_probs, y, True)\n",
    "predicted = np.asarray(CV_probs >= bias, dtype=np.int)\n",
    "print(recall_score(y,predicted), precision_score(y,predicted))\n",
    "print(score,bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElkanotoPuClassifier(estimator=Pipeline(steps=[('pca', PCA(n_components=2)),\n",
       "                                               ('rf',\n",
       "                                                LogisticRegression(C=0.001,\n",
       "                                                                   class_weight={0: 0.41000000000000003,\n",
       "                                                                                 1: 0.59},\n",
       "                                                                   n_jobs=-1))]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CC3.3",
   "language": "python",
   "name": "cc33"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
