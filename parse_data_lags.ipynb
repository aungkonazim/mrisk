{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "from datetime import datetime,timedelta\n",
    "from scipy.stats import iqr,skew,kurtosis\n",
    "from joblib import Parallel,delayed\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "from datetime import datetime,timedelta\n",
    "from scipy.stats import iqr,skew,kurtosis\n",
    "from joblib import Parallel,delayed\n",
    "from sklearn.feature_selection import SelectKBest,f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import f1_score,r2_score,classification_report\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,RandomForestRegressor\n",
    "from sklearn.svm import SVC\n",
    "# print(m/(m+n),'baseline accuracy')\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix,f1_score,precision_score,recall_score,accuracy_score\n",
    "import itertools\n",
    "from sklearn.model_selection import ParameterGrid, cross_val_predict, GroupKFold,GridSearchCV,StratifiedKFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_directory = './data/parsed_data/'\n",
    "save_directory = './data/lagged_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_sequence(df,K=5,standarization=False):\n",
    "    df  = df.sort_values('time').reset_index(drop=True)\n",
    "    df['feature_final'] = df['feature_final'].apply(lambda a:np.float64(a.reshape(-1)[2:].reshape(1,-1)))\n",
    "    if standarization:\n",
    "        X = np.concatenate(list(df['feature_final']))\n",
    "        X = preprocessing.StandardScaler().fit_transform(X)\n",
    "        df['feature_final'] = list([np.array(a).reshape(1,-1) for a in X])\n",
    "    time_of_day = df['Time of Day'].values[0]\n",
    "    age = df['Gender'].values[0]\n",
    "    user_id = df.user.values[0]\n",
    "    all_data = []\n",
    "    if df.shape[0]<=K:\n",
    "        return pd.DataFrame([],columns=['features','user','label','day','time','Time of Day','Gender','start_time','end_time'])\n",
    "    for i in range(K-1,df.shape[0],1):\n",
    "        row = df.iloc[i]\n",
    "        features = np.concatenate(list(df['feature_final'].iloc[i-K+1:i+1])).reshape(1,K,-1)\n",
    "        label = df['Label'].iloc[i]\n",
    "        day = df['day'].iloc[i]\n",
    "        time = df['time'].iloc[i]\n",
    "        start_time = df['start_time'].iloc[i-K+1]\n",
    "        end_time = df['end_time'].iloc[i]\n",
    "        all_data.append([features,user_id,label,day,time,time_of_day,age,start_time,end_time])\n",
    "    return pd.DataFrame(all_data,columns=['features','user','label','day','time','Time of Day','Gender','start_time','end_time'])\n",
    "# Ks = [30,60,75,90,120,150,180]\n",
    "Ks = [5,10,15,20,25,30]\n",
    "standarization = True\n",
    "for f in os.listdir(file_directory):\n",
    "    print(f)\n",
    "    if f=='mRisk' or f[:3]=='lag' or f[0]=='.' or f[-6:]!='_new.p':\n",
    "        continue\n",
    "    obs = f.split('_')[4]\n",
    "    prediction = f.split('_')[-2].split('.')[0]\n",
    "    if int(prediction) not in [60]:\n",
    "        continue\n",
    "    if int(obs) not in [30]:\n",
    "        continue\n",
    "#     if os.path.isdir(save_directory+'obs_'+str(obs)+'_prediction_'+str(prediction)):\n",
    "#         continue\n",
    "    if not os.path.isdir(save_directory+'obs_'+str(obs)+'_prediction_'+str(prediction)):\n",
    "        os.makedirs(save_directory+'obs_'+str(obs)+'_prediction_'+str(prediction))\n",
    "    print(f,int(obs),int(prediction))\n",
    "    data = pickle.load(open(file_directory+f,'rb'))\n",
    "    for K1 in Ks:\n",
    "#         K = (K1-int(obs))//2 + 1\n",
    "#         if K<=1:\n",
    "#             continue\n",
    "        K = K1\n",
    "        df_seq = pd.concat(Parallel(n_jobs=-1,verbose=2)(delayed(get_feature_sequence)(df,K=K,standarization=standarization) for i,df in data.groupby('user',as_index=False)))\n",
    "        saving_directory = save_directory+'obs_'+str(obs)+'_prediction_'+str(prediction)+'/'\n",
    "        if not standarization:\n",
    "            pickle.dump(df_seq,open(saving_directory+'lagged_'+str(K1)+'_windows_new.p','wb'))\n",
    "        else:\n",
    "            pickle.dump(df_seq,open(saving_directory+'lagged_'+str(K1)+'_windows_standardized_new.p','wb'))\n",
    "        print(df_seq.shape,K1)\n",
    "    print('done')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['Time of Day','Gender', 'Age', 'current_window_stress_p90', 'current_window_stress_p95', 'current_window_stress_p80',\n",
    " 'current_window_stress_p5', 'current_window_stress_p10', 'current_window_stress_p20', 'current_window_stress_range_90_to_80',\n",
    " 'current_window_stress_range_20_to_10', 'current_window_stress_range_90_to_10', 'current_window_stress_range_80_to_20', 'current_window_stress_median',\n",
    " 'current_window_stress_iqr', 'current_window_stress_skew', 'current_window_stress_diff_p90', 'current_window_stress_diff_p95',\n",
    " 'current_window_stress_diff_p80', 'current_window_stress_diff_p5', 'current_window_stress_diff_p10', 'current_window_stress_diff_p20',\n",
    " 'current_window_stress_diff_range_90_to_80', 'current_window_stress_diff_range_20_to_10', 'current_window_stress_diff_range_90_to_10', 'current_window_stress_diff_range_80_to_20',\n",
    " 'current_window_stress_diff_median', 'current_window_stress_diff_iqr', 'current_window_stress_diff_skew', 'time_since_last_visit_smoking_spot',\n",
    " 'duration_of_stay_in_smoking_spot', 'fraction_of_minutes_spent_in_smoking_spots_out_of_observed', 'daily_stress_p90', 'daily_stress_p95',\n",
    " 'daily_stress_p80', 'daily_stress_p5', 'daily_stress_p10', 'daily_stress_p20', 'daily_stress_range_90_to_80', 'daily_stress_range_20_to_10',\n",
    " 'daily_stress_range_90_to_10', 'daily_stress_range_80_to_20', 'daily_stress_median', 'daily_stress_iqr', 'daily_stress_skew', 'percentage_of_stress', 'maximum_duration_of_current_stress_episode',\n",
    " 'average_duration_of_current_stress_episode', 'maximum_density_of_current_stress_episode', 'average_density_of_current_stress_episode', 'average_deviation_to_daily_mean_current',\n",
    " 'no_stress_till_now', 'time_since_last_stress', 'duration_of_last_stress_episode', 'average_duration_of_before_stress_episode', 'density_of_last_stress_episode',\n",
    " 'average_density_of_before_stress_episode', 'deviation_to_daily_mean_of_last_stress_episode', 'percentage_of_stress_before', 'percentage_of_active_',\n",
    " 'maximum_duration_of_current_activity_episode', 'average_duration_of_current_window_episode', 'no_activity_till_now', 'time_since_last_activity',\n",
    " 'duration_of_last_activity_episode', 'average_duration_of_before_activity_episode', 'percentage_of_active_before', 'is_smoking', 'spread', 'distance_to_nearest_spot', 'time_spent_in_transition',\n",
    " 'time_spent_in_smoking_spot']\n",
    "\n",
    "from sklearn import preprocessing\n",
    "use_standardization = True\n",
    "use_current_stress = True\n",
    "n_lag = 10\n",
    "if use_standardization:\n",
    "    data  = pickle.load(open('./data/lagged_data/obs_30_prediction_60/lagged_'+str(n_lag)+'_windows.p','rb'))\n",
    "else:\n",
    "    data  = pickle.load(open('./data/lagged_data/obs_30_prediction_60/lagged_'+str(n_lag)+'_windows'+'_standardized_new'+'.p','rb'))\n",
    "n_t = data.iloc[0]['features'].shape[1]\n",
    "n_f = data.iloc[0]['features'].shape[2]\n",
    "y_time = data['time'].values\n",
    "X = np.concatenate(list(data['features']))\n",
    "n = X.shape[0]\n",
    "X1 = X\n",
    "y = data['label'].values\n",
    "y = np.int64(np.array(y))\n",
    "y[y>0] = 1\n",
    "y[y<1] = -1\n",
    "groups = data['user'].values\n",
    "X_time = data['Time of Day'].values.reshape(-1,1)\n",
    "X_gender = data.Gender.values.reshape(-1,1)\n",
    "time_oh = preprocessing.OneHotEncoder().fit(X_time)\n",
    "gender_oh = preprocessing.OneHotEncoder().fit(X_gender)\n",
    "X_time = time_oh.transform(X_time).todense()\n",
    "X_gender = gender_oh.transform(X_gender).todense()\n",
    "if use_standardization:\n",
    "    X1_all,y_all,groups_all,y_time_all,X_gender_all,X_time_all = [],[],[],[],[],[]\n",
    "    for g in np.unique(groups):\n",
    "        X1_all.append(X1[groups==g])\n",
    "        y_all.extend(list(y[groups==g]))\n",
    "        groups_all.extend(list(groups[groups==g]))\n",
    "        y_time_all.extend(list(y_time[groups==g]))\n",
    "        X_gender_all.append(preprocessing.StandardScaler().fit_transform(X_gender[groups==g]))\n",
    "        X_time_all.append(preprocessing.StandardScaler().fit_transform(X_time[groups==g]))\n",
    "    X1,y,groups,y_time,X_gender,X_time =  np.concatenate(X1_all),np.array(y_all),np.array(groups_all), \\\n",
    "    np.array(y_time_all),np.concatenate(X_gender_all),np.concatenate(X_time_all)\n",
    "\n",
    "X_time = np.concatenate([np.expand_dims(X_time,axis=1)]*n_t,axis=1)\n",
    "X_gender = np.concatenate([np.expand_dims(X_gender,axis=1)]*n_t,axis=1)\n",
    "feature_names_temp = feature_names[2:]\n",
    "if not use_current_stress:\n",
    "    index_of_features_kept = np.array([max(k-2,0) for k,name in enumerate(feature_names_temp) if name.find('current_window_stress')==-1])\n",
    "    X1 = X[:,:,index_of_features_kept]\n",
    "# X = np.concatenate([X_time,X_gender,X1.reshape(X1.shape[0],-1)],axis=1)\n",
    "# X.shape,y.shape,groups.shape,y_time.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_feature_columns = [feature_names[0]+'=='+a for a in time_oh.categories_[0]]\n",
    "gender_feature_columns = [feature_names[1]+'=='+a for a in gender_oh.categories_[0]]\n",
    "\n",
    "feature_names = time_feature_columns+gender_feature_columns+feature_names_temp\n",
    "\n",
    "X = np.concatenate([X1,X_time,X_gender],axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((68931, 10, 86), (68931,), (68931,), 86, Counter({-1: 67192, 1: 1739}))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape,groups.shape,len(feature_names),Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CC3.3",
   "language": "python",
   "name": "cc33"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
