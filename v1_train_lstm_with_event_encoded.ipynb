{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azim/miniconda3/envs/test1/lib/python3.8/site-packages/tensorflow_addons/utils/ensure_tf_install.py:38: UserWarning: You are currently using a nightly version of TensorFlow (2.5.0-dev20210310). \n",
      "TensorFlow Addons offers no support for the nightly versions of TensorFlow. Some things might work, some other might not. \n",
      "If you encounter a bug, do not file an issue on GitHub.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime,timedelta\n",
    "from scipy.stats import iqr,skew,kurtosis,mode\n",
    "from joblib import Parallel,delayed\n",
    "import zipfile\n",
    "import shutil\n",
    "from sklearn.feature_selection import SelectKBest,f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import f1_score,r2_score,classification_report\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,RandomForestRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix,f1_score,precision_score,recall_score,accuracy_score\n",
    "import itertools\n",
    "from sklearn.model_selection import ParameterGrid, cross_val_predict, GroupKFold,GridSearchCV,StratifiedKFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "seed = 100\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from sklearn.model_selection import train_test_split,LeavePGroupsOut\n",
    "from keras.backend import expand_dims, repeat_elements\n",
    "from keras.layers import Lambda\n",
    "from tensorflow.keras.layers import Conv1D,BatchNormalization,Dropout,InputLayer,MaxPooling1D,Flatten,RepeatVector,Dense,Input,Activation,GRU,Bidirectional,LSTM\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow_addons as tfa\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[1], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_file = './data/episode_encoded_lagged_data/episode_encoded_'+'lagged_{}_windows_standardized_phenotype_no_episode_cluster_check'\n",
    "def get_X_y_groups(n_lag=10):\n",
    "    data = pickle.load(open(filepath_file.format(n_lag),'rb'))\n",
    "\n",
    "    X_feature = np.concatenate(data.feature_final.values)\n",
    "    X_static =  np.concatenate(data.static_features.values)\n",
    "\n",
    "    X_stress_episode = np.concatenate(data.stress_episode.values)\n",
    "    X_quit_episode = np.concatenate(data.quit_episode.values)\n",
    "    X_activity_episode = np.concatenate(data.activity_episode.values)\n",
    "    X_smoking_episode = np.concatenate(data.smoking_episode.values)\n",
    "\n",
    "    y_time = data['time'].values\n",
    "    y = data['label'].values\n",
    "    groups = data['user'].values\n",
    "    \n",
    "    return X_feature,X_static,X_stress_episode,X_quit_episode,X_activity_episode,X_smoking_episode,y_time,y,groups\n",
    "\n",
    "\n",
    "def get_train_test_indexes(groups,n_groups_split = 10,n_val_groups = 10):\n",
    "    groups_unique = np.unique(groups)\n",
    "    groups_split = np.array_split(groups_unique,n_groups_split)\n",
    "    indexes = []\n",
    "    for this_groups in groups_split:\n",
    "        train_groups = np.array([a for a in groups_unique if a not in this_groups])\n",
    "        val_groups = np.random.choice(train_groups,n_val_groups)\n",
    "        train_groups = np.array([a for a in groups_unique if a not in list(this_groups)+list(val_groups)])\n",
    "        test_groups = this_groups\n",
    "        train_index,test_index = np.array([i for i,a in enumerate(groups) \n",
    "                                           if a in train_groups]),np.array([i for i,a in enumerate(groups) \n",
    "                                                                               if a in test_groups])\n",
    "        val_index = np.array([i for i,a in enumerate(groups) \n",
    "                                           if a in val_groups])\n",
    "        indexes.append([train_index,test_index,val_index])\n",
    "    return indexes\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "def f1Bias_scorer_CV(probs, y, ret_bias=True):\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(y, probs)\n",
    "\n",
    "    f1,bias = 0.0,.5\n",
    "    min_recall = .7\n",
    "    for i in range(0, len(thresholds)):\n",
    "        if not (precision[i] == 0 and recall[i] == 0) and recall[i]>min_recall:\n",
    "            f = 2 * (precision[i] * recall[i]) / (precision[i] + recall[i])\n",
    "            if f > f1:\n",
    "                f1 = f\n",
    "                bias = thresholds[i]\n",
    "\n",
    "    if ret_bias:\n",
    "        return f1, bias\n",
    "    else:\n",
    "        return f1\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    n_t,n_f = train_feature.shape[1],train_feature.shape[2]\n",
    "    print(n_t,n_f)\n",
    "    x_input = Input(shape=(n_t,n_f))\n",
    "    # x_feature = Conv1D(100,1,activation='linear')(x_input)\n",
    "    x_feature = Conv1D(100,1,activation='tanh')(x_input)\n",
    "    x_feature = Dropout(.2)(x_feature)\n",
    "    x_feature = LSTM(20,activation='tanh',return_sequences=False)(x_feature)\n",
    "    x_feature = Dropout(.3)(x_feature)\n",
    "    x_feature = Flatten()(x_feature)\n",
    "    x_feature = Dense(10,activation='relu')(x_feature)\n",
    "    # x_final = Dense(1,activation='sigmoid')(x_feature)\n",
    "\n",
    "    n_sf = train_static.shape[1]\n",
    "    x_input_static = Input(shape=(n_sf))\n",
    "    x_static = Dense(10,activation='relu')(x_input_static)\n",
    "    x_static = Dense(10,activation='relu')(x_static)\n",
    "    n_timesteps = train_stress.shape[-2]\n",
    "    n_episodes_stress,n_episodes_quit,n_episodes_activity,n_episodes_smoking = train_stress.shape[1],train_quit.shape[1],train_activity.shape[1],train_smoking.shape[1]\n",
    "    x_alpha_stress = Dense(1,activation='sigmoid',name='alpha_stress')(x_static)\n",
    "    x_alpha_stress = RepeatVector(n_timesteps)(x_alpha_stress)\n",
    "    x_alpha_stress = Lambda(lambda x: repeat_elements(expand_dims(x, axis=1), n_episodes_stress, 1))(x_alpha_stress)\n",
    "    x_alpha_quit = Dense(1,activation='sigmoid',name='alpha_quit')(x_static)\n",
    "    x_alpha_quit = RepeatVector(n_timesteps)(x_alpha_quit)\n",
    "    x_alpha_quit = Lambda(lambda x: repeat_elements(expand_dims(x, axis=1), n_episodes_quit, 1))(x_alpha_quit)\n",
    "    x_alpha_activity = Dense(1,activation='sigmoid',name='alpha_activity')(x_static)\n",
    "    x_alpha_activity = RepeatVector(n_timesteps)(x_alpha_activity)\n",
    "    x_alpha_activity = Lambda(lambda x: repeat_elements(expand_dims(x, axis=1), n_episodes_activity, 1))(x_alpha_activity)\n",
    "    x_alpha_smoking = Dense(1,activation='sigmoid',name='alpha_smoking')(x_static)\n",
    "    x_alpha_smoking = RepeatVector(n_timesteps)(x_alpha_smoking)\n",
    "    x_alpha_smoking = Lambda(lambda x: repeat_elements(expand_dims(x, axis=1), n_episodes_smoking, 1))(x_alpha_smoking)\n",
    "\n",
    "    n_dim = 3\n",
    "    x_stress = Input(shape=(n_episodes_stress,n_timesteps,n_dim))\n",
    "    stress_alpha_time = tf.math.multiply(x_alpha_stress[:,:,:,0]*-1,x_stress[:,:,:,0])\n",
    "    stress_alpha_time_exp = tf.math.exp(stress_alpha_time)\n",
    "\n",
    "    x_stress_amplitude = x_stress[:,:,:,1]\n",
    "    stress_amplitude_coeff = Dense(1,activation='relu',name='amplitude_stress')(x_static)\n",
    "    stress_amplitude_coeff = Lambda(lambda x: expand_dims(x, axis=2))(stress_amplitude_coeff)\n",
    "    print(stress_amplitude_coeff.shape,'coeff',x_stress_amplitude.shape,'amplitude')\n",
    "    x_stress_amplitude = tf.math.multiply(x_stress_amplitude,stress_amplitude_coeff)\n",
    "#     print(x_stress_amplitude.shape,'final')\n",
    "    \n",
    "    x_stress_duration = x_stress[:,:,:,2]\n",
    "    stress_duration_coeff = Dense(1,activation='sigmoid',name='duration_stress')(x_static)\n",
    "    stress_duration_coeff = Lambda(lambda x: expand_dims(x, axis=2))(stress_duration_coeff)\n",
    "    x_stress_duration = tf.math.multiply(x_stress_duration,stress_duration_coeff)\n",
    "    \n",
    "    x_stress_all = tf.math.add(x_stress_amplitude,x_stress_duration)\n",
    "    \n",
    "#     print(x_stress_all.shape,stress_alpha_time_exp.shape)\n",
    "    stress_alpha_time_exp_amplitude = tf.math.multiply(stress_alpha_time_exp,x_stress_all)\n",
    "    \n",
    "#     print(stress_alpha_time_exp_amplitude.shape)\n",
    "    stress_final = tf.math.reduce_sum(stress_alpha_time_exp_amplitude,axis=1)\n",
    "#     print(stress_final.shape)\n",
    "    stress_final = Lambda(lambda x: expand_dims(x, axis=2))(stress_final)\n",
    "#     print(stress_final.shape)\n",
    "    # stress_final = LSTM(10,activation='tanh',return_sequences=True)(stress_final)\n",
    "    \n",
    "    \n",
    "    \n",
    "    x_quit = Input(shape=(n_episodes_quit,n_timesteps,n_dim))\n",
    "#     quit_alpha_time = tf.math.multiply(x_alpha_quit[:,:,:,0]*-1,x_quit[:,:,:,0])\n",
    "#     quit_alpha_time_exp = tf.math.exp(quit_alpha_time)\n",
    "#     quit_alpha_time_exp_amplitude = tf.math.multiply(quit_alpha_time_exp,x_quit[:,:,:,1])\n",
    "#     quit_final = tf.math.reduce_sum(quit_alpha_time_exp_amplitude,axis=1)\n",
    "#     quit_final = Lambda(lambda x: expand_dims(x, axis=2))(quit_final)\n",
    "#     quit_final = LSTM(5,activation='tanh',return_sequences=True)(quit_final)\n",
    "\n",
    "    \n",
    "    \n",
    "    x_smoking = Input(shape=(n_episodes_smoking,n_timesteps,n_dim))\n",
    "    smoking_alpha_time = tf.math.multiply(x_alpha_smoking[:,:,:,0]*-1,x_smoking[:,:,:,0])\n",
    "    smoking_alpha_time_exp = tf.math.exp(smoking_alpha_time)\n",
    "    \n",
    "    x_smoking_amplitude = x_smoking[:,:,:,1]\n",
    "    smoking_amplitude_coeff = Dense(1,activation='sigmoid',name='amplitude_smoking')(x_static)\n",
    "    smoking_amplitude_coeff = Lambda(lambda x: expand_dims(x, axis=2))(smoking_amplitude_coeff)\n",
    "    x_smoking_amplitude = tf.math.multiply(x_smoking_amplitude,smoking_amplitude_coeff)\n",
    "    \n",
    "    x_smoking_duration = x_smoking[:,:,:,2]\n",
    "    smoking_duration_coeff = Dense(1,activation='sigmoid',name='duration_smoking')(x_static)\n",
    "    smoking_duration_coeff = Lambda(lambda x: expand_dims(x, axis=2))(smoking_duration_coeff)\n",
    "    x_smoking_duration = tf.math.multiply(x_smoking_duration,smoking_duration_coeff)\n",
    "    \n",
    "    x_smoking_all = tf.math.add(x_smoking_amplitude,x_smoking_duration)\n",
    "    smoking_alpha_time_exp_amplitude = tf.math.multiply(smoking_alpha_time_exp,x_smoking_all)\n",
    "    smoking_final = tf.math.reduce_sum(smoking_alpha_time_exp_amplitude,axis=1)\n",
    "    smoking_final = Lambda(lambda x: expand_dims(x, axis=2))(smoking_final)\n",
    "    # smoking_final = LSTM(10,activation='tanh',return_sequences=True)(smoking_final)\n",
    "\n",
    "    \n",
    "    \n",
    "    x_activity = Input(shape=(n_episodes_activity,n_timesteps,n_dim))\n",
    "    activity_alpha_time = tf.math.multiply(x_alpha_activity[:,:,:,0]*-1,x_activity[:,:,:,0])\n",
    "    activity_alpha_time_exp = tf.math.exp(activity_alpha_time)\n",
    "    \n",
    "    x_activity_amplitude = x_activity[:,:,:,1]\n",
    "    activity_amplitude_coeff = Dense(1,activation='sigmoid',name='amplitude_activity')(x_static)\n",
    "    activity_amplitude_coeff = Lambda(lambda x: expand_dims(x, axis=2))(activity_amplitude_coeff)\n",
    "    x_activity_amplitude = tf.math.multiply(x_activity_amplitude,activity_amplitude_coeff)\n",
    "    \n",
    "    x_activity_duration = x_activity[:,:,:,2]\n",
    "    activity_duration_coeff = Dense(1,activation='sigmoid',name='duration_activity')(x_static)\n",
    "    activity_duration_coeff = Lambda(lambda x: expand_dims(x, axis=2))(activity_duration_coeff)\n",
    "#     print(activity_duration_coeff)\n",
    "    x_activity_duration = tf.math.multiply(x_activity_duration,activity_duration_coeff)\n",
    "    \n",
    "    x_activity_all = tf.math.add(x_activity_amplitude,x_activity_duration)\n",
    "    activity_alpha_time_exp_amplitude = tf.math.multiply(activity_alpha_time_exp,x_activity_all)\n",
    "    activity_final = tf.math.reduce_sum(activity_alpha_time_exp_amplitude,axis=1)\n",
    "    activity_final = Lambda(lambda x: expand_dims(x, axis=2))(activity_final)\n",
    "    # activity_final = LSTM(10,activation='tanh',return_sequences=True)(activity_final)\n",
    "    \n",
    "    \n",
    "    x_episode = tf.concat([activity_final, stress_final, smoking_final],2)\n",
    "    # x_episode = Conv1D(100,10,activation='relu')(x_episode)\n",
    "    # x_episode = Conv1D(100,10,activation='tanh')(x_episode)\n",
    "    # x_episode = LSTM(100,activation='tanh',return_sequences=True)(x_episode)\n",
    "    x_episode = LSTM(20,activation='tanh',return_sequences=False)(x_episode)\n",
    "    x_episode = Dropout(.3)(x_episode)\n",
    "    x_episode = Flatten()(x_episode)\n",
    "    x_episode = Dense(10,activation='relu')(x_episode)\n",
    "\n",
    "    # merged = tf.concat([x_feature,x_episode],1)\n",
    "    merged = x_feature\n",
    "    merged = Dense(10,activation='relu')(merged)\n",
    "    # merged = Dense(10,activation='relu')(merged)\n",
    "    merged = Lambda(lambda x: K.l2_normalize(x,axis=1),name='normalize')(merged)\n",
    "    output = Dense(2,activation='relu')(merged)\n",
    "    output = Dense(2,activation='softmax',name='softmax')(output)\n",
    "    # output = Dense(2,activation='softmax')(merged)\n",
    "    # output = Reshape((-1,1))(output)\n",
    "#     output = Activation('softmax',name='softmax')(output)\n",
    "    model = Model(inputs=[x_input,x_input_static,x_stress,x_activity,x_smoking,x_quit], outputs=[output,merged])\n",
    "    model.compile(\n",
    "        loss={'softmax':tf.losses.SparseCategoricalCrossentropy(),'normalize':tfa.losses.TripletSemiHardLoss()},\n",
    "        metrics={'softmax':['acc']},\n",
    "        optimizer='adam'\n",
    "    )\n",
    "    return model\n",
    "# tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "# from keras.layers import Reshape\n",
    "def myloss(alpha=.2):\n",
    "    \n",
    "    def custom_loss(true,pred):\n",
    "        m = tf.keras.losses.BinaryCrossentropy()\n",
    "        return f1_weighted(true,pred)+m(true,pred)*alpha\n",
    "    \n",
    "    \n",
    "    def f1_weighted(true, pred): #shapes (batch, 4)\n",
    "\n",
    "        #for metrics include these two lines, for loss, don't include them\n",
    "        #these are meant to round 'pred' to exactly zeros and ones\n",
    "        #predLabels = K.argmax(pred, axis=-1)\n",
    "        #pred = K.one_hot(predLabels, 4) \n",
    "\n",
    "\n",
    "        ground_positives = K.sum(true, axis=0) + K.epsilon()       # = TP + FN\n",
    "        pred_positives = K.sum(pred, axis=0) + K.epsilon()         # = TP + FP\n",
    "        true_positives = K.sum(true * pred, axis=0) + K.epsilon()  # = TP\n",
    "            #all with shape (4,)\n",
    "\n",
    "        precision = true_positives / pred_positives \n",
    "        recall = true_positives / ground_positives\n",
    "            #both = 1 if ground_positives == 0 or pred_positives == 0\n",
    "            #shape (4,)\n",
    "\n",
    "        f1 = 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
    "            #still with shape (4,)\n",
    "\n",
    "        weighted_f1 = f1 * ground_positives / K.sum(ground_positives) \n",
    "        weighted_f1 = K.sum(weighted_f1)\n",
    "\n",
    "\n",
    "        return 1 - weighted_f1\n",
    "    return custom_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "15 70\n",
      "(None, 1, 1) coeff (None, 10, 30) amplitude\n",
      "Epoch 00112: early stopping\n",
      "15 70\n",
      "(None, 1, 1) coeff (None, 10, 30) amplitude\n",
      "Epoch 00149: early stopping\n",
      "15 70\n",
      "(None, 1, 1) coeff (None, 10, 30) amplitude\n",
      "Epoch 00112: early stopping\n",
      "15 70\n",
      "(None, 1, 1) coeff (None, 10, 30) amplitude\n",
      "Epoch 00118: early stopping\n",
      "15 70\n",
      "(None, 1, 1) coeff (None, 10, 30) amplitude\n",
      "Epoch 00195: early stopping\n",
      "3002 val results 0.1879895561357702 0.003995239 index 0 test results 0.22380643767552386 0.0038435208 test result with val bias 0.2234209934816813\n",
      "3002 val results 0.3159268929503916 0.0044131144 index 1 test results 0.24830032515518766 0.0044055325 test result with val bias 0.2190709046454768\n",
      "3002 val results 0.23330365093499555 0.005212347 index 2 test results 0.23191433794724473 0.005206288 test result with val bias 0.22470030666294954\n",
      "3002 val results 0.24113475177304963 0.0045443163 index 3 test results 0.2478247824782478 0.004535908 test result with val bias 0.23672131147540984\n",
      "3002 val results 0.19327731092436976 0.002203025 index 4 test results 0.22787610619469023 0.0022025388 test result with val bias 0.22103054325017488\n",
      "3004 val results 0.1879895561357702 0.003995239 index 0 test results 0.22380643767552386 0.0038435208 test result with val bias 0.2234209934816813\n",
      "3004 val results 0.3159268929503916 0.0044131144 index 1 test results 0.24830032515518766 0.0044055325 test result with val bias 0.2190709046454768\n",
      "3004 val results 0.23330365093499555 0.005212347 index 2 test results 0.23191433794724473 0.005206288 test result with val bias 0.22470030666294954\n",
      "3004 val results 0.24113475177304963 0.0045443163 index 3 test results 0.2478247824782478 0.004535908 test result with val bias 0.23672131147540984\n",
      "3004 val results 0.19327731092436976 0.002203025 index 4 test results 0.22787610619469023 0.0022025388 test result with val bias 0.22103054325017488\n",
      "3005 val results 0.1879895561357702 0.003995239 index 0 test results 0.22380643767552386 0.0038435208 test result with val bias 0.2234209934816813\n",
      "3005 val results 0.3159268929503916 0.0044131144 index 1 test results 0.24830032515518766 0.0044055325 test result with val bias 0.2190709046454768\n",
      "3005 val results 0.23330365093499555 0.005212347 index 2 test results 0.23191433794724473 0.005206288 test result with val bias 0.22470030666294954\n",
      "3005 val results 0.24113475177304963 0.0045443163 index 3 test results 0.2478247824782478 0.004535908 test result with val bias 0.23672131147540984\n",
      "3005 val results 0.19327731092436976 0.002203025 index 4 test results 0.22787610619469023 0.0022025388 test result with val bias 0.22103054325017488\n",
      "3006 val results 0.1879895561357702 0.003995239 index 0 test results 0.22380643767552386 0.0038435208 test result with val bias 0.2234209934816813\n",
      "3006 val results 0.3159268929503916 0.0044131144 index 1 test results 0.24830032515518766 0.0044055325 test result with val bias 0.2190709046454768\n",
      "3006 val results 0.23330365093499555 0.005212347 index 2 test results 0.23191433794724473 0.005206288 test result with val bias 0.22470030666294954\n",
      "3006 val results 0.24113475177304963 0.0045443163 index 3 test results 0.2478247824782478 0.004535908 test result with val bias 0.23672131147540984\n",
      "3006 val results 0.19327731092436976 0.002203025 index 4 test results 0.22787610619469023 0.0022025388 test result with val bias 0.22103054325017488\n",
      "3007 val results 0.1879895561357702 0.003995239 index 0 test results 0.22380643767552386 0.0038435208 test result with val bias 0.2234209934816813\n",
      "3007 val results 0.3159268929503916 0.0044131144 index 1 test results 0.24830032515518766 0.0044055325 test result with val bias 0.2190709046454768\n",
      "3007 val results 0.23330365093499555 0.005212347 index 2 test results 0.23191433794724473 0.005206288 test result with val bias 0.22470030666294954\n",
      "3007 val results 0.24113475177304963 0.0045443163 index 3 test results 0.2478247824782478 0.004535908 test result with val bias 0.23672131147540984\n",
      "3007 val results 0.19327731092436976 0.002203025 index 4 test results 0.22787610619469023 0.0022025388 test result with val bias 0.22103054325017488\n",
      "3009 val results 0.1879895561357702 0.003995239 index 0 test results 0.22380643767552386 0.0038435208 test result with val bias 0.2234209934816813\n",
      "3009 val results 0.3159268929503916 0.0044131144 index 1 test results 0.24830032515518766 0.0044055325 test result with val bias 0.2190709046454768\n",
      "3009 val results 0.23330365093499555 0.005212347 index 2 test results 0.23191433794724473 0.005206288 test result with val bias 0.22470030666294954\n",
      "3009 val results 0.24113475177304963 0.0045443163 index 3 test results 0.2478247824782478 0.004535908 test result with val bias 0.23672131147540984\n",
      "3009 val results 0.19327731092436976 0.002203025 index 4 test results 0.22787610619469023 0.0022025388 test result with val bias 0.22103054325017488\n",
      "3013 val results 0.1879895561357702 0.003995239 index 0 test results 0.22380643767552386 0.0038435208 test result with val bias 0.2234209934816813\n",
      "3013 val results 0.3159268929503916 0.0044131144 index 1 test results 0.24830032515518766 0.0044055325 test result with val bias 0.2190709046454768\n",
      "3013 val results 0.23330365093499555 0.005212347 index 2 test results 0.23191433794724473 0.005206288 test result with val bias 0.22470030666294954\n",
      "3013 val results 0.24113475177304963 0.0045443163 index 3 test results 0.2478247824782478 0.004535908 test result with val bias 0.23672131147540984\n",
      "3013 val results 0.19327731092436976 0.002203025 index 4 test results 0.22787610619469023 0.0022025388 test result with val bias 0.22103054325017488\n",
      "3014 val results 0.1879895561357702 0.003995239 index 0 test results 0.22380643767552386 0.0038435208 test result with val bias 0.2234209934816813\n",
      "3014 val results 0.3159268929503916 0.0044131144 index 1 test results 0.24830032515518766 0.0044055325 test result with val bias 0.2190709046454768\n",
      "3014 val results 0.23330365093499555 0.005212347 index 2 test results 0.23191433794724473 0.005206288 test result with val bias 0.22470030666294954\n",
      "3014 val results 0.24113475177304963 0.0045443163 index 3 test results 0.2478247824782478 0.004535908 test result with val bias 0.23672131147540984\n",
      "3014 val results 0.19327731092436976 0.002203025 index 4 test results 0.22787610619469023 0.0022025388 test result with val bias 0.22103054325017488\n",
      "3015 val results 0.1879895561357702 0.003995239 index 0 test results 0.22380643767552386 0.0038435208 test result with val bias 0.2234209934816813\n",
      "3015 val results 0.3159268929503916 0.0044131144 index 1 test results 0.24830032515518766 0.0044055325 test result with val bias 0.2190709046454768\n",
      "3015 val results 0.23330365093499555 0.005212347 index 2 test results 0.23191433794724473 0.005206288 test result with val bias 0.22470030666294954\n",
      "3015 val results 0.24113475177304963 0.0045443163 index 3 test results 0.2478247824782478 0.004535908 test result with val bias 0.23672131147540984\n",
      "3015 val results 0.19327731092436976 0.002203025 index 4 test results 0.22787610619469023 0.0022025388 test result with val bias 0.22103054325017488\n",
      "3022 val results 0.1879895561357702 0.003995239 index 0 test results 0.22380643767552386 0.0038435208 test result with val bias 0.2234209934816813\n",
      "3022 val results 0.3159268929503916 0.0044131144 index 1 test results 0.24830032515518766 0.0044055325 test result with val bias 0.2190709046454768\n",
      "3022 val results 0.23330365093499555 0.005212347 index 2 test results 0.23191433794724473 0.005206288 test result with val bias 0.22470030666294954\n",
      "3022 val results 0.24113475177304963 0.0045443163 index 3 test results 0.2478247824782478 0.004535908 test result with val bias 0.23672131147540984\n",
      "3022 val results 0.19327731092436976 0.002203025 index 4 test results 0.22787610619469023 0.0022025388 test result with val bias 0.22103054325017488\n",
      "3024 val results 0.1879895561357702 0.003995239 index 0 test results 0.22380643767552386 0.0038435208 test result with val bias 0.2234209934816813\n",
      "3024 val results 0.3159268929503916 0.0044131144 index 1 test results 0.24830032515518766 0.0044055325 test result with val bias 0.2190709046454768\n",
      "3024 val results 0.23330365093499555 0.005212347 index 2 test results 0.23191433794724473 0.005206288 test result with val bias 0.22470030666294954\n",
      "3024 val results 0.24113475177304963 0.0045443163 index 3 test results 0.2478247824782478 0.004535908 test result with val bias 0.23672131147540984\n",
      "3024 val results 0.19327731092436976 0.002203025 index 4 test results 0.22787610619469023 0.0022025388 test result with val bias 0.22103054325017488\n",
      "11\n",
      "15 70\n",
      "(None, 1, 1) coeff (None, 10, 30) amplitude\n",
      "Epoch 00149: early stopping\n",
      "15 70\n",
      "(None, 1, 1) coeff (None, 10, 30) amplitude\n",
      "Epoch 00092: early stopping\n",
      "15 70\n",
      "(None, 1, 1) coeff (None, 10, 30) amplitude\n",
      "Epoch 00094: early stopping\n",
      "15 70\n",
      "(None, 1, 1) coeff (None, 10, 30) amplitude\n",
      "Epoch 00094: early stopping\n",
      "15 70\n",
      "(None, 1, 1) coeff (None, 10, 30) amplitude\n",
      "Epoch 00157: early stopping\n",
      "3025 val results 0.36042402826855124 0.002755457 index 0 test results 0.1778185151237397 0.0027501527 test result with val bias 0.19764011799410028\n",
      "3025 val results 0.2207245155855097 0.005458889 index 1 test results 0.17308004546192562 0.005421242 test result with val bias 0.1613653995345229\n",
      "3025 val results 0.2651113467656416 0.0076419897 index 2 test results 0.17605907500971632 0.007621207 test result with val bias 0.17747823645043528\n",
      "3025 val results 0.21559633027522937 0.0024962802 index 3 test results 0.1710820300031918 0.0021886586 test result with val bias 0.15309366593299095\n",
      "3025 val results 0.1904761904761905 0.003510439 index 4 test results 0.17194279286517755 0.0030397768 test result with val bias 0.1662277814351547\n",
      "3029 val results 0.36042402826855124 0.002755457 index 0 test results 0.1778185151237397 0.0027501527 test result with val bias 0.19764011799410028\n",
      "3029 val results 0.2207245155855097 0.005458889 index 1 test results 0.17308004546192562 0.005421242 test result with val bias 0.1613653995345229\n",
      "3029 val results 0.2651113467656416 0.0076419897 index 2 test results 0.17605907500971632 0.007621207 test result with val bias 0.17747823645043528\n",
      "3029 val results 0.21559633027522937 0.0024962802 index 3 test results 0.1710820300031918 0.0021886586 test result with val bias 0.15309366593299095\n",
      "3029 val results 0.1904761904761905 0.003510439 index 4 test results 0.17194279286517755 0.0030397768 test result with val bias 0.1662277814351547\n",
      "3031 val results 0.36042402826855124 0.002755457 index 0 test results 0.1778185151237397 0.0027501527 test result with val bias 0.19764011799410028\n",
      "3031 val results 0.2207245155855097 0.005458889 index 1 test results 0.17308004546192562 0.005421242 test result with val bias 0.1613653995345229\n",
      "3031 val results 0.2651113467656416 0.0076419897 index 2 test results 0.17605907500971632 0.007621207 test result with val bias 0.17747823645043528\n",
      "3031 val results 0.21559633027522937 0.0024962802 index 3 test results 0.1710820300031918 0.0021886586 test result with val bias 0.15309366593299095\n",
      "3031 val results 0.1904761904761905 0.003510439 index 4 test results 0.17194279286517755 0.0030397768 test result with val bias 0.1662277814351547\n",
      "3033 val results 0.36042402826855124 0.002755457 index 0 test results 0.1778185151237397 0.0027501527 test result with val bias 0.19764011799410028\n",
      "3033 val results 0.2207245155855097 0.005458889 index 1 test results 0.17308004546192562 0.005421242 test result with val bias 0.1613653995345229\n",
      "3033 val results 0.2651113467656416 0.0076419897 index 2 test results 0.17605907500971632 0.007621207 test result with val bias 0.17747823645043528\n",
      "3033 val results 0.21559633027522937 0.0024962802 index 3 test results 0.1710820300031918 0.0021886586 test result with val bias 0.15309366593299095\n",
      "3033 val results 0.1904761904761905 0.003510439 index 4 test results 0.17194279286517755 0.0030397768 test result with val bias 0.1662277814351547\n",
      "3036 val results 0.36042402826855124 0.002755457 index 0 test results 0.1778185151237397 0.0027501527 test result with val bias 0.19764011799410028\n",
      "3036 val results 0.2207245155855097 0.005458889 index 1 test results 0.17308004546192562 0.005421242 test result with val bias 0.1613653995345229\n",
      "3036 val results 0.2651113467656416 0.0076419897 index 2 test results 0.17605907500971632 0.007621207 test result with val bias 0.17747823645043528\n",
      "3036 val results 0.21559633027522937 0.0024962802 index 3 test results 0.1710820300031918 0.0021886586 test result with val bias 0.15309366593299095\n",
      "3036 val results 0.1904761904761905 0.003510439 index 4 test results 0.17194279286517755 0.0030397768 test result with val bias 0.1662277814351547\n",
      "3038 val results 0.36042402826855124 0.002755457 index 0 test results 0.1778185151237397 0.0027501527 test result with val bias 0.19764011799410028\n",
      "3038 val results 0.2207245155855097 0.005458889 index 1 test results 0.17308004546192562 0.005421242 test result with val bias 0.1613653995345229\n",
      "3038 val results 0.2651113467656416 0.0076419897 index 2 test results 0.17605907500971632 0.007621207 test result with val bias 0.17747823645043528\n",
      "3038 val results 0.21559633027522937 0.0024962802 index 3 test results 0.1710820300031918 0.0021886586 test result with val bias 0.15309366593299095\n",
      "3038 val results 0.1904761904761905 0.003510439 index 4 test results 0.17194279286517755 0.0030397768 test result with val bias 0.1662277814351547\n",
      "3041 val results 0.36042402826855124 0.002755457 index 0 test results 0.1778185151237397 0.0027501527 test result with val bias 0.19764011799410028\n",
      "3041 val results 0.2207245155855097 0.005458889 index 1 test results 0.17308004546192562 0.005421242 test result with val bias 0.1613653995345229\n",
      "3041 val results 0.2651113467656416 0.0076419897 index 2 test results 0.17605907500971632 0.007621207 test result with val bias 0.17747823645043528\n",
      "3041 val results 0.21559633027522937 0.0024962802 index 3 test results 0.1710820300031918 0.0021886586 test result with val bias 0.15309366593299095\n",
      "3041 val results 0.1904761904761905 0.003510439 index 4 test results 0.17194279286517755 0.0030397768 test result with val bias 0.1662277814351547\n",
      "3045 val results 0.36042402826855124 0.002755457 index 0 test results 0.1778185151237397 0.0027501527 test result with val bias 0.19764011799410028\n",
      "3045 val results 0.2207245155855097 0.005458889 index 1 test results 0.17308004546192562 0.005421242 test result with val bias 0.1613653995345229\n",
      "3045 val results 0.2651113467656416 0.0076419897 index 2 test results 0.17605907500971632 0.007621207 test result with val bias 0.17747823645043528\n",
      "3045 val results 0.21559633027522937 0.0024962802 index 3 test results 0.1710820300031918 0.0021886586 test result with val bias 0.15309366593299095\n",
      "3045 val results 0.1904761904761905 0.003510439 index 4 test results 0.17194279286517755 0.0030397768 test result with val bias 0.1662277814351547\n",
      "3048 val results 0.36042402826855124 0.002755457 index 0 test results 0.1778185151237397 0.0027501527 test result with val bias 0.19764011799410028\n",
      "3048 val results 0.2207245155855097 0.005458889 index 1 test results 0.17308004546192562 0.005421242 test result with val bias 0.1613653995345229\n",
      "3048 val results 0.2651113467656416 0.0076419897 index 2 test results 0.17605907500971632 0.007621207 test result with val bias 0.17747823645043528\n",
      "3048 val results 0.21559633027522937 0.0024962802 index 3 test results 0.1710820300031918 0.0021886586 test result with val bias 0.15309366593299095\n",
      "3048 val results 0.1904761904761905 0.003510439 index 4 test results 0.17194279286517755 0.0030397768 test result with val bias 0.1662277814351547\n",
      "3053 val results 0.36042402826855124 0.002755457 index 0 test results 0.1778185151237397 0.0027501527 test result with val bias 0.19764011799410028\n",
      "3053 val results 0.2207245155855097 0.005458889 index 1 test results 0.17308004546192562 0.005421242 test result with val bias 0.1613653995345229\n",
      "3053 val results 0.2651113467656416 0.0076419897 index 2 test results 0.17605907500971632 0.007621207 test result with val bias 0.17747823645043528\n",
      "3053 val results 0.21559633027522937 0.0024962802 index 3 test results 0.1710820300031918 0.0021886586 test result with val bias 0.15309366593299095\n",
      "3053 val results 0.1904761904761905 0.003510439 index 4 test results 0.17194279286517755 0.0030397768 test result with val bias 0.1662277814351547\n",
      "21\n",
      "15 70\n",
      "(None, 1, 1) coeff (None, 10, 30) amplitude\n",
      "Epoch 00152: early stopping\n",
      "15 70\n",
      "(None, 1, 1) coeff (None, 10, 30) amplitude\n",
      "Epoch 00156: early stopping\n",
      "15 70\n",
      "(None, 1, 1) coeff (None, 10, 30) amplitude\n",
      "Epoch 00152: early stopping\n",
      "15 70\n",
      "(None, 1, 1) coeff (None, 10, 30) amplitude\n",
      "Epoch 00136: early stopping\n",
      "15 70\n",
      "(None, 1, 1) coeff (None, 10, 30) amplitude\n",
      "Epoch 00187: early stopping\n",
      "3076 val results 0.15018587360594796 0.006080167 index 0 test results 0.1977919452651221 0.006080164 test result with val bias 0.1222879684418146\n",
      "3076 val results 0.21460506706408347 0.008220377 index 1 test results 0.19719179139021756 0.0077778944 test result with val bias 0.13199723565998617\n",
      "3076 val results 0.1589825119236884 0.0053549106 index 2 test results 0.19937205651491366 0.005353697 test result with val bias 0.19422394865732143\n",
      "3076 val results 0.14708002883922133 0.004500473 index 3 test results 0.19771039603960397 0.0044799405 test result with val bias 0.1867007672634271\n",
      "3076 val results 0.14627081824764665 0.0018571978 index 4 test results 0.207883898803687 0.0019244308 test result with val bias 0.19865477866416392\n",
      "3077 val results 0.15018587360594796 0.006080167 index 0 test results 0.1977919452651221 0.006080164 test result with val bias 0.1222879684418146\n",
      "3077 val results 0.21460506706408347 0.008220377 index 1 test results 0.19719179139021756 0.0077778944 test result with val bias 0.13199723565998617\n",
      "3077 val results 0.1589825119236884 0.0053549106 index 2 test results 0.19937205651491366 0.005353697 test result with val bias 0.19422394865732143\n",
      "3077 val results 0.14708002883922133 0.004500473 index 3 test results 0.19771039603960397 0.0044799405 test result with val bias 0.1867007672634271\n",
      "3077 val results 0.14627081824764665 0.0018571978 index 4 test results 0.207883898803687 0.0019244308 test result with val bias 0.19865477866416392\n",
      "3079 val results 0.15018587360594796 0.006080167 index 0 test results 0.1977919452651221 0.006080164 test result with val bias 0.1222879684418146\n",
      "3079 val results 0.21460506706408347 0.008220377 index 1 test results 0.19719179139021756 0.0077778944 test result with val bias 0.13199723565998617\n",
      "3079 val results 0.1589825119236884 0.0053549106 index 2 test results 0.19937205651491366 0.005353697 test result with val bias 0.19422394865732143\n",
      "3079 val results 0.14708002883922133 0.004500473 index 3 test results 0.19771039603960397 0.0044799405 test result with val bias 0.1867007672634271\n",
      "3079 val results 0.14627081824764665 0.0018571978 index 4 test results 0.207883898803687 0.0019244308 test result with val bias 0.19865477866416392\n",
      "3086 val results 0.15018587360594796 0.006080167 index 0 test results 0.1977919452651221 0.006080164 test result with val bias 0.1222879684418146\n",
      "3086 val results 0.21460506706408347 0.008220377 index 1 test results 0.19719179139021756 0.0077778944 test result with val bias 0.13199723565998617\n",
      "3086 val results 0.1589825119236884 0.0053549106 index 2 test results 0.19937205651491366 0.005353697 test result with val bias 0.19422394865732143\n",
      "3086 val results 0.14708002883922133 0.004500473 index 3 test results 0.19771039603960397 0.0044799405 test result with val bias 0.1867007672634271\n",
      "3086 val results 0.14627081824764665 0.0018571978 index 4 test results 0.207883898803687 0.0019244308 test result with val bias 0.19865477866416392\n",
      "3088 val results 0.15018587360594796 0.006080167 index 0 test results 0.1977919452651221 0.006080164 test result with val bias 0.1222879684418146\n",
      "3088 val results 0.21460506706408347 0.008220377 index 1 test results 0.19719179139021756 0.0077778944 test result with val bias 0.13199723565998617\n",
      "3088 val results 0.1589825119236884 0.0053549106 index 2 test results 0.19937205651491366 0.005353697 test result with val bias 0.19422394865732143\n",
      "3088 val results 0.14708002883922133 0.004500473 index 3 test results 0.19771039603960397 0.0044799405 test result with val bias 0.1867007672634271\n",
      "3088 val results 0.14627081824764665 0.0018571978 index 4 test results 0.207883898803687 0.0019244308 test result with val bias 0.19865477866416392\n",
      "3091 val results 0.15018587360594796 0.006080167 index 0 test results 0.1977919452651221 0.006080164 test result with val bias 0.1222879684418146\n",
      "3091 val results 0.21460506706408347 0.008220377 index 1 test results 0.19719179139021756 0.0077778944 test result with val bias 0.13199723565998617\n",
      "3091 val results 0.1589825119236884 0.0053549106 index 2 test results 0.19937205651491366 0.005353697 test result with val bias 0.19422394865732143\n",
      "3091 val results 0.14708002883922133 0.004500473 index 3 test results 0.19771039603960397 0.0044799405 test result with val bias 0.1867007672634271\n",
      "3091 val results 0.14627081824764665 0.0018571978 index 4 test results 0.207883898803687 0.0019244308 test result with val bias 0.19865477866416392\n",
      "3095 val results 0.15018587360594796 0.006080167 index 0 test results 0.1977919452651221 0.006080164 test result with val bias 0.1222879684418146\n",
      "3095 val results 0.21460506706408347 0.008220377 index 1 test results 0.19719179139021756 0.0077778944 test result with val bias 0.13199723565998617\n",
      "3095 val results 0.1589825119236884 0.0053549106 index 2 test results 0.19937205651491366 0.005353697 test result with val bias 0.19422394865732143\n",
      "3095 val results 0.14708002883922133 0.004500473 index 3 test results 0.19771039603960397 0.0044799405 test result with val bias 0.1867007672634271\n",
      "3095 val results 0.14627081824764665 0.0018571978 index 4 test results 0.207883898803687 0.0019244308 test result with val bias 0.19865477866416392\n",
      "3099 val results 0.15018587360594796 0.006080167 index 0 test results 0.1977919452651221 0.006080164 test result with val bias 0.1222879684418146\n",
      "3099 val results 0.21460506706408347 0.008220377 index 1 test results 0.19719179139021756 0.0077778944 test result with val bias 0.13199723565998617\n",
      "3099 val results 0.1589825119236884 0.0053549106 index 2 test results 0.19937205651491366 0.005353697 test result with val bias 0.19422394865732143\n",
      "3099 val results 0.14708002883922133 0.004500473 index 3 test results 0.19771039603960397 0.0044799405 test result with val bias 0.1867007672634271\n",
      "3099 val results 0.14627081824764665 0.0018571978 index 4 test results 0.207883898803687 0.0019244308 test result with val bias 0.19865477866416392\n",
      "3101 val results 0.15018587360594796 0.006080167 index 0 test results 0.1977919452651221 0.006080164 test result with val bias 0.1222879684418146\n",
      "3101 val results 0.21460506706408347 0.008220377 index 1 test results 0.19719179139021756 0.0077778944 test result with val bias 0.13199723565998617\n",
      "3101 val results 0.1589825119236884 0.0053549106 index 2 test results 0.19937205651491366 0.005353697 test result with val bias 0.19422394865732143\n",
      "3101 val results 0.14708002883922133 0.004500473 index 3 test results 0.19771039603960397 0.0044799405 test result with val bias 0.1867007672634271\n",
      "3101 val results 0.14627081824764665 0.0018571978 index 4 test results 0.207883898803687 0.0019244308 test result with val bias 0.19865477866416392\n",
      "3102 val results 0.15018587360594796 0.006080167 index 0 test results 0.1977919452651221 0.006080164 test result with val bias 0.1222879684418146\n",
      "3102 val results 0.21460506706408347 0.008220377 index 1 test results 0.19719179139021756 0.0077778944 test result with val bias 0.13199723565998617\n",
      "3102 val results 0.1589825119236884 0.0053549106 index 2 test results 0.19937205651491366 0.005353697 test result with val bias 0.19422394865732143\n",
      "3102 val results 0.14708002883922133 0.004500473 index 3 test results 0.19771039603960397 0.0044799405 test result with val bias 0.1867007672634271\n",
      "3102 val results 0.14627081824764665 0.0018571978 index 4 test results 0.207883898803687 0.0019244308 test result with val bias 0.19865477866416392\n",
      "31\n",
      "15 70\n",
      "(None, 1, 1) coeff (None, 10, 30) amplitude\n",
      "Epoch 00082: early stopping\n",
      "15 70\n",
      "(None, 1, 1) coeff (None, 10, 30) amplitude\n",
      "Epoch 00160: early stopping\n",
      "15 70\n",
      "(None, 1, 1) coeff (None, 10, 30) amplitude\n",
      "Epoch 00151: early stopping\n",
      "15 70\n",
      "(None, 1, 1) coeff (None, 10, 30) amplitude\n",
      "Epoch 00125: early stopping\n",
      "15 70\n",
      "(None, 1, 1) coeff (None, 10, 30) amplitude\n",
      "Epoch 00165: early stopping\n",
      "3122 val results 0.18135283363802562 0.07162251 index 0 test results 0.23099320608217402 0.07162251 test result with val bias 0.15027322404371585\n",
      "3122 val results 0.18135283363802562 0.0055865785 index 1 test results 0.23099320608217402 0.0055865785 test result with val bias 0.14545454545454545\n",
      "3122 val results 0.18135283363802562 0.0028810522 index 2 test results 0.23847695390781562 0.002956698 test result with val bias 0.23099320608217402\n",
      "3122 val results 0.19005328596802842 0.0071456167 index 3 test results 0.24761204996326236 0.00713663 test result with val bias 0.23921568627450981\n",
      "3122 val results 0.18135283363802562 0.012980842 index 4 test results 0.23099320608217402 0.012980842 test result with val bias 0.16210526315789472\n",
      "3125 val results 0.18135283363802562 0.07162251 index 0 test results 0.23099320608217402 0.07162251 test result with val bias 0.15027322404371585\n",
      "3125 val results 0.18135283363802562 0.0055865785 index 1 test results 0.23099320608217402 0.0055865785 test result with val bias 0.14545454545454545\n",
      "3125 val results 0.18135283363802562 0.0028810522 index 2 test results 0.23847695390781562 0.002956698 test result with val bias 0.23099320608217402\n",
      "3125 val results 0.19005328596802842 0.0071456167 index 3 test results 0.24761204996326236 0.00713663 test result with val bias 0.23921568627450981\n",
      "3125 val results 0.18135283363802562 0.012980842 index 4 test results 0.23099320608217402 0.012980842 test result with val bias 0.16210526315789472\n",
      "3126 val results 0.18135283363802562 0.07162251 index 0 test results 0.23099320608217402 0.07162251 test result with val bias 0.15027322404371585\n",
      "3126 val results 0.18135283363802562 0.0055865785 index 1 test results 0.23099320608217402 0.0055865785 test result with val bias 0.14545454545454545\n",
      "3126 val results 0.18135283363802562 0.0028810522 index 2 test results 0.23847695390781562 0.002956698 test result with val bias 0.23099320608217402\n",
      "3126 val results 0.19005328596802842 0.0071456167 index 3 test results 0.24761204996326236 0.00713663 test result with val bias 0.23921568627450981\n",
      "3126 val results 0.18135283363802562 0.012980842 index 4 test results 0.23099320608217402 0.012980842 test result with val bias 0.16210526315789472\n",
      "3128 val results 0.18135283363802562 0.07162251 index 0 test results 0.23099320608217402 0.07162251 test result with val bias 0.15027322404371585\n",
      "3128 val results 0.18135283363802562 0.0055865785 index 1 test results 0.23099320608217402 0.0055865785 test result with val bias 0.14545454545454545\n",
      "3128 val results 0.18135283363802562 0.0028810522 index 2 test results 0.23847695390781562 0.002956698 test result with val bias 0.23099320608217402\n",
      "3128 val results 0.19005328596802842 0.0071456167 index 3 test results 0.24761204996326236 0.00713663 test result with val bias 0.23921568627450981\n",
      "3128 val results 0.18135283363802562 0.012980842 index 4 test results 0.23099320608217402 0.012980842 test result with val bias 0.16210526315789472\n",
      "3133 val results 0.18135283363802562 0.07162251 index 0 test results 0.23099320608217402 0.07162251 test result with val bias 0.15027322404371585\n",
      "3133 val results 0.18135283363802562 0.0055865785 index 1 test results 0.23099320608217402 0.0055865785 test result with val bias 0.14545454545454545\n",
      "3133 val results 0.18135283363802562 0.0028810522 index 2 test results 0.23847695390781562 0.002956698 test result with val bias 0.23099320608217402\n",
      "3133 val results 0.19005328596802842 0.0071456167 index 3 test results 0.24761204996326236 0.00713663 test result with val bias 0.23921568627450981\n",
      "3133 val results 0.18135283363802562 0.012980842 index 4 test results 0.23099320608217402 0.012980842 test result with val bias 0.16210526315789472\n",
      "3135 val results 0.18135283363802562 0.07162251 index 0 test results 0.23099320608217402 0.07162251 test result with val bias 0.15027322404371585\n",
      "3135 val results 0.18135283363802562 0.0055865785 index 1 test results 0.23099320608217402 0.0055865785 test result with val bias 0.14545454545454545\n",
      "3135 val results 0.18135283363802562 0.0028810522 index 2 test results 0.23847695390781562 0.002956698 test result with val bias 0.23099320608217402\n",
      "3135 val results 0.19005328596802842 0.0071456167 index 3 test results 0.24761204996326236 0.00713663 test result with val bias 0.23921568627450981\n",
      "3135 val results 0.18135283363802562 0.012980842 index 4 test results 0.23099320608217402 0.012980842 test result with val bias 0.16210526315789472\n",
      "3137 val results 0.18135283363802562 0.07162251 index 0 test results 0.23099320608217402 0.07162251 test result with val bias 0.15027322404371585\n",
      "3137 val results 0.18135283363802562 0.0055865785 index 1 test results 0.23099320608217402 0.0055865785 test result with val bias 0.14545454545454545\n",
      "3137 val results 0.18135283363802562 0.0028810522 index 2 test results 0.23847695390781562 0.002956698 test result with val bias 0.23099320608217402\n",
      "3137 val results 0.19005328596802842 0.0071456167 index 3 test results 0.24761204996326236 0.00713663 test result with val bias 0.23921568627450981\n",
      "3137 val results 0.18135283363802562 0.012980842 index 4 test results 0.23099320608217402 0.012980842 test result with val bias 0.16210526315789472\n",
      "3138 val results 0.18135283363802562 0.07162251 index 0 test results 0.23099320608217402 0.07162251 test result with val bias 0.15027322404371585\n",
      "3138 val results 0.18135283363802562 0.0055865785 index 1 test results 0.23099320608217402 0.0055865785 test result with val bias 0.14545454545454545\n",
      "3138 val results 0.18135283363802562 0.0028810522 index 2 test results 0.23847695390781562 0.002956698 test result with val bias 0.23099320608217402\n",
      "3138 val results 0.19005328596802842 0.0071456167 index 3 test results 0.24761204996326236 0.00713663 test result with val bias 0.23921568627450981\n",
      "3138 val results 0.18135283363802562 0.012980842 index 4 test results 0.23099320608217402 0.012980842 test result with val bias 0.16210526315789472\n",
      "3139 val results 0.18135283363802562 0.07162251 index 0 test results 0.23099320608217402 0.07162251 test result with val bias 0.15027322404371585\n",
      "3139 val results 0.18135283363802562 0.0055865785 index 1 test results 0.23099320608217402 0.0055865785 test result with val bias 0.14545454545454545\n",
      "3139 val results 0.18135283363802562 0.0028810522 index 2 test results 0.23847695390781562 0.002956698 test result with val bias 0.23099320608217402\n",
      "3139 val results 0.19005328596802842 0.0071456167 index 3 test results 0.24761204996326236 0.00713663 test result with val bias 0.23921568627450981\n",
      "3139 val results 0.18135283363802562 0.012980842 index 4 test results 0.23099320608217402 0.012980842 test result with val bias 0.16210526315789472\n",
      "3143 val results 0.18135283363802562 0.07162251 index 0 test results 0.23099320608217402 0.07162251 test result with val bias 0.15027322404371585\n",
      "3143 val results 0.18135283363802562 0.0055865785 index 1 test results 0.23099320608217402 0.0055865785 test result with val bias 0.14545454545454545\n",
      "3143 val results 0.18135283363802562 0.0028810522 index 2 test results 0.23847695390781562 0.002956698 test result with val bias 0.23099320608217402\n",
      "3143 val results 0.19005328596802842 0.0071456167 index 3 test results 0.24761204996326236 0.00713663 test result with val bias 0.23921568627450981\n",
      "3143 val results 0.18135283363802562 0.012980842 index 4 test results 0.23099320608217402 0.012980842 test result with val bias 0.16210526315789472\n",
      "41\n",
      "15 70\n",
      "(None, 1, 1) coeff (None, 10, 30) amplitude\n",
      "Epoch 00084: early stopping\n",
      "15 70\n",
      "(None, 1, 1) coeff (None, 10, 30) amplitude\n",
      "Epoch 00099: early stopping\n",
      "15 70\n",
      "(None, 1, 1) coeff (None, 10, 30) amplitude\n",
      "Epoch 00094: early stopping\n",
      "15 70\n",
      "(None, 1, 1) coeff (None, 10, 30) amplitude\n",
      "Epoch 00110: early stopping\n",
      "15 70\n",
      "(None, 1, 1) coeff (None, 10, 30) amplitude\n",
      "Epoch 00093: early stopping\n",
      "3145 val results 0.2479935794542536 0.012592862 index 0 test results 0.09635316698656429 0.012573181 test result with val bias 0.0932336742722266\n",
      "3145 val results 0.24588576960309777 0.032773647 index 1 test results 0.08852941176470588 0.032773647 test result with val bias 0.10450966356478168\n",
      "3145 val results 0.2540365984930032 0.0062339054 index 2 test results 0.09046026437330784 0.006192201 test result with val bias 0.08815244407622205\n",
      "3145 val results 0.24688932547478715 0.002185901 index 3 test results 0.0888560885608856 0.0021856015 test result with val bias 0.08764582710140593\n",
      "3145 val results 0.25151311365164764 0.01135127 index 4 test results 0.08852941176470588 0.011063184 test result with val bias 0.08462363942971025\n",
      "3148 val results 0.2479935794542536 0.012592862 index 0 test results 0.09635316698656429 0.012573181 test result with val bias 0.0932336742722266\n",
      "3148 val results 0.24588576960309777 0.032773647 index 1 test results 0.08852941176470588 0.032773647 test result with val bias 0.10450966356478168\n",
      "3148 val results 0.2540365984930032 0.0062339054 index 2 test results 0.09046026437330784 0.006192201 test result with val bias 0.08815244407622205\n",
      "3148 val results 0.24688932547478715 0.002185901 index 3 test results 0.0888560885608856 0.0021856015 test result with val bias 0.08764582710140593\n",
      "3148 val results 0.25151311365164764 0.01135127 index 4 test results 0.08852941176470588 0.011063184 test result with val bias 0.08462363942971025\n",
      "3152 val results 0.2479935794542536 0.012592862 index 0 test results 0.09635316698656429 0.012573181 test result with val bias 0.0932336742722266\n",
      "3152 val results 0.24588576960309777 0.032773647 index 1 test results 0.08852941176470588 0.032773647 test result with val bias 0.10450966356478168\n",
      "3152 val results 0.2540365984930032 0.0062339054 index 2 test results 0.09046026437330784 0.006192201 test result with val bias 0.08815244407622205\n",
      "3152 val results 0.24688932547478715 0.002185901 index 3 test results 0.0888560885608856 0.0021856015 test result with val bias 0.08764582710140593\n",
      "3152 val results 0.25151311365164764 0.01135127 index 4 test results 0.08852941176470588 0.011063184 test result with val bias 0.08462363942971025\n",
      "3153 val results 0.2479935794542536 0.012592862 index 0 test results 0.09635316698656429 0.012573181 test result with val bias 0.0932336742722266\n",
      "3153 val results 0.24588576960309777 0.032773647 index 1 test results 0.08852941176470588 0.032773647 test result with val bias 0.10450966356478168\n",
      "3153 val results 0.2540365984930032 0.0062339054 index 2 test results 0.09046026437330784 0.006192201 test result with val bias 0.08815244407622205\n",
      "3153 val results 0.24688932547478715 0.002185901 index 3 test results 0.0888560885608856 0.0021856015 test result with val bias 0.08764582710140593\n",
      "3153 val results 0.25151311365164764 0.01135127 index 4 test results 0.08852941176470588 0.011063184 test result with val bias 0.08462363942971025\n",
      "3158 val results 0.2479935794542536 0.012592862 index 0 test results 0.09635316698656429 0.012573181 test result with val bias 0.0932336742722266\n",
      "3158 val results 0.24588576960309777 0.032773647 index 1 test results 0.08852941176470588 0.032773647 test result with val bias 0.10450966356478168\n",
      "3158 val results 0.2540365984930032 0.0062339054 index 2 test results 0.09046026437330784 0.006192201 test result with val bias 0.08815244407622205\n",
      "3158 val results 0.24688932547478715 0.002185901 index 3 test results 0.0888560885608856 0.0021856015 test result with val bias 0.08764582710140593\n",
      "3158 val results 0.25151311365164764 0.01135127 index 4 test results 0.08852941176470588 0.011063184 test result with val bias 0.08462363942971025\n",
      "3160 val results 0.2479935794542536 0.012592862 index 0 test results 0.09635316698656429 0.012573181 test result with val bias 0.0932336742722266\n",
      "3160 val results 0.24588576960309777 0.032773647 index 1 test results 0.08852941176470588 0.032773647 test result with val bias 0.10450966356478168\n",
      "3160 val results 0.2540365984930032 0.0062339054 index 2 test results 0.09046026437330784 0.006192201 test result with val bias 0.08815244407622205\n",
      "3160 val results 0.24688932547478715 0.002185901 index 3 test results 0.0888560885608856 0.0021856015 test result with val bias 0.08764582710140593\n",
      "3160 val results 0.25151311365164764 0.01135127 index 4 test results 0.08852941176470588 0.011063184 test result with val bias 0.08462363942971025\n",
      "3164 val results 0.2479935794542536 0.012592862 index 0 test results 0.09635316698656429 0.012573181 test result with val bias 0.0932336742722266\n",
      "3164 val results 0.24588576960309777 0.032773647 index 1 test results 0.08852941176470588 0.032773647 test result with val bias 0.10450966356478168\n",
      "3164 val results 0.2540365984930032 0.0062339054 index 2 test results 0.09046026437330784 0.006192201 test result with val bias 0.08815244407622205\n",
      "3164 val results 0.24688932547478715 0.002185901 index 3 test results 0.0888560885608856 0.0021856015 test result with val bias 0.08764582710140593\n",
      "3164 val results 0.25151311365164764 0.01135127 index 4 test results 0.08852941176470588 0.011063184 test result with val bias 0.08462363942971025\n",
      "3165 val results 0.2479935794542536 0.012592862 index 0 test results 0.09635316698656429 0.012573181 test result with val bias 0.0932336742722266\n",
      "3165 val results 0.24588576960309777 0.032773647 index 1 test results 0.08852941176470588 0.032773647 test result with val bias 0.10450966356478168\n",
      "3165 val results 0.2540365984930032 0.0062339054 index 2 test results 0.09046026437330784 0.006192201 test result with val bias 0.08815244407622205\n",
      "3165 val results 0.24688932547478715 0.002185901 index 3 test results 0.0888560885608856 0.0021856015 test result with val bias 0.08764582710140593\n",
      "3165 val results 0.25151311365164764 0.01135127 index 4 test results 0.08852941176470588 0.011063184 test result with val bias 0.08462363942971025\n",
      "3166 val results 0.2479935794542536 0.012592862 index 0 test results 0.09635316698656429 0.012573181 test result with val bias 0.0932336742722266\n",
      "3166 val results 0.24588576960309777 0.032773647 index 1 test results 0.08852941176470588 0.032773647 test result with val bias 0.10450966356478168\n",
      "3166 val results 0.2540365984930032 0.0062339054 index 2 test results 0.09046026437330784 0.006192201 test result with val bias 0.08815244407622205\n",
      "3166 val results 0.24688932547478715 0.002185901 index 3 test results 0.0888560885608856 0.0021856015 test result with val bias 0.08764582710140593\n",
      "3166 val results 0.25151311365164764 0.01135127 index 4 test results 0.08852941176470588 0.011063184 test result with val bias 0.08462363942971025\n",
      "3168 val results 0.2479935794542536 0.012592862 index 0 test results 0.09635316698656429 0.012573181 test result with val bias 0.0932336742722266\n",
      "3168 val results 0.24588576960309777 0.032773647 index 1 test results 0.08852941176470588 0.032773647 test result with val bias 0.10450966356478168\n",
      "3168 val results 0.2540365984930032 0.0062339054 index 2 test results 0.09046026437330784 0.006192201 test result with val bias 0.08815244407622205\n",
      "3168 val results 0.24688932547478715 0.002185901 index 3 test results 0.0888560885608856 0.0021856015 test result with val bias 0.08764582710140593\n",
      "3168 val results 0.25151311365164764 0.01135127 index 4 test results 0.08852941176470588 0.011063184 test result with val bias 0.08462363942971025\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "def get_X_y_groups(n_lag=10):\n",
    "    data = pickle.load(open(filepath_file.format(n_lag),'rb'))\n",
    "\n",
    "    X_feature = np.concatenate(data.feature_final.values)\n",
    "    X_static =  np.concatenate(data.static_features.values)\n",
    "\n",
    "    X_stress_episode = np.concatenate(data.stress_episode.values)\n",
    "    X_quit_episode = np.concatenate(data.quit_episode.values)\n",
    "    X_activity_episode = np.concatenate(data.activity_episode.values)\n",
    "    X_smoking_episode = np.concatenate(data.smoking_episode.values)\n",
    "\n",
    "    y_time = data['time'].values\n",
    "    print(data['label'].unique())\n",
    "    # y =  OneHotEncoder().fit_transform(data['label'].values.reshape(-1,1)).todense()\n",
    "    y = data['label'].values\n",
    "    groups = data['user'].values\n",
    "    \n",
    "    return X_feature,X_static,X_stress_episode,X_quit_episode,X_activity_episode,X_smoking_episode,y_time,y,groups\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "use_standardization = True\n",
    "for n_lag in [15]:\n",
    "    all_data = []\n",
    "    columns = ['alpha_stress','alpha_smoking','alpha_activity']\n",
    "    amplitude_duration_data = []\n",
    "    amplitude_duration_columns = ['amplitude_stress','duration_stress'] \n",
    "    data_cluster = pickle.load(open(filepath_file.format(n_lag),'rb'))\n",
    "    temp = data_cluster.groupby(['user','cluster_label']).count().index.values\n",
    "    users = np.array([a[0] for a in temp])\n",
    "    labels = np.array([a[1] for a in temp])\n",
    "    cluster_dict = {}\n",
    "    for i,a in enumerate(users):\n",
    "        cluster_dict[a] = labels[i]\n",
    "    n_groups = len(np.unique(users))\n",
    "    # n_groups = 20\n",
    "    X_feature,X_static,X_stress_episode,X_quit_episode,X_activity_episode,X_smoking_episode,y_time,y,groups = get_X_y_groups(n_lag)\n",
    "    # y[y<0] = 0\n",
    "    y = np.float32(y)\n",
    "    indexes = get_train_test_indexes(groups,n_groups_split = 5,n_val_groups=5)\n",
    "    final_y_time = []\n",
    "    final_probs = []\n",
    "    final_y = []\n",
    "    final_groups = []\n",
    "    bias_dict = {}\n",
    "    val_results = {}\n",
    "    for kk,yyyy in enumerate(indexes):\n",
    "        train_index,test_index,val_index = yyyy\n",
    "        \n",
    "        X_feature_train,X_feature_test = X_feature[train_index],X_feature[test_index]\n",
    "        X_static_train,X_static_test = X_static[train_index],X_static[test_index]\n",
    "        X_stress_episode_train,X_stress_episode_test = X_stress_episode[train_index], X_stress_episode[test_index]\n",
    "        X_quit_episode_train,X_quit_episode_test = X_quit_episode[train_index], X_quit_episode[test_index]\n",
    "        X_activity_episode_train,X_activity_episode_test = X_activity_episode[train_index], X_activity_episode[test_index]\n",
    "        X_smoking_episode_train,X_smoking_episode_test = X_smoking_episode[train_index], X_smoking_episode[test_index]\n",
    "        y_train,y_test,groups_train,groups_test,time_train,time_test = y[train_index],y[test_index],groups[train_index],groups[test_index],y_time[train_index],y_time[test_index]\n",
    "        \n",
    "        X_feature_val,X_static_val,X_stress_episode_val,X_quit_episode_val,\\\n",
    "        X_activity_episode_val,X_smoking_episode_val,y_val,groups_val,time_val = X_feature[val_index],X_static[val_index],X_stress_episode[val_index],X_quit_episode[val_index],\\\n",
    "                                                                                X_activity_episode[val_index],X_smoking_episode[val_index],y[val_index],groups[val_index],y_time[val_index]\n",
    "        \n",
    "        # y_train = np.array(y_train).reshape(len(y_train),-1)\n",
    "        positive_train_index = np.where(y_train==1)[0]\n",
    "        negative_train_index = np.where(y_train==0)[0]\n",
    "        len_positive = len(positive_train_index)\n",
    "        n_iters = 5\n",
    "        test_preds = []\n",
    "        bias_pred = []\n",
    "        for i,n_iter in enumerate(range(n_iters)):\n",
    "            np.random.seed(np.random.randint(109))\n",
    "            indexes_sampled = np.array(list(positive_train_index)*5+list(np.random.choice(negative_train_index,len_positive*5,replace=False)))\n",
    "            train_feature = X_feature_train[indexes_sampled]\n",
    "            train_static = X_static_train[indexes_sampled]\n",
    "            train_stress = X_stress_episode_train[indexes_sampled]\n",
    "            train_quit = X_quit_episode_train[indexes_sampled]\n",
    "            train_activity = X_activity_episode_train[indexes_sampled]\n",
    "            train_smoking = X_smoking_episode_train[indexes_sampled]\n",
    "            train_y = y_train[indexes_sampled]\n",
    "            from keras import backend as K\n",
    "            K.clear_session()\n",
    "            model = get_model()\n",
    "            # model.summary()\n",
    "\n",
    "            filepath = './models/lag_'+str(n_lag)+'_iter_'+str(n_iter)+'_split_episode_model_v9_new_validation_set_include_smoking_focal_loss_static_coeff_phenotype_lower_model_v5_triplet_no_episode.hdf5'\n",
    "            checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, mode='min',save_weights_only=False)\n",
    "            es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=60)\n",
    "            callbacks_list = [es,checkpoint]\n",
    "            train_feature,val_feature,train_static,val_static,train_stress,val_stress, \\\n",
    "            train_smoking,val_smoking,train_quit,val_quit,train_activity,val_activity, \\\n",
    "            train_y,val_y = train_test_split(\n",
    "                                            train_feature,\n",
    "                                            train_static,\n",
    "                                            train_stress,\n",
    "                                            train_smoking,\n",
    "                                            train_quit,\n",
    "                                            train_activity,\n",
    "                                            train_y,\n",
    "                                            test_size=.15,\n",
    "                                            stratify=train_y\n",
    "                                            )\n",
    "            val_feature = np.concatenate([val_feature,X_feature_val])\n",
    "            val_static = np.concatenate([val_static,X_static_val])\n",
    "            val_stress = np.concatenate([val_stress,X_stress_episode_val])\n",
    "            val_activity = np.concatenate([val_activity,X_activity_episode_val])\n",
    "            val_smoking = np.concatenate([val_smoking,X_smoking_episode_val])\n",
    "            val_quit = np.concatenate([val_quit,X_quit_episode_val])\n",
    "            val_y = np.array(list(val_y)+list(y_val))\n",
    "            \n",
    "            model.fit([train_feature,train_static,train_stress,train_activity,train_smoking,train_quit],train_y,\n",
    "            validation_data=([val_feature,val_static,val_stress,val_activity,val_smoking,val_quit],val_y), epochs=300, batch_size=200,\n",
    "                        verbose=0,callbacks=callbacks_list,shuffle=True)\n",
    "            if os.path.isfile(filepath):\n",
    "                model.load_weights(filepath)\n",
    "            # temp_model = Model(model.input[1],[model.get_layer(c).output for c in columns+amplitude_duration_columns])\n",
    "            # X_static_test_new = np.hstack((X_static_test, np.zeros((X_static_test.shape[0], 3), dtype=X_static_test.dtype)))\n",
    "            # X_static_test_new[:,-3] = np.mean(X_stress_episode_test[:,:,0,1],axis=1)\n",
    "            # X_static_test_new[:,-2] = np.mean(X_stress_episode_test[:,:,0,2],axis=1)\n",
    "            # X_static_test_new[:,-1] = [cluster_dict[a] for a in groups_test]\n",
    "            # X_static_test_new = np.unique(X_static_test_new,axis=0)\n",
    "            # pred_list = list(zip(*[list(a.reshape(-1)) for a in temp_model.predict(X_static_test_new[:,:-3])]))\n",
    "            # for ii,a in enumerate(pred_list):\n",
    "            #     for jj,c_name in enumerate(columns+amplitude_duration_columns):\n",
    "            #         all_data.append([a[jj],\n",
    "            #                         c_name,\n",
    "            #                         X_static_test_new[ii][-1],\n",
    "            #                         a[-2]*X_static_test_new[ii][-3],\n",
    "            #                         a[-1]*X_static_test_new[ii][-2],\n",
    "            #                         n_lag,\n",
    "            #                         kk,\n",
    "            #                         i])\n",
    "\n",
    "            test_preds.append(model.predict([X_feature_test,X_static_test,X_stress_episode_test,\n",
    "                                        X_activity_episode_test,X_smoking_episode_test,X_quit_episode_test])[0][:,1])\n",
    "            bias_pred.append(model.predict([X_feature_val,X_static_val,X_stress_episode_val,X_activity_episode_val,\n",
    "                                            X_smoking_episode_val,X_quit_episode_val])[0][:,1])\n",
    "            \n",
    "        from sklearn.preprocessing import MinMaxScaler\n",
    "        y_test_pred = np.concatenate([a.reshape(-1,1) for a in test_preds],axis=1)\n",
    "        bias_pred = np.concatenate([a.reshape(-1,1) for a in bias_pred],axis=1)\n",
    "        # print(roc_auc_score(y_test,y_test_pred))\n",
    "        final_y_time.extend(list(time_test))\n",
    "        final_probs.extend(list(y_test_pred))\n",
    "        final_y.extend(list(y_test))\n",
    "        final_groups.extend(list(groups_test))\n",
    "        for group_b in np.unique(groups_test):\n",
    "            bias_dict[group_b] = []\n",
    "            for kkk in range(bias_pred.shape[1]):\n",
    "                f1,bias = f1Bias_scorer_CV(bias_pred[:,kkk].reshape(-1),np.int64(y_val.reshape(-1)))\n",
    "                f1_test, bias_test = f1Bias_scorer_CV(y_test_pred[:,kkk],np.int64(y_test.reshape(-1)))\n",
    "                \n",
    "                print(group_b,\n",
    "                'val results',\n",
    "                f1,bias,\n",
    "                'index',kkk,\n",
    "                'test results',\n",
    "                f1_test,bias_test,\n",
    "                'test result with val bias',\n",
    "                f1_score(y_test,np.array(y_test_pred[:,kkk]>bias,dtype=np.int64)))\n",
    "                \n",
    "                bias_dict[group_b].append(bias)\n",
    "            val_results[group_b] = [time_val,bias_pred,y_val,groups_val]\n",
    "        print(len(np.unique(final_groups)))\n",
    "        # print(bias_dict)\n",
    "    final_y_time,final_probs,final_y,final_groups = np.array(final_y_time),np.array(final_probs),np.array(final_y),np.array(final_groups)\n",
    "    pickle.dump([final_y_time,final_probs,final_y,final_groups,bias_dict,val_results],open('./data/output_final/result_no_episode_new_lag_{}_triplet_loss.p'.format(n_lag),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "51b244ab9aca612e739a0539ae1af887c58db9e180d786deb0ab1761def69c1f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('test1': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
