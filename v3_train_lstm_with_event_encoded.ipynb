{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azim/miniconda3/envs/test1/lib/python3.8/site-packages/tensorflow_addons/utils/ensure_tf_install.py:38: UserWarning: You are currently using a nightly version of TensorFlow (2.5.0-dev20210310). \n",
      "TensorFlow Addons offers no support for the nightly versions of TensorFlow. Some things might work, some other might not. \n",
      "If you encounter a bug, do not file an issue on GitHub.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime,timedelta\n",
    "from scipy.stats import iqr,skew,kurtosis,mode\n",
    "from joblib import Parallel,delayed\n",
    "import zipfile\n",
    "import shutil\n",
    "from sklearn.feature_selection import SelectKBest,f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import f1_score,r2_score,classification_report\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,RandomForestRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix,f1_score,precision_score,recall_score,accuracy_score\n",
    "import itertools\n",
    "from sklearn.model_selection import ParameterGrid, cross_val_predict, GroupKFold,GridSearchCV,StratifiedKFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "seed = 100\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from sklearn.model_selection import train_test_split,LeavePGroupsOut\n",
    "from keras.backend import expand_dims, repeat_elements\n",
    "from keras.layers import Lambda\n",
    "from tensorflow.keras.layers import Conv1D,BatchNormalization,Dropout,InputLayer,MaxPooling1D,Flatten,RepeatVector,Dense,Input,Activation,GRU,Bidirectional,LSTM\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow_addons as tfa\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[-1], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y_groups(n_lag=10):\n",
    "    data = pickle.load(open('./data/episode_encoded_lagged_data/episode_encoded_lagged_'+str(n_lag)+'_windows_standardized.p','rb'))\n",
    "\n",
    "    X_feature = np.concatenate(data.feature_final.values)\n",
    "    X_static =  np.concatenate(data.static_features.values)\n",
    "\n",
    "    X_stress_episode = np.concatenate(data.stress_episode.values)\n",
    "    X_quit_episode = np.concatenate(data.quit_episode.values)\n",
    "    X_activity_episode = np.concatenate(data.activity_episode.values)\n",
    "    X_smoking_episode = np.concatenate(data.smoking_episode.values)\n",
    "\n",
    "    y_time = data['time'].values\n",
    "    y = data['label'].values\n",
    "    groups = data['user'].values\n",
    "    \n",
    "    return X_feature,X_static,X_stress_episode,X_quit_episode,X_activity_episode,X_smoking_episode,y_time,y,groups\n",
    "\n",
    "\n",
    "def get_train_test_indexes(groups,n_groups_split = 10,n_val_groups = 5):\n",
    "    groups_unique = np.unique(groups)\n",
    "    groups_split = np.array_split(groups_unique,n_groups_split)\n",
    "    indexes = []\n",
    "    for this_groups in groups_split:\n",
    "        train_groups = np.array([a for a in groups_unique if a not in this_groups])\n",
    "        val_groups = np.random.choice(train_groups,n_val_groups)\n",
    "        train_groups = np.array([a for a in groups_unique if a not in list(this_groups)+list(val_groups)])\n",
    "        test_groups = this_groups\n",
    "        train_index,test_index = np.array([i for i,a in enumerate(groups) \n",
    "                                           if a in train_groups]),np.array([i for i,a in enumerate(groups) \n",
    "                                                                               if a in test_groups])\n",
    "        val_index = np.array([i for i,a in enumerate(groups) \n",
    "                                           if a in val_groups])\n",
    "        indexes.append([train_index,test_index,val_index])\n",
    "    return indexes\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "def f1Bias_scorer_CV(probs, y, ret_bias=True):\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(y, probs)\n",
    "\n",
    "    f1,bias = 0.0,.5\n",
    "    min_recall = .7\n",
    "    for i in range(0, len(thresholds)):\n",
    "        if not (precision[i] == 0 and recall[i] == 0) and recall[i]>min_recall:\n",
    "            f = 2 * (precision[i] * recall[i]) / (precision[i] + recall[i])\n",
    "            if f > f1:\n",
    "                f1 = f\n",
    "                bias = thresholds[i]\n",
    "\n",
    "    if ret_bias:\n",
    "        return f1, bias\n",
    "    else:\n",
    "        return f1\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    n_t,n_f = train_feature.shape[1],train_feature.shape[2]\n",
    "#     print(n_t,n_f)\n",
    "    x_input = Input(shape=(n_t,n_f))\n",
    "    x_feature = Conv1D(100,1,activation='linear')(x_input)\n",
    "    x_feature = Conv1D(100,1,activation='tanh')(x_feature)\n",
    "    x_feature = Dropout(.2)(x_feature)\n",
    "    x_feature = LSTM(20,activation='tanh',return_sequences=False)(x_feature)\n",
    "    x_feature = Dropout(.3)(x_feature)\n",
    "    x_feature = Flatten()(x_feature)\n",
    "    x_feature = Dense(10,activation='relu')(x_feature)\n",
    "    # x_final = Dense(1,activation='sigmoid')(x_feature)\n",
    "\n",
    "    n_sf = train_static.shape[1]\n",
    "    x_input_static = Input(shape=(n_sf))\n",
    "    x_static = Dense(100,activation='relu')(x_input_static)\n",
    "    x_static = Dense(10,activation='relu')(x_static)\n",
    "    n_timesteps = train_stress.shape[-2]\n",
    "    n_episodes_stress,n_episodes_quit,n_episodes_activity,n_episodes_smoking = train_stress.shape[1],train_quit.shape[1],train_activity.shape[1],train_smoking.shape[1]\n",
    "    x_alpha_stress = Dense(1,activation='sigmoid')(x_static)\n",
    "    x_alpha_stress = RepeatVector(n_timesteps)(x_alpha_stress)\n",
    "    x_alpha_stress = Lambda(lambda x: repeat_elements(expand_dims(x, axis=1), n_episodes_stress, 1))(x_alpha_stress)\n",
    "    x_alpha_quit = Dense(1,activation='sigmoid')(x_static)\n",
    "    x_alpha_quit = RepeatVector(n_timesteps)(x_alpha_quit)\n",
    "    x_alpha_quit = Lambda(lambda x: repeat_elements(expand_dims(x, axis=1), n_episodes_quit, 1))(x_alpha_quit)\n",
    "    x_alpha_activity = Dense(1,activation='sigmoid')(x_static)\n",
    "    x_alpha_activity = RepeatVector(n_timesteps)(x_alpha_activity)\n",
    "    x_alpha_activity = Lambda(lambda x: repeat_elements(expand_dims(x, axis=1), n_episodes_activity, 1))(x_alpha_activity)\n",
    "    x_alpha_smoking = Dense(1,activation='sigmoid')(x_static)\n",
    "    x_alpha_smoking = RepeatVector(n_timesteps)(x_alpha_smoking)\n",
    "    x_alpha_smoking = Lambda(lambda x: repeat_elements(expand_dims(x, axis=1), n_episodes_smoking, 1))(x_alpha_smoking)\n",
    "\n",
    "    n_dim = 3\n",
    "    x_stress = Input(shape=(n_episodes_stress,n_timesteps,n_dim))\n",
    "    stress_alpha_time = tf.math.multiply(x_alpha_stress[:,:,:,0]*-1,x_stress[:,:,:,0])\n",
    "    stress_alpha_time_exp = tf.math.exp(stress_alpha_time)\n",
    "\n",
    "    x_stress_amplitude = x_stress[:,:,:,1]\n",
    "    stress_amplitude_coeff = Dense(1,activation='sigmoid')(x_feature)\n",
    "    stress_amplitude_coeff = Lambda(lambda x: expand_dims(x, axis=2))(stress_amplitude_coeff)\n",
    "    print(stress_amplitude_coeff.shape,'coeff',x_stress_amplitude.shape,'amplitude')\n",
    "    x_stress_amplitude = tf.math.multiply(x_stress_amplitude,stress_amplitude_coeff)\n",
    "#     print(x_stress_amplitude.shape,'final')\n",
    "    \n",
    "    x_stress_duration = x_stress[:,:,:,2]\n",
    "    stress_duration_coeff = Dense(1,activation='sigmoid')(x_feature)\n",
    "    stress_duration_coeff = Lambda(lambda x: expand_dims(x, axis=2))(stress_duration_coeff)\n",
    "    x_stress_duration = tf.math.multiply(x_stress_duration,stress_duration_coeff)\n",
    "    \n",
    "    x_stress_all = tf.math.add(x_stress_amplitude,x_stress_duration)\n",
    "    \n",
    "#     print(x_stress_all.shape,stress_alpha_time_exp.shape)\n",
    "    stress_alpha_time_exp_amplitude = tf.math.multiply(stress_alpha_time_exp,x_stress_all)\n",
    "    \n",
    "#     print(stress_alpha_time_exp_amplitude.shape)\n",
    "    stress_final = tf.math.reduce_sum(stress_alpha_time_exp_amplitude,axis=1)\n",
    "#     print(stress_final.shape)\n",
    "    stress_final = Lambda(lambda x: expand_dims(x, axis=2))(stress_final)\n",
    "#     print(stress_final.shape)\n",
    "    stress_final = LSTM(10,activation='tanh',return_sequences=True)(stress_final)\n",
    "    \n",
    "    \n",
    "    \n",
    "    x_quit = Input(shape=(n_episodes_quit,n_timesteps,n_dim))\n",
    "#     quit_alpha_time = tf.math.multiply(x_alpha_quit[:,:,:,0]*-1,x_quit[:,:,:,0])\n",
    "#     quit_alpha_time_exp = tf.math.exp(quit_alpha_time)\n",
    "#     quit_alpha_time_exp_amplitude = tf.math.multiply(quit_alpha_time_exp,x_quit[:,:,:,1])\n",
    "#     quit_final = tf.math.reduce_sum(quit_alpha_time_exp_amplitude,axis=1)\n",
    "#     quit_final = Lambda(lambda x: expand_dims(x, axis=2))(quit_final)\n",
    "#     quit_final = LSTM(5,activation='tanh',return_sequences=True)(quit_final)\n",
    "\n",
    "    \n",
    "    \n",
    "    x_smoking = Input(shape=(n_episodes_smoking,n_timesteps,n_dim))\n",
    "    smoking_alpha_time = tf.math.multiply(x_alpha_smoking[:,:,:,0]*-1,x_smoking[:,:,:,0])\n",
    "    smoking_alpha_time_exp = tf.math.exp(smoking_alpha_time)\n",
    "    \n",
    "    x_smoking_amplitude = x_smoking[:,:,:,1]\n",
    "    smoking_amplitude_coeff = Dense(1,activation='sigmoid')(x_feature)\n",
    "    smoking_amplitude_coeff = Lambda(lambda x: expand_dims(x, axis=2))(smoking_amplitude_coeff)\n",
    "    x_smoking_amplitude = tf.math.multiply(x_smoking_amplitude,smoking_amplitude_coeff)\n",
    "    \n",
    "    x_smoking_duration = x_smoking[:,:,:,2]\n",
    "    smoking_duration_coeff = Dense(1,activation='sigmoid')(x_feature)\n",
    "    smoking_duration_coeff = Lambda(lambda x: expand_dims(x, axis=2))(smoking_duration_coeff)\n",
    "    x_smoking_duration = tf.math.multiply(x_smoking_duration,smoking_duration_coeff)\n",
    "    \n",
    "    x_smoking_all = tf.math.add(x_smoking_amplitude,x_smoking_duration)\n",
    "    smoking_alpha_time_exp_amplitude = tf.math.multiply(smoking_alpha_time_exp,x_smoking_all)\n",
    "    smoking_final = tf.math.reduce_sum(smoking_alpha_time_exp_amplitude,axis=1)\n",
    "    smoking_final = Lambda(lambda x: expand_dims(x, axis=2))(smoking_final)\n",
    "    smoking_final = LSTM(10,activation='tanh',return_sequences=True)(smoking_final)\n",
    "\n",
    "    \n",
    "    \n",
    "    x_activity = Input(shape=(n_episodes_activity,n_timesteps,n_dim))\n",
    "    activity_alpha_time = tf.math.multiply(x_alpha_activity[:,:,:,0]*-1,x_activity[:,:,:,0])\n",
    "    activity_alpha_time_exp = tf.math.exp(activity_alpha_time)\n",
    "    \n",
    "    x_activity_amplitude = x_activity[:,:,:,1]\n",
    "    activity_amplitude_coeff = Dense(1,activation='sigmoid')(x_feature)\n",
    "    activity_amplitude_coeff = Lambda(lambda x: expand_dims(x, axis=2))(activity_amplitude_coeff)\n",
    "    x_activity_amplitude = tf.math.multiply(x_activity_amplitude,activity_amplitude_coeff)\n",
    "    \n",
    "    x_activity_duration = x_activity[:,:,:,2]\n",
    "    activity_duration_coeff = Dense(1,activation='sigmoid')(x_feature)\n",
    "    activity_duration_coeff = Lambda(lambda x: expand_dims(x, axis=2))(activity_duration_coeff)\n",
    "#     print(activity_duration_coeff)\n",
    "    x_activity_duration = tf.math.multiply(x_activity_duration,activity_duration_coeff)\n",
    "    \n",
    "    x_activity_all = tf.math.add(x_activity_amplitude,x_activity_duration)\n",
    "    activity_alpha_time_exp_amplitude = tf.math.multiply(activity_alpha_time_exp,x_activity_all)\n",
    "    activity_final = tf.math.reduce_sum(activity_alpha_time_exp_amplitude,axis=1)\n",
    "    activity_final = Lambda(lambda x: expand_dims(x, axis=2))(activity_final)\n",
    "    activity_final = LSTM(10,activation='tanh',return_sequences=True)(activity_final)\n",
    "    \n",
    "    \n",
    "    x_episode = tf.concat([activity_final,stress_final,smoking_final],2)\n",
    "    x_episode = Conv1D(100,10,activation='relu')(x_episode)\n",
    "    x_episode = Conv1D(100,10,activation='tanh')(x_episode)\n",
    "    x_episode = LSTM(100,activation='tanh',return_sequences=True)(x_episode)\n",
    "    x_episode = LSTM(20,activation='tanh',return_sequences=False)(x_episode)\n",
    "    x_episode = Dropout(.3)(x_episode)\n",
    "    x_episode = Flatten()(x_episode)\n",
    "    x_episode = Dense(10,activation='relu')(x_episode)\n",
    "\n",
    "    merged = tf.concat([x_feature,x_episode],1)\n",
    "\n",
    "    merged = Dense(10,activation='relu')(merged)\n",
    "    output = Dense(1,activation='sigmoid')(merged)\n",
    "    # output = Activation('softmax',name='softmax')(output)\n",
    "    model = Model(inputs=[x_input,x_input_static,x_stress,x_activity,x_smoking,x_quit], outputs=[output])\n",
    "    model.compile(loss=myloss(.1),metrics=['acc',tfa.metrics.F1Score(num_classes=2,average='micro',threshold=.5)])\n",
    "    return model\n",
    "# tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "def myloss(alpha=.2):\n",
    "    \n",
    "    def custom_loss(true,pred):\n",
    "        m = tf.keras.losses.BinaryCrossentropy()\n",
    "        return f1_loss(true,pred)+m(true,pred)*alpha\n",
    "    \n",
    "    \n",
    "    def f1_weighted(true, pred): #shapes (batch, 4)\n",
    "\n",
    "        #for metrics include these two lines, for loss, don't include them\n",
    "        #these are meant to round 'pred' to exactly zeros and ones\n",
    "        #predLabels = K.argmax(pred, axis=-1)\n",
    "        #pred = K.one_hot(predLabels, 4) \n",
    "\n",
    "\n",
    "        ground_positives = K.sum(true, axis=0) + K.epsilon()       # = TP + FN\n",
    "        pred_positives = K.sum(pred, axis=0) + K.epsilon()         # = TP + FP\n",
    "        true_positives = K.sum(true * pred, axis=0) + K.epsilon()  # = TP\n",
    "            #all with shape (4,)\n",
    "\n",
    "        precision = true_positives / pred_positives \n",
    "        recall = true_positives / ground_positives\n",
    "            #both = 1 if ground_positives == 0 or pred_positives == 0\n",
    "            #shape (4,)\n",
    "\n",
    "        f1 = 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
    "            #still with shape (4,)\n",
    "        # print(f1)\n",
    "        # weighted_f1 = f1 * ground_positives / K.sum(ground_positives) \n",
    "        weighted_f1 = K.sum(f1)\n",
    "\n",
    "\n",
    "        return 1 - weighted_f1\n",
    "\n",
    "    def f1_loss(y_true, y_pred):\n",
    "    \n",
    "        tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "        tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "        fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "        fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "        p = tp / (tp + fp + K.epsilon())\n",
    "        r = tp / (tp + fn + K.epsilon())\n",
    "        fpr = fp/(fp+tn+K.epsilon())\n",
    "        f1 = 2*p*r / (p+r+K.epsilon())\n",
    "        # f1 = tf.where(tf(f1), tf.zeros_like(f1), f1)\n",
    "        return 1-K.mean(f1)\n",
    "    return custom_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 5s 36ms/step - loss: 0.0234 - acc: 0.9966 - f1_score: 0.9814 - val_loss: 1.0354 - val_acc: 0.9332 - val_f1_score: 0.1645\n",
      "\n",
      "Epoch 00049: val_f1_score did not improve from 0.25439\n",
      "Epoch 50/300\n",
      "151/151 [==============================] - 6s 37ms/step - loss: 0.0186 - acc: 0.9971 - f1_score: 0.9846 - val_loss: 1.0755 - val_acc: 0.9024 - val_f1_score: 0.0784\n",
      "\n",
      "Epoch 00050: val_f1_score did not improve from 0.25439\n",
      "Epoch 51/300\n",
      "151/151 [==============================] - 5s 36ms/step - loss: 0.0223 - acc: 0.9965 - f1_score: 0.9808 - val_loss: 1.0411 - val_acc: 0.9252 - val_f1_score: 0.1429\n",
      "\n",
      "Epoch 00051: val_f1_score did not improve from 0.25439\n",
      "Epoch 52/300\n",
      "151/151 [==============================] - 5s 36ms/step - loss: 0.0152 - acc: 0.9978 - f1_score: 0.9876 - val_loss: 1.0529 - val_acc: 0.9096 - val_f1_score: 0.1608\n",
      "\n",
      "Epoch 00052: val_f1_score did not improve from 0.25439\n",
      "Epoch 53/300\n",
      "151/151 [==============================] - 6s 37ms/step - loss: 0.0253 - acc: 0.9964 - f1_score: 0.9796 - val_loss: 1.0225 - val_acc: 0.9339 - val_f1_score: 0.1941\n",
      "\n",
      "Epoch 00053: val_f1_score did not improve from 0.25439\n",
      "Epoch 54/300\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.0171 - acc: 0.9973 - f1_score: 0.9855 - val_loss: 1.0682 - val_acc: 0.9103 - val_f1_score: 0.0783\n",
      "\n",
      "Epoch 00054: val_f1_score did not improve from 0.25439\n",
      "Epoch 55/300\n",
      "151/151 [==============================] - 7s 44ms/step - loss: 0.0177 - acc: 0.9974 - f1_score: 0.9859 - val_loss: 1.0820 - val_acc: 0.9186 - val_f1_score: 0.0562\n",
      "\n",
      "Epoch 00055: val_f1_score did not improve from 0.25439\n",
      "Epoch 56/300\n",
      "151/151 [==============================] - 7s 44ms/step - loss: 0.0180 - acc: 0.9972 - f1_score: 0.9847 - val_loss: 1.0607 - val_acc: 0.9100 - val_f1_score: 0.1503\n",
      "\n",
      "Epoch 00056: val_f1_score did not improve from 0.25439\n",
      "Epoch 57/300\n",
      "151/151 [==============================] - 7s 44ms/step - loss: 0.0130 - acc: 0.9978 - f1_score: 0.9881 - val_loss: 1.0660 - val_acc: 0.9148 - val_f1_score: 0.1087\n",
      "\n",
      "Epoch 00057: val_f1_score did not improve from 0.25439\n",
      "Epoch 58/300\n",
      "151/151 [==============================] - 6s 37ms/step - loss: 0.0170 - acc: 0.9974 - f1_score: 0.9857 - val_loss: 1.0621 - val_acc: 0.9217 - val_f1_score: 0.0960\n",
      "\n",
      "Epoch 00058: val_f1_score did not improve from 0.25439\n",
      "Epoch 59/300\n",
      "151/151 [==============================] - 6s 39ms/step - loss: 0.0183 - acc: 0.9972 - f1_score: 0.9846 - val_loss: 1.0432 - val_acc: 0.9048 - val_f1_score: 0.1641\n",
      "\n",
      "Epoch 00059: val_f1_score did not improve from 0.25439\n",
      "Epoch 60/300\n",
      "151/151 [==============================] - 7s 44ms/step - loss: 0.0165 - acc: 0.9975 - f1_score: 0.9865 - val_loss: 1.0667 - val_acc: 0.9269 - val_f1_score: 0.0944\n",
      "\n",
      "Epoch 00060: val_f1_score did not improve from 0.25439\n",
      "Epoch 61/300\n",
      "151/151 [==============================] - 6s 42ms/step - loss: 0.0137 - acc: 0.9980 - f1_score: 0.9893 - val_loss: 1.0590 - val_acc: 0.9207 - val_f1_score: 0.1158\n",
      "\n",
      "Epoch 00061: val_f1_score did not improve from 0.25439\n",
      "Epoch 62/300\n",
      "151/151 [==============================] - 6s 37ms/step - loss: 0.0137 - acc: 0.9980 - f1_score: 0.9889 - val_loss: 1.0707 - val_acc: 0.9235 - val_f1_score: 0.0753\n",
      "\n",
      "Epoch 00062: val_f1_score did not improve from 0.25439\n",
      "Epoch 63/300\n",
      "151/151 [==============================] - 7s 43ms/step - loss: 0.0182 - acc: 0.9972 - f1_score: 0.9845 - val_loss: 1.0707 - val_acc: 0.9200 - val_f1_score: 0.0723\n",
      "\n",
      "Epoch 00063: val_f1_score did not improve from 0.25439\n",
      "Epoch 64/300\n",
      "151/151 [==============================] - 7s 44ms/step - loss: 0.0152 - acc: 0.9977 - f1_score: 0.9869 - val_loss: 1.0901 - val_acc: 0.9089 - val_f1_score: 0.0505\n",
      "\n",
      "Epoch 00064: val_f1_score did not improve from 0.25439\n",
      "Epoch 65/300\n",
      "151/151 [==============================] - 6s 38ms/step - loss: 0.0182 - acc: 0.9974 - f1_score: 0.9859 - val_loss: 1.0991 - val_acc: 0.9262 - val_f1_score: 0.0093\n",
      "\n",
      "Epoch 00065: val_f1_score did not improve from 0.25439\n",
      "Epoch 66/300\n",
      "151/151 [==============================] - 6s 36ms/step - loss: 0.0199 - acc: 0.9972 - f1_score: 0.9839 - val_loss: 1.0346 - val_acc: 0.9280 - val_f1_score: 0.1811\n",
      "\n",
      "Epoch 00066: val_f1_score did not improve from 0.25439\n",
      "Epoch 67/300\n",
      "151/151 [==============================] - 5s 36ms/step - loss: 0.0157 - acc: 0.9974 - f1_score: 0.9857 - val_loss: 1.0729 - val_acc: 0.9176 - val_f1_score: 0.0630\n",
      "\n",
      "Epoch 00067: val_f1_score did not improve from 0.25439\n",
      "Epoch 68/300\n",
      "151/151 [==============================] - 6s 40ms/step - loss: 0.0183 - acc: 0.9973 - f1_score: 0.9856 - val_loss: 1.0793 - val_acc: 0.9124 - val_f1_score: 0.0595\n",
      "\n",
      "Epoch 00068: val_f1_score did not improve from 0.25439\n",
      "Epoch 69/300\n",
      "151/151 [==============================] - 6s 43ms/step - loss: 0.0117 - acc: 0.9982 - f1_score: 0.9900 - val_loss: 1.0712 - val_acc: 0.9231 - val_f1_score: 0.0826\n",
      "\n",
      "Epoch 00069: val_f1_score did not improve from 0.25439\n",
      "Epoch 70/300\n",
      "151/151 [==============================] - 6s 42ms/step - loss: 0.0116 - acc: 0.9983 - f1_score: 0.9903 - val_loss: 1.0906 - val_acc: 0.9048 - val_f1_score: 0.0550\n",
      "\n",
      "Epoch 00070: val_f1_score did not improve from 0.25439\n",
      "Epoch 71/300\n",
      "151/151 [==============================] - 6s 37ms/step - loss: 0.0156 - acc: 0.9977 - f1_score: 0.9871 - val_loss: 0.9807 - val_acc: 0.9335 - val_f1_score: 0.2381\n",
      "\n",
      "Epoch 00071: val_f1_score did not improve from 0.25439\n",
      "Epoch 72/300\n",
      "151/151 [==============================] - 6s 42ms/step - loss: 0.0128 - acc: 0.9982 - f1_score: 0.9896 - val_loss: 1.0592 - val_acc: 0.9217 - val_f1_score: 0.1102\n",
      "\n",
      "Epoch 00072: val_f1_score did not improve from 0.25439\n",
      "Epoch 73/300\n",
      "151/151 [==============================] - 7s 43ms/step - loss: 0.0161 - acc: 0.9975 - f1_score: 0.9862 - val_loss: 1.0208 - val_acc: 0.9131 - val_f1_score: 0.1492\n",
      "\n",
      "Epoch 00073: val_f1_score did not improve from 0.25439\n",
      "Epoch 74/300\n",
      "151/151 [==============================] - 6s 38ms/step - loss: 0.0150 - acc: 0.9976 - f1_score: 0.9867 - val_loss: 1.0299 - val_acc: 0.9311 - val_f1_score: 0.1811\n",
      "\n",
      "Epoch 00074: val_f1_score did not improve from 0.25439\n",
      "Epoch 75/300\n",
      "151/151 [==============================] - 6s 42ms/step - loss: 0.0169 - acc: 0.9975 - f1_score: 0.9862 - val_loss: 1.0382 - val_acc: 0.9273 - val_f1_score: 0.1532\n",
      "\n",
      "Epoch 00075: val_f1_score did not improve from 0.25439\n",
      "Epoch 00075: early stopping\n",
      "(0.1583793738489871, 5.204162e-10)\n",
      "(0.14609929078014186, 2.0310384e-07)\n",
      "0.7020635372640708\n",
      "1330 (18781,)\n",
      "29260\n",
      "(None, 1, 1) coeff (None, 5, 30) amplitude\n",
      "Epoch 1/300\n",
      "147/147 [==============================] - 14s 47ms/step - loss: 0.8221 - acc: 0.8693 - f1_score: 0.2859 - val_loss: 0.9899 - val_acc: 0.8472 - val_f1_score: 0.1091\n",
      "\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.10909, saving model to ./models/lag_15_iter_0_split_4_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_10-100_f1_no_fpr_test.hdf5\n",
      "Epoch 2/300\n",
      "147/147 [==============================] - 6s 43ms/step - loss: 0.3324 - acc: 0.9561 - f1_score: 0.7532 - val_loss: 1.0923 - val_acc: 0.8659 - val_f1_score: 0.0359\n",
      "\n",
      "Epoch 00002: val_f1_score did not improve from 0.10909\n",
      "Epoch 3/300\n",
      "147/147 [==============================] - 6s 42ms/step - loss: 0.1892 - acc: 0.9737 - f1_score: 0.8504 - val_loss: 1.0214 - val_acc: 0.8621 - val_f1_score: 0.1597\n",
      "\n",
      "Epoch 00003: val_f1_score improved from 0.10909 to 0.15970, saving model to ./models/lag_15_iter_0_split_4_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_10-100_f1_no_fpr_test.hdf5\n",
      "Epoch 4/300\n",
      "147/147 [==============================] - 6s 42ms/step - loss: 0.1478 - acc: 0.9785 - f1_score: 0.8777 - val_loss: 1.0622 - val_acc: 0.8802 - val_f1_score: 0.1351\n",
      "\n",
      "Epoch 00004: val_f1_score did not improve from 0.15970\n",
      "Epoch 5/300\n",
      "147/147 [==============================] - 6s 40ms/step - loss: 0.0994 - acc: 0.9852 - f1_score: 0.9184 - val_loss: 1.0019 - val_acc: 0.8752 - val_f1_score: 0.1870\n",
      "\n",
      "Epoch 00005: val_f1_score improved from 0.15970 to 0.18699, saving model to ./models/lag_15_iter_0_split_4_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_10-100_f1_no_fpr_test.hdf5\n",
      "Epoch 6/300\n",
      "147/147 [==============================] - 6s 39ms/step - loss: 0.1015 - acc: 0.9853 - f1_score: 0.9179 - val_loss: 1.0963 - val_acc: 0.8415 - val_f1_score: 0.0662\n",
      "\n",
      "Epoch 00006: val_f1_score did not improve from 0.18699\n",
      "Epoch 7/300\n",
      "147/147 [==============================] - 6s 44ms/step - loss: 0.0894 - acc: 0.9866 - f1_score: 0.9238 - val_loss: 1.0013 - val_acc: 0.8746 - val_f1_score: 0.1992\n",
      "\n",
      "Epoch 00007: val_f1_score improved from 0.18699 to 0.19920, saving model to ./models/lag_15_iter_0_split_4_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_10-100_f1_no_fpr_test.hdf5\n",
      "Epoch 8/300\n",
      "147/147 [==============================] - 6s 41ms/step - loss: 0.0791 - acc: 0.9884 - f1_score: 0.9340 - val_loss: 1.0800 - val_acc: 0.8671 - val_f1_score: 0.0858\n",
      "\n",
      "Epoch 00008: val_f1_score did not improve from 0.19920\n",
      "Epoch 9/300\n",
      "147/147 [==============================] - 5s 37ms/step - loss: 0.0631 - acc: 0.9903 - f1_score: 0.9462 - val_loss: 0.9736 - val_acc: 0.8403 - val_f1_score: 0.2471\n",
      "\n",
      "Epoch 00009: val_f1_score improved from 0.19920 to 0.24706, saving model to ./models/lag_15_iter_0_split_4_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_10-100_f1_no_fpr_test.hdf5\n",
      "Epoch 10/300\n",
      "147/147 [==============================] - 6s 42ms/step - loss: 0.0717 - acc: 0.9896 - f1_score: 0.9395 - val_loss: 1.1212 - val_acc: 0.8646 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00010: val_f1_score did not improve from 0.24706\n",
      "Epoch 11/300\n",
      "147/147 [==============================] - 6s 44ms/step - loss: 0.0567 - acc: 0.9918 - f1_score: 0.9531 - val_loss: 1.1095 - val_acc: 0.8565 - val_f1_score: 0.0800\n",
      "\n",
      "Epoch 00011: val_f1_score did not improve from 0.24706\n",
      "Epoch 12/300\n",
      "147/147 [==============================] - 6s 43ms/step - loss: 0.0548 - acc: 0.9921 - f1_score: 0.9564 - val_loss: 1.1507 - val_acc: 0.8621 - val_f1_score: 0.0264\n",
      "\n",
      "Epoch 00012: val_f1_score did not improve from 0.24706\n",
      "Epoch 13/300\n",
      "147/147 [==============================] - 6s 44ms/step - loss: 0.0547 - acc: 0.9914 - f1_score: 0.9523 - val_loss: 1.0689 - val_acc: 0.8565 - val_f1_score: 0.1727\n",
      "\n",
      "Epoch 00013: val_f1_score did not improve from 0.24706\n",
      "Epoch 14/300\n",
      "147/147 [==============================] - 6s 42ms/step - loss: 0.0407 - acc: 0.9941 - f1_score: 0.9680 - val_loss: 1.0006 - val_acc: 0.8933 - val_f1_score: 0.2400\n",
      "\n",
      "Epoch 00014: val_f1_score did not improve from 0.24706\n",
      "Epoch 15/300\n",
      "147/147 [==============================] - 6s 44ms/step - loss: 0.0370 - acc: 0.9944 - f1_score: 0.9689 - val_loss: 1.0247 - val_acc: 0.8571 - val_f1_score: 0.1908\n",
      "\n",
      "Epoch 00015: val_f1_score did not improve from 0.24706\n",
      "Epoch 16/300\n",
      "147/147 [==============================] - 6s 44ms/step - loss: 0.0366 - acc: 0.9947 - f1_score: 0.9716 - val_loss: 1.0803 - val_acc: 0.8690 - val_f1_score: 0.1393\n",
      "\n",
      "Epoch 00016: val_f1_score did not improve from 0.24706\n",
      "Epoch 17/300\n",
      "147/147 [==============================] - 6s 44ms/step - loss: 0.0343 - acc: 0.9946 - f1_score: 0.9698 - val_loss: 1.1267 - val_acc: 0.8540 - val_f1_score: 0.0787\n",
      "\n",
      "Epoch 00017: val_f1_score did not improve from 0.24706\n",
      "Epoch 18/300\n",
      "147/147 [==============================] - 6s 44ms/step - loss: 0.0362 - acc: 0.9947 - f1_score: 0.9710 - val_loss: 1.1123 - val_acc: 0.8677 - val_f1_score: 0.0783\n",
      "\n",
      "Epoch 00018: val_f1_score did not improve from 0.24706\n",
      "Epoch 19/300\n",
      "147/147 [==============================] - 6s 44ms/step - loss: 0.0337 - acc: 0.9951 - f1_score: 0.9730 - val_loss: 1.0637 - val_acc: 0.8472 - val_f1_score: 0.1695\n",
      "\n",
      "Epoch 00019: val_f1_score did not improve from 0.24706\n",
      "Epoch 20/300\n",
      "147/147 [==============================] - 6s 40ms/step - loss: 0.0312 - acc: 0.9952 - f1_score: 0.9733 - val_loss: 1.0501 - val_acc: 0.8596 - val_f1_score: 0.1818\n",
      "\n",
      "Epoch 00020: val_f1_score did not improve from 0.24706\n",
      "Epoch 21/300\n",
      "147/147 [==============================] - 5s 36ms/step - loss: 0.0281 - acc: 0.9958 - f1_score: 0.9768 - val_loss: 1.1073 - val_acc: 0.8465 - val_f1_score: 0.1022\n",
      "\n",
      "Epoch 00021: val_f1_score did not improve from 0.24706\n",
      "Epoch 22/300\n",
      "147/147 [==============================] - 5s 37ms/step - loss: 0.0287 - acc: 0.9958 - f1_score: 0.9771 - val_loss: 1.1049 - val_acc: 0.8740 - val_f1_score: 0.0982\n",
      "\n",
      "Epoch 00022: val_f1_score did not improve from 0.24706\n",
      "Epoch 23/300\n",
      "147/147 [==============================] - 6s 41ms/step - loss: 0.0322 - acc: 0.9952 - f1_score: 0.9729 - val_loss: 1.1342 - val_acc: 0.8391 - val_f1_score: 0.0979\n",
      "\n",
      "Epoch 00023: val_f1_score did not improve from 0.24706\n",
      "Epoch 24/300\n",
      "147/147 [==============================] - 5s 37ms/step - loss: 0.0338 - acc: 0.9951 - f1_score: 0.9727 - val_loss: 1.1013 - val_acc: 0.8684 - val_f1_score: 0.1172\n",
      "\n",
      "Epoch 00024: val_f1_score did not improve from 0.24706\n",
      "Epoch 25/300\n",
      "147/147 [==============================] - 6s 41ms/step - loss: 0.0321 - acc: 0.9951 - f1_score: 0.9728 - val_loss: 1.0945 - val_acc: 0.8871 - val_f1_score: 0.1084\n",
      "\n",
      "Epoch 00025: val_f1_score did not improve from 0.24706\n",
      "Epoch 26/300\n",
      "147/147 [==============================] - 6s 38ms/step - loss: 0.0285 - acc: 0.9957 - f1_score: 0.9767 - val_loss: 1.0996 - val_acc: 0.8615 - val_f1_score: 0.1260\n",
      "\n",
      "Epoch 00026: val_f1_score did not improve from 0.24706\n",
      "Epoch 27/300\n",
      "147/147 [==============================] - 6s 40ms/step - loss: 0.0270 - acc: 0.9957 - f1_score: 0.9762 - val_loss: 1.1207 - val_acc: 0.8584 - val_f1_score: 0.0956\n",
      "\n",
      "Epoch 00027: val_f1_score did not improve from 0.24706\n",
      "Epoch 28/300\n",
      "147/147 [==============================] - 6s 42ms/step - loss: 0.0361 - acc: 0.9942 - f1_score: 0.9685 - val_loss: 1.1022 - val_acc: 0.8759 - val_f1_score: 0.1156\n",
      "\n",
      "Epoch 00028: val_f1_score did not improve from 0.24706\n",
      "Epoch 29/300\n",
      "147/147 [==============================] - 5s 37ms/step - loss: 0.0251 - acc: 0.9963 - f1_score: 0.9793 - val_loss: 1.1062 - val_acc: 0.8696 - val_f1_score: 0.1030\n",
      "\n",
      "Epoch 00029: val_f1_score did not improve from 0.24706\n",
      "Epoch 30/300\n",
      "147/147 [==============================] - 6s 42ms/step - loss: 0.0287 - acc: 0.9953 - f1_score: 0.9744 - val_loss: 1.1479 - val_acc: 0.8827 - val_f1_score: 0.0208\n",
      "\n",
      "Epoch 00030: val_f1_score did not improve from 0.24706\n",
      "Epoch 31/300\n",
      "147/147 [==============================] - 6s 44ms/step - loss: 0.0253 - acc: 0.9962 - f1_score: 0.9789 - val_loss: 1.0401 - val_acc: 0.8771 - val_f1_score: 0.1826\n",
      "\n",
      "Epoch 00031: val_f1_score did not improve from 0.24706\n",
      "Epoch 32/300\n",
      "147/147 [==============================] - 6s 44ms/step - loss: 0.0250 - acc: 0.9961 - f1_score: 0.9784 - val_loss: 1.0839 - val_acc: 0.8790 - val_f1_score: 0.1261\n",
      "\n",
      "Epoch 00032: val_f1_score did not improve from 0.24706\n",
      "Epoch 33/300\n",
      "147/147 [==============================] - 6s 44ms/step - loss: 0.0200 - acc: 0.9970 - f1_score: 0.9838 - val_loss: 1.0499 - val_acc: 0.8665 - val_f1_score: 0.1894\n",
      "\n",
      "Epoch 00033: val_f1_score did not improve from 0.24706\n",
      "Epoch 34/300\n",
      "147/147 [==============================] - 6s 43ms/step - loss: 0.0201 - acc: 0.9970 - f1_score: 0.9838 - val_loss: 1.0658 - val_acc: 0.8646 - val_f1_score: 0.1556\n",
      "\n",
      "Epoch 00034: val_f1_score did not improve from 0.24706\n",
      "Epoch 35/300\n",
      "147/147 [==============================] - 6s 44ms/step - loss: 0.0221 - acc: 0.9966 - f1_score: 0.9806 - val_loss: 1.1604 - val_acc: 0.8478 - val_f1_score: 0.0469\n",
      "\n",
      "Epoch 00035: val_f1_score did not improve from 0.24706\n",
      "Epoch 36/300\n",
      "147/147 [==============================] - 6s 43ms/step - loss: 0.0184 - acc: 0.9971 - f1_score: 0.9841 - val_loss: 1.1204 - val_acc: 0.8646 - val_f1_score: 0.0996\n",
      "\n",
      "Epoch 00036: val_f1_score did not improve from 0.24706\n",
      "Epoch 37/300\n",
      "147/147 [==============================] - 6s 43ms/step - loss: 0.0216 - acc: 0.9969 - f1_score: 0.9824 - val_loss: 1.0412 - val_acc: 0.8746 - val_f1_score: 0.1590\n",
      "\n",
      "Epoch 00037: val_f1_score did not improve from 0.24706\n",
      "Epoch 38/300\n",
      "147/147 [==============================] - 6s 44ms/step - loss: 0.0212 - acc: 0.9966 - f1_score: 0.9813 - val_loss: 1.1311 - val_acc: 0.8540 - val_f1_score: 0.0787\n",
      "\n",
      "Epoch 00038: val_f1_score did not improve from 0.24706\n",
      "Epoch 39/300\n",
      "147/147 [==============================] - 6s 44ms/step - loss: 0.0175 - acc: 0.9974 - f1_score: 0.9854 - val_loss: 1.1357 - val_acc: 0.8677 - val_f1_score: 0.0275\n",
      "\n",
      "Epoch 00039: val_f1_score did not improve from 0.24706\n",
      "Epoch 40/300\n",
      "147/147 [==============================] - 6s 43ms/step - loss: 0.0289 - acc: 0.9955 - f1_score: 0.9753 - val_loss: 1.1284 - val_acc: 0.8478 - val_f1_score: 0.0687\n",
      "\n",
      "Epoch 00040: val_f1_score did not improve from 0.24706\n",
      "Epoch 41/300\n",
      "147/147 [==============================] - 6s 44ms/step - loss: 0.0147 - acc: 0.9978 - f1_score: 0.9885 - val_loss: 1.1130 - val_acc: 0.8609 - val_f1_score: 0.0898\n",
      "\n",
      "Epoch 00041: val_f1_score did not improve from 0.24706\n",
      "Epoch 42/300\n",
      "147/147 [==============================] - 6s 44ms/step - loss: 0.0227 - acc: 0.9968 - f1_score: 0.9821 - val_loss: 1.1380 - val_acc: 0.8509 - val_f1_score: 0.0402\n",
      "\n",
      "Epoch 00042: val_f1_score did not improve from 0.24706\n",
      "Epoch 43/300\n",
      "147/147 [==============================] - 6s 44ms/step - loss: 0.0224 - acc: 0.9967 - f1_score: 0.9815 - val_loss: 1.1739 - val_acc: 0.8584 - val_f1_score: 0.0173\n",
      "\n",
      "Epoch 00043: val_f1_score did not improve from 0.24706\n",
      "Epoch 44/300\n",
      "147/147 [==============================] - 6s 42ms/step - loss: 0.0204 - acc: 0.9970 - f1_score: 0.9834 - val_loss: 1.1213 - val_acc: 0.8509 - val_f1_score: 0.0843\n",
      "\n",
      "Epoch 00044: val_f1_score did not improve from 0.24706\n",
      "Epoch 45/300\n",
      "147/147 [==============================] - 6s 43ms/step - loss: 0.0133 - acc: 0.9979 - f1_score: 0.9883 - val_loss: 1.1103 - val_acc: 0.8677 - val_f1_score: 0.1167\n",
      "\n",
      "Epoch 00045: val_f1_score did not improve from 0.24706\n",
      "Epoch 46/300\n",
      "147/147 [==============================] - 6s 43ms/step - loss: 0.0186 - acc: 0.9971 - f1_score: 0.9840 - val_loss: 1.1092 - val_acc: 0.8659 - val_f1_score: 0.1004\n",
      "\n",
      "Epoch 00046: val_f1_score did not improve from 0.24706\n",
      "Epoch 47/300\n",
      "147/147 [==============================] - 6s 44ms/step - loss: 0.0188 - acc: 0.9971 - f1_score: 0.9839 - val_loss: 1.1113 - val_acc: 0.8715 - val_f1_score: 0.1197\n",
      "\n",
      "Epoch 00047: val_f1_score did not improve from 0.24706\n",
      "Epoch 48/300\n",
      "147/147 [==============================] - 6s 44ms/step - loss: 0.0217 - acc: 0.9966 - f1_score: 0.9814 - val_loss: 1.1389 - val_acc: 0.8696 - val_f1_score: 0.0952\n",
      "\n",
      "Epoch 00048: val_f1_score did not improve from 0.24706\n",
      "Epoch 49/300\n",
      "147/147 [==============================] - 6s 44ms/step - loss: 0.0207 - acc: 0.9965 - f1_score: 0.9812 - val_loss: 1.1416 - val_acc: 0.8640 - val_f1_score: 0.0763\n",
      "\n",
      "Epoch 00049: val_f1_score did not improve from 0.24706\n",
      "Epoch 00049: early stopping\n",
      "(0.2676767676767677, 9.332015e-07)\n",
      "(0.28074534161490683, 2.17385e-06)\n",
      "0.6995072406336955\n",
      "1315 (15741,)\n",
      "28930\n",
      "(None, 1, 1) coeff (None, 5, 30) amplitude\n",
      "Epoch 1/300\n",
      "145/145 [==============================] - 15s 56ms/step - loss: 0.7975 - acc: 0.8110 - f1_score: 0.2874 - val_loss: 0.9957 - val_acc: 0.9381 - val_f1_score: 0.1244\n",
      "\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.12440, saving model to ./models/lag_15_iter_0_split_5_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_10-100_f1_no_fpr_test.hdf5\n",
      "Epoch 2/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.4385 - acc: 0.9459 - f1_score: 0.6443 - val_loss: 1.0384 - val_acc: 0.9334 - val_f1_score: 0.0199\n",
      "\n",
      "Epoch 00002: val_f1_score did not improve from 0.12440\n",
      "Epoch 3/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.2958 - acc: 0.9613 - f1_score: 0.7523 - val_loss: 1.0043 - val_acc: 0.9290 - val_f1_score: 0.1985\n",
      "\n",
      "Epoch 00003: val_f1_score improved from 0.12440 to 0.19847, saving model to ./models/lag_15_iter_0_split_5_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_10-100_f1_no_fpr_test.hdf5\n",
      "Epoch 4/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.2445 - acc: 0.9664 - f1_score: 0.7929 - val_loss: 1.0190 - val_acc: 0.9249 - val_f1_score: 0.1654\n",
      "\n",
      "Epoch 00004: val_f1_score did not improve from 0.19847\n",
      "Epoch 5/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.2068 - acc: 0.9723 - f1_score: 0.8295 - val_loss: 1.0374 - val_acc: 0.8965 - val_f1_score: 0.1000\n",
      "\n",
      "Epoch 00005: val_f1_score did not improve from 0.19847\n",
      "Epoch 6/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.1568 - acc: 0.9768 - f1_score: 0.8679 - val_loss: 1.0656 - val_acc: 0.8921 - val_f1_score: 0.0590\n",
      "\n",
      "Epoch 00006: val_f1_score did not improve from 0.19847\n",
      "Epoch 7/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.1266 - acc: 0.9818 - f1_score: 0.8954 - val_loss: 1.0457 - val_acc: 0.9094 - val_f1_score: 0.0884\n",
      "\n",
      "Epoch 00007: val_f1_score did not improve from 0.19847\n",
      "Epoch 8/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.1030 - acc: 0.9844 - f1_score: 0.9143 - val_loss: 1.0284 - val_acc: 0.9138 - val_f1_score: 0.1528\n",
      "\n",
      "Epoch 00008: val_f1_score did not improve from 0.19847\n",
      "Epoch 9/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.1012 - acc: 0.9851 - f1_score: 0.9146 - val_loss: 1.0362 - val_acc: 0.9097 - val_f1_score: 0.1470\n",
      "\n",
      "Epoch 00009: val_f1_score did not improve from 0.19847\n",
      "Epoch 10/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0826 - acc: 0.9878 - f1_score: 0.9300 - val_loss: 1.0570 - val_acc: 0.9046 - val_f1_score: 0.0962\n",
      "\n",
      "Epoch 00010: val_f1_score did not improve from 0.19847\n",
      "Epoch 11/300\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.0818 - acc: 0.9883 - f1_score: 0.9330 - val_loss: 1.0495 - val_acc: 0.9117 - val_f1_score: 0.0969\n",
      "\n",
      "Epoch 00011: val_f1_score did not improve from 0.19847\n",
      "Epoch 12/300\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.0826 - acc: 0.9876 - f1_score: 0.9307 - val_loss: 1.0547 - val_acc: 0.8887 - val_f1_score: 0.1410\n",
      "\n",
      "Epoch 00012: val_f1_score did not improve from 0.19847\n",
      "Epoch 13/300\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 0.0665 - acc: 0.9898 - f1_score: 0.9428 - val_loss: 1.0560 - val_acc: 0.8941 - val_f1_score: 0.1828\n",
      "\n",
      "Epoch 00013: val_f1_score did not improve from 0.19847\n",
      "Epoch 14/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0570 - acc: 0.9915 - f1_score: 0.9532 - val_loss: 1.0565 - val_acc: 0.9094 - val_f1_score: 0.0946\n",
      "\n",
      "Epoch 00014: val_f1_score did not improve from 0.19847\n",
      "Epoch 15/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0628 - acc: 0.9904 - f1_score: 0.9461 - val_loss: 1.0311 - val_acc: 0.9053 - val_f1_score: 0.1617\n",
      "\n",
      "Epoch 00015: val_f1_score did not improve from 0.19847\n",
      "Epoch 16/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0539 - acc: 0.9916 - f1_score: 0.9539 - val_loss: 1.0885 - val_acc: 0.8979 - val_f1_score: 0.0258\n",
      "\n",
      "Epoch 00016: val_f1_score did not improve from 0.19847\n",
      "Epoch 17/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0499 - acc: 0.9924 - f1_score: 0.9571 - val_loss: 1.0300 - val_acc: 0.9249 - val_f1_score: 0.2014\n",
      "\n",
      "Epoch 00017: val_f1_score improved from 0.19847 to 0.20144, saving model to ./models/lag_15_iter_0_split_5_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_10-100_f1_no_fpr_test.hdf5\n",
      "Epoch 18/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0418 - acc: 0.9935 - f1_score: 0.9636 - val_loss: 1.0390 - val_acc: 0.9016 - val_f1_score: 0.1803\n",
      "\n",
      "Epoch 00018: val_f1_score did not improve from 0.20144\n",
      "Epoch 19/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0573 - acc: 0.9911 - f1_score: 0.9501 - val_loss: 1.0622 - val_acc: 0.9151 - val_f1_score: 0.0738\n",
      "\n",
      "Epoch 00019: val_f1_score did not improve from 0.20144\n",
      "Epoch 20/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0480 - acc: 0.9924 - f1_score: 0.9579 - val_loss: 1.0643 - val_acc: 0.9226 - val_f1_score: 0.0803\n",
      "\n",
      "Epoch 00020: val_f1_score did not improve from 0.20144\n",
      "Epoch 21/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0369 - acc: 0.9943 - f1_score: 0.9679 - val_loss: 1.0512 - val_acc: 0.8975 - val_f1_score: 0.1607\n",
      "\n",
      "Epoch 00021: val_f1_score did not improve from 0.20144\n",
      "Epoch 22/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0395 - acc: 0.9939 - f1_score: 0.9666 - val_loss: 1.0343 - val_acc: 0.8728 - val_f1_score: 0.1681\n",
      "\n",
      "Epoch 00022: val_f1_score did not improve from 0.20144\n",
      "Epoch 23/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0331 - acc: 0.9951 - f1_score: 0.9732 - val_loss: 1.0664 - val_acc: 0.9124 - val_f1_score: 0.1338\n",
      "\n",
      "Epoch 00023: val_f1_score did not improve from 0.20144\n",
      "Epoch 24/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0328 - acc: 0.9952 - f1_score: 0.9737 - val_loss: 1.0618 - val_acc: 0.9182 - val_f1_score: 0.1168\n",
      "\n",
      "Epoch 00024: val_f1_score did not improve from 0.20144\n",
      "Epoch 25/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0334 - acc: 0.9950 - f1_score: 0.9729 - val_loss: 1.0746 - val_acc: 0.8925 - val_f1_score: 0.1117\n",
      "\n",
      "Epoch 00025: val_f1_score did not improve from 0.20144\n",
      "Epoch 26/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0287 - acc: 0.9956 - f1_score: 0.9765 - val_loss: 1.0982 - val_acc: 0.8843 - val_f1_score: 0.0707\n",
      "\n",
      "Epoch 00026: val_f1_score did not improve from 0.20144\n",
      "Epoch 27/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0283 - acc: 0.9953 - f1_score: 0.9745 - val_loss: 1.0750 - val_acc: 0.9222 - val_f1_score: 0.0726\n",
      "\n",
      "Epoch 00027: val_f1_score did not improve from 0.20144\n",
      "Epoch 28/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0266 - acc: 0.9959 - f1_score: 0.9772 - val_loss: 1.0813 - val_acc: 0.8891 - val_f1_score: 0.0889\n",
      "\n",
      "Epoch 00028: val_f1_score did not improve from 0.20144\n",
      "Epoch 29/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0264 - acc: 0.9958 - f1_score: 0.9763 - val_loss: 1.1079 - val_acc: 0.9023 - val_f1_score: 0.0137\n",
      "\n",
      "Epoch 00029: val_f1_score did not improve from 0.20144\n",
      "Epoch 30/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0252 - acc: 0.9962 - f1_score: 0.9789 - val_loss: 1.1069 - val_acc: 0.8904 - val_f1_score: 0.0414\n",
      "\n",
      "Epoch 00030: val_f1_score did not improve from 0.20144\n",
      "Epoch 31/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0252 - acc: 0.9961 - f1_score: 0.9778 - val_loss: 1.0800 - val_acc: 0.9060 - val_f1_score: 0.0544\n",
      "\n",
      "Epoch 00031: val_f1_score did not improve from 0.20144\n",
      "Epoch 32/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0316 - acc: 0.9953 - f1_score: 0.9740 - val_loss: 1.0783 - val_acc: 0.8958 - val_f1_score: 0.1047\n",
      "\n",
      "Epoch 00032: val_f1_score did not improve from 0.20144\n",
      "Epoch 33/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0265 - acc: 0.9958 - f1_score: 0.9765 - val_loss: 1.0706 - val_acc: 0.9080 - val_f1_score: 0.1338\n",
      "\n",
      "Epoch 00033: val_f1_score did not improve from 0.20144\n",
      "Epoch 34/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0263 - acc: 0.9958 - f1_score: 0.9773 - val_loss: 1.0872 - val_acc: 0.9050 - val_f1_score: 0.0602\n",
      "\n",
      "Epoch 00034: val_f1_score did not improve from 0.20144\n",
      "Epoch 35/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0284 - acc: 0.9956 - f1_score: 0.9755 - val_loss: 1.0837 - val_acc: 0.9097 - val_f1_score: 0.0498\n",
      "\n",
      "Epoch 00035: val_f1_score did not improve from 0.20144\n",
      "Epoch 36/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.0190 - acc: 0.9969 - f1_score: 0.9828 - val_loss: 1.0979 - val_acc: 0.9094 - val_f1_score: 0.0147\n",
      "\n",
      "Epoch 00036: val_f1_score did not improve from 0.20144\n",
      "Epoch 37/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0214 - acc: 0.9967 - f1_score: 0.9821 - val_loss: 1.0801 - val_acc: 0.9050 - val_f1_score: 0.1136\n",
      "\n",
      "Epoch 00037: val_f1_score did not improve from 0.20144\n",
      "Epoch 38/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0200 - acc: 0.9969 - f1_score: 0.9830 - val_loss: 1.1003 - val_acc: 0.8874 - val_f1_score: 0.1351\n",
      "\n",
      "Epoch 00038: val_f1_score did not improve from 0.20144\n",
      "Epoch 39/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0249 - acc: 0.9964 - f1_score: 0.9795 - val_loss: 1.1193 - val_acc: 0.9050 - val_f1_score: 0.0071\n",
      "\n",
      "Epoch 00039: val_f1_score did not improve from 0.20144\n",
      "Epoch 40/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0192 - acc: 0.9968 - f1_score: 0.9822 - val_loss: 1.0635 - val_acc: 0.9215 - val_f1_score: 0.1145\n",
      "\n",
      "Epoch 00040: val_f1_score did not improve from 0.20144\n",
      "Epoch 41/300\n",
      "145/145 [==============================] - 5s 36ms/step - loss: 0.0214 - acc: 0.9966 - f1_score: 0.9817 - val_loss: 1.0624 - val_acc: 0.9215 - val_f1_score: 0.1471\n",
      "\n",
      "Epoch 00041: val_f1_score did not improve from 0.20144\n",
      "Epoch 42/300\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.0189 - acc: 0.9970 - f1_score: 0.9834 - val_loss: 1.0398 - val_acc: 0.9222 - val_f1_score: 0.2014\n",
      "\n",
      "Epoch 00042: val_f1_score did not improve from 0.20144\n",
      "Epoch 43/300\n",
      "145/145 [==============================] - 6s 41ms/step - loss: 0.0261 - acc: 0.9957 - f1_score: 0.9763 - val_loss: 1.0704 - val_acc: 0.9131 - val_f1_score: 0.0982\n",
      "\n",
      "Epoch 00043: val_f1_score did not improve from 0.20144\n",
      "Epoch 44/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0204 - acc: 0.9968 - f1_score: 0.9826 - val_loss: 1.0825 - val_acc: 0.9249 - val_f1_score: 0.0672\n",
      "\n",
      "Epoch 00044: val_f1_score did not improve from 0.20144\n",
      "Epoch 45/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0117 - acc: 0.9981 - f1_score: 0.9894 - val_loss: 1.0675 - val_acc: 0.9199 - val_f1_score: 0.1190\n",
      "\n",
      "Epoch 00045: val_f1_score did not improve from 0.20144\n",
      "Epoch 46/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0184 - acc: 0.9971 - f1_score: 0.9839 - val_loss: 1.0242 - val_acc: 0.9161 - val_f1_score: 0.2201\n",
      "\n",
      "Epoch 00046: val_f1_score improved from 0.20144 to 0.22013, saving model to ./models/lag_15_iter_0_split_5_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_10-100_f1_no_fpr_test.hdf5\n",
      "Epoch 47/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0196 - acc: 0.9969 - f1_score: 0.9832 - val_loss: 1.0636 - val_acc: 0.9080 - val_f1_score: 0.1500\n",
      "\n",
      "Epoch 00047: val_f1_score did not improve from 0.22013\n",
      "Epoch 48/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0191 - acc: 0.9969 - f1_score: 0.9834 - val_loss: 1.0754 - val_acc: 0.8931 - val_f1_score: 0.1459\n",
      "\n",
      "Epoch 00048: val_f1_score did not improve from 0.22013\n",
      "Epoch 49/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0149 - acc: 0.9978 - f1_score: 0.9878 - val_loss: 1.0574 - val_acc: 0.9080 - val_f1_score: 0.1656\n",
      "\n",
      "Epoch 00049: val_f1_score did not improve from 0.22013\n",
      "Epoch 50/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0154 - acc: 0.9976 - f1_score: 0.9863 - val_loss: 1.0537 - val_acc: 0.9087 - val_f1_score: 0.1818\n",
      "\n",
      "Epoch 00050: val_f1_score did not improve from 0.22013\n",
      "Epoch 51/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0154 - acc: 0.9974 - f1_score: 0.9858 - val_loss: 1.0743 - val_acc: 0.9202 - val_f1_score: 0.1449\n",
      "\n",
      "Epoch 00051: val_f1_score did not improve from 0.22013\n",
      "Epoch 52/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0162 - acc: 0.9976 - f1_score: 0.9861 - val_loss: 1.0445 - val_acc: 0.9080 - val_f1_score: 0.1807\n",
      "\n",
      "Epoch 00052: val_f1_score did not improve from 0.22013\n",
      "Epoch 53/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0223 - acc: 0.9965 - f1_score: 0.9812 - val_loss: 1.0489 - val_acc: 0.9097 - val_f1_score: 0.1734\n",
      "\n",
      "Epoch 00053: val_f1_score did not improve from 0.22013\n",
      "Epoch 54/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0206 - acc: 0.9968 - f1_score: 0.9827 - val_loss: 1.0586 - val_acc: 0.9182 - val_f1_score: 0.1418\n",
      "\n",
      "Epoch 00054: val_f1_score did not improve from 0.22013\n",
      "Epoch 55/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0136 - acc: 0.9978 - f1_score: 0.9880 - val_loss: 1.0360 - val_acc: 0.9107 - val_f1_score: 0.1801\n",
      "\n",
      "Epoch 00055: val_f1_score did not improve from 0.22013\n",
      "Epoch 56/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0137 - acc: 0.9980 - f1_score: 0.9893 - val_loss: 1.0507 - val_acc: 0.9175 - val_f1_score: 0.1348\n",
      "\n",
      "Epoch 00056: val_f1_score did not improve from 0.22013\n",
      "Epoch 57/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0134 - acc: 0.9978 - f1_score: 0.9881 - val_loss: 1.0723 - val_acc: 0.9215 - val_f1_score: 0.0938\n",
      "\n",
      "Epoch 00057: val_f1_score did not improve from 0.22013\n",
      "Epoch 58/300\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 0.0115 - acc: 0.9983 - f1_score: 0.9908 - val_loss: 1.0778 - val_acc: 0.9276 - val_f1_score: 0.0614\n",
      "\n",
      "Epoch 00058: val_f1_score did not improve from 0.22013\n",
      "Epoch 59/300\n",
      "145/145 [==============================] - 5s 36ms/step - loss: 0.0180 - acc: 0.9970 - f1_score: 0.9836 - val_loss: 1.0935 - val_acc: 0.9273 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00059: val_f1_score did not improve from 0.22013\n",
      "Epoch 60/300\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.0181 - acc: 0.9974 - f1_score: 0.9852 - val_loss: 1.0982 - val_acc: 0.8979 - val_f1_score: 0.0443\n",
      "\n",
      "Epoch 00060: val_f1_score did not improve from 0.22013\n",
      "Epoch 61/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0122 - acc: 0.9981 - f1_score: 0.9898 - val_loss: 1.1050 - val_acc: 0.9212 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00061: val_f1_score did not improve from 0.22013\n",
      "Epoch 62/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0106 - acc: 0.9985 - f1_score: 0.9916 - val_loss: 1.0937 - val_acc: 0.8881 - val_f1_score: 0.1078\n",
      "\n",
      "Epoch 00062: val_f1_score did not improve from 0.22013\n",
      "Epoch 63/300\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 0.0164 - acc: 0.9971 - f1_score: 0.9848 - val_loss: 1.0889 - val_acc: 0.8884 - val_f1_score: 0.1081\n",
      "\n",
      "Epoch 00063: val_f1_score did not improve from 0.22013\n",
      "Epoch 64/300\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.0132 - acc: 0.9979 - f1_score: 0.9885 - val_loss: 1.1055 - val_acc: 0.9114 - val_f1_score: 0.0150\n",
      "\n",
      "Epoch 00064: val_f1_score did not improve from 0.22013\n",
      "Epoch 65/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0113 - acc: 0.9983 - f1_score: 0.9910 - val_loss: 1.0875 - val_acc: 0.8999 - val_f1_score: 0.0976\n",
      "\n",
      "Epoch 00065: val_f1_score did not improve from 0.22013\n",
      "Epoch 66/300\n",
      "145/145 [==============================] - 6s 41ms/step - loss: 0.0175 - acc: 0.9972 - f1_score: 0.9849 - val_loss: 1.1335 - val_acc: 0.8928 - val_f1_score: 0.0063\n",
      "\n",
      "Epoch 00066: val_f1_score did not improve from 0.22013\n",
      "Epoch 67/300\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.0119 - acc: 0.9980 - f1_score: 0.9895 - val_loss: 1.1050 - val_acc: 0.9229 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00067: val_f1_score did not improve from 0.22013\n",
      "Epoch 68/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0185 - acc: 0.9971 - f1_score: 0.9839 - val_loss: 1.0801 - val_acc: 0.9040 - val_f1_score: 0.0719\n",
      "\n",
      "Epoch 00068: val_f1_score did not improve from 0.22013\n",
      "Epoch 69/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0081 - acc: 0.9988 - f1_score: 0.9932 - val_loss: 1.1006 - val_acc: 0.9124 - val_f1_score: 0.0372\n",
      "\n",
      "Epoch 00069: val_f1_score did not improve from 0.22013\n",
      "Epoch 70/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0126 - acc: 0.9979 - f1_score: 0.9887 - val_loss: 1.0836 - val_acc: 0.9060 - val_f1_score: 0.1258\n",
      "\n",
      "Epoch 00070: val_f1_score did not improve from 0.22013\n",
      "Epoch 71/300\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.0144 - acc: 0.9977 - f1_score: 0.9872 - val_loss: 1.1103 - val_acc: 0.9185 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00071: val_f1_score did not improve from 0.22013\n",
      "Epoch 72/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0143 - acc: 0.9979 - f1_score: 0.9884 - val_loss: 1.1334 - val_acc: 0.8850 - val_f1_score: 0.0173\n",
      "\n",
      "Epoch 00072: val_f1_score did not improve from 0.22013\n",
      "Epoch 73/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0135 - acc: 0.9977 - f1_score: 0.9876 - val_loss: 1.1111 - val_acc: 0.8945 - val_f1_score: 0.0488\n",
      "\n",
      "Epoch 00073: val_f1_score did not improve from 0.22013\n",
      "Epoch 74/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0129 - acc: 0.9981 - f1_score: 0.9895 - val_loss: 1.0890 - val_acc: 0.9006 - val_f1_score: 0.0926\n",
      "\n",
      "Epoch 00074: val_f1_score did not improve from 0.22013\n",
      "Epoch 75/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0124 - acc: 0.9981 - f1_score: 0.9897 - val_loss: 1.1181 - val_acc: 0.8854 - val_f1_score: 0.0451\n",
      "\n",
      "Epoch 00075: val_f1_score did not improve from 0.22013\n",
      "Epoch 76/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0150 - acc: 0.9976 - f1_score: 0.9863 - val_loss: 1.1048 - val_acc: 0.9155 - val_f1_score: 0.0310\n",
      "\n",
      "Epoch 00076: val_f1_score did not improve from 0.22013\n",
      "Epoch 77/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0117 - acc: 0.9982 - f1_score: 0.9902 - val_loss: 1.1199 - val_acc: 0.9100 - val_f1_score: 0.0221\n",
      "\n",
      "Epoch 00077: val_f1_score did not improve from 0.22013\n",
      "Epoch 78/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0104 - acc: 0.9984 - f1_score: 0.9913 - val_loss: 1.1316 - val_acc: 0.9050 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00078: val_f1_score did not improve from 0.22013\n",
      "Epoch 79/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0096 - acc: 0.9984 - f1_score: 0.9911 - val_loss: 1.1152 - val_acc: 0.9023 - val_f1_score: 0.0269\n",
      "\n",
      "Epoch 00079: val_f1_score did not improve from 0.22013\n",
      "Epoch 80/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0088 - acc: 0.9987 - f1_score: 0.9923 - val_loss: 1.1104 - val_acc: 0.9050 - val_f1_score: 0.0277\n",
      "\n",
      "Epoch 00080: val_f1_score did not improve from 0.22013\n",
      "Epoch 81/300\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 0.0131 - acc: 0.9980 - f1_score: 0.9888 - val_loss: 1.0892 - val_acc: 0.9077 - val_f1_score: 0.0683\n",
      "\n",
      "Epoch 00081: val_f1_score did not improve from 0.22013\n",
      "Epoch 82/300\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 0.0116 - acc: 0.9981 - f1_score: 0.9889 - val_loss: 1.0867 - val_acc: 0.9073 - val_f1_score: 0.1046\n",
      "\n",
      "Epoch 00082: val_f1_score did not improve from 0.22013\n",
      "Epoch 83/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0116 - acc: 0.9982 - f1_score: 0.9901 - val_loss: 1.1040 - val_acc: 0.9097 - val_f1_score: 0.0291\n",
      "\n",
      "Epoch 00083: val_f1_score did not improve from 0.22013\n",
      "Epoch 84/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0122 - acc: 0.9980 - f1_score: 0.9890 - val_loss: 1.1128 - val_acc: 0.9205 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00084: val_f1_score did not improve from 0.22013\n",
      "Epoch 85/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.0113 - acc: 0.9981 - f1_score: 0.9896 - val_loss: 1.0819 - val_acc: 0.9100 - val_f1_score: 0.1014\n",
      "\n",
      "Epoch 00085: val_f1_score did not improve from 0.22013\n",
      "Epoch 86/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0114 - acc: 0.9981 - f1_score: 0.9892 - val_loss: 1.1127 - val_acc: 0.9148 - val_f1_score: 0.0156\n",
      "\n",
      "Epoch 00086: val_f1_score did not improve from 0.22013\n",
      "Epoch 00086: early stopping\n",
      "(0.135632183908046, 7.3434666e-07)\n",
      "(0.10881174899866489, 3.1255077e-08)\n",
      "0.4933248723162254\n",
      "1317 (18931,)\n",
      "28974\n",
      "(None, 1, 1) coeff (None, 5, 30) amplitude\n",
      "Epoch 1/300\n",
      "145/145 [==============================] - 15s 53ms/step - loss: 0.7967 - acc: 0.8490 - f1_score: 0.2977 - val_loss: 1.0254 - val_acc: 0.8619 - val_f1_score: 0.0905\n",
      "\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.09045, saving model to ./models/lag_15_iter_0_split_6_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_10-100_f1_no_fpr_test.hdf5\n",
      "Epoch 2/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.3812 - acc: 0.9442 - f1_score: 0.6873 - val_loss: 1.1330 - val_acc: 0.8734 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_f1_score did not improve from 0.09045\n",
      "Epoch 3/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.1846 - acc: 0.9735 - f1_score: 0.8513 - val_loss: 1.1664 - val_acc: 0.8482 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_f1_score did not improve from 0.09045\n",
      "Epoch 4/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.1573 - acc: 0.9775 - f1_score: 0.8690 - val_loss: 1.0566 - val_acc: 0.8726 - val_f1_score: 0.1692\n",
      "\n",
      "Epoch 00004: val_f1_score improved from 0.09045 to 0.16915, saving model to ./models/lag_15_iter_0_split_6_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_10-100_f1_no_fpr_test.hdf5\n",
      "Epoch 5/300\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.1328 - acc: 0.9794 - f1_score: 0.8854 - val_loss: 1.1720 - val_acc: 0.8635 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_f1_score did not improve from 0.16915\n",
      "Epoch 6/300\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 0.1089 - acc: 0.9843 - f1_score: 0.9113 - val_loss: 1.1755 - val_acc: 0.8520 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_f1_score did not improve from 0.16915\n",
      "Epoch 7/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.1116 - acc: 0.9844 - f1_score: 0.9104 - val_loss: 1.1572 - val_acc: 0.8398 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00007: val_f1_score did not improve from 0.16915\n",
      "Epoch 8/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0971 - acc: 0.9862 - f1_score: 0.9204 - val_loss: 1.1607 - val_acc: 0.8581 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00008: val_f1_score did not improve from 0.16915\n",
      "Epoch 9/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0767 - acc: 0.9884 - f1_score: 0.9364 - val_loss: 1.1748 - val_acc: 0.8558 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00009: val_f1_score did not improve from 0.16915\n",
      "Epoch 10/300\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 0.0952 - acc: 0.9861 - f1_score: 0.9184 - val_loss: 1.1861 - val_acc: 0.8642 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00010: val_f1_score did not improve from 0.16915\n",
      "Epoch 11/300\n",
      "145/145 [==============================] - 5s 36ms/step - loss: 0.0720 - acc: 0.9891 - f1_score: 0.9395 - val_loss: 1.1753 - val_acc: 0.8192 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00011: val_f1_score did not improve from 0.16915\n",
      "Epoch 12/300\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.0820 - acc: 0.9872 - f1_score: 0.9278 - val_loss: 1.1614 - val_acc: 0.8635 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00012: val_f1_score did not improve from 0.16915\n",
      "Epoch 13/300\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 0.0732 - acc: 0.9889 - f1_score: 0.9397 - val_loss: 1.1559 - val_acc: 0.8703 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00013: val_f1_score did not improve from 0.16915\n",
      "Epoch 14/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0568 - acc: 0.9911 - f1_score: 0.9515 - val_loss: 1.1857 - val_acc: 0.8513 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00014: val_f1_score did not improve from 0.16915\n",
      "Epoch 15/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0458 - acc: 0.9930 - f1_score: 0.9618 - val_loss: 1.1759 - val_acc: 0.8497 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00015: val_f1_score did not improve from 0.16915\n",
      "Epoch 16/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0485 - acc: 0.9923 - f1_score: 0.9558 - val_loss: 1.1686 - val_acc: 0.8551 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00016: val_f1_score did not improve from 0.16915\n",
      "Epoch 17/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0461 - acc: 0.9928 - f1_score: 0.9597 - val_loss: 1.1771 - val_acc: 0.8528 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00017: val_f1_score did not improve from 0.16915\n",
      "Epoch 18/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0468 - acc: 0.9931 - f1_score: 0.9620 - val_loss: 1.1763 - val_acc: 0.8619 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00018: val_f1_score did not improve from 0.16915\n",
      "Epoch 19/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0488 - acc: 0.9924 - f1_score: 0.9580 - val_loss: 1.1887 - val_acc: 0.8604 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00019: val_f1_score did not improve from 0.16915\n",
      "Epoch 20/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0418 - acc: 0.9935 - f1_score: 0.9638 - val_loss: 1.1923 - val_acc: 0.8543 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00020: val_f1_score did not improve from 0.16915\n",
      "Epoch 21/300\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 0.0324 - acc: 0.9949 - f1_score: 0.9722 - val_loss: 1.1732 - val_acc: 0.8619 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00021: val_f1_score did not improve from 0.16915\n",
      "Epoch 22/300\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.0411 - acc: 0.9935 - f1_score: 0.9641 - val_loss: 1.1708 - val_acc: 0.8596 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00022: val_f1_score did not improve from 0.16915\n",
      "Epoch 23/300\n",
      "145/145 [==============================] - 5s 36ms/step - loss: 0.0324 - acc: 0.9950 - f1_score: 0.9730 - val_loss: 1.1760 - val_acc: 0.8703 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00023: val_f1_score did not improve from 0.16915\n",
      "Epoch 24/300\n",
      "145/145 [==============================] - 5s 33ms/step - loss: 0.0393 - acc: 0.9942 - f1_score: 0.9668 - val_loss: 1.1268 - val_acc: 0.8711 - val_f1_score: 0.0559\n",
      "\n",
      "Epoch 00024: val_f1_score did not improve from 0.16915\n",
      "Epoch 25/300\n",
      "145/145 [==============================] - 4s 30ms/step - loss: 0.0303 - acc: 0.9953 - f1_score: 0.9744 - val_loss: 1.1931 - val_acc: 0.8368 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00025: val_f1_score did not improve from 0.16915\n",
      "Epoch 26/300\n",
      "145/145 [==============================] - 4s 27ms/step - loss: 0.0370 - acc: 0.9944 - f1_score: 0.9689 - val_loss: 1.1925 - val_acc: 0.8520 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00026: val_f1_score did not improve from 0.16915\n",
      "Epoch 27/300\n",
      "145/145 [==============================] - 4s 27ms/step - loss: 0.0314 - acc: 0.9949 - f1_score: 0.9724 - val_loss: 1.1781 - val_acc: 0.8627 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00027: val_f1_score did not improve from 0.16915\n",
      "Epoch 28/300\n",
      "145/145 [==============================] - 4s 27ms/step - loss: 0.0266 - acc: 0.9960 - f1_score: 0.9778 - val_loss: 1.1847 - val_acc: 0.8635 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00028: val_f1_score did not improve from 0.16915\n",
      "Epoch 29/300\n",
      "145/145 [==============================] - 4s 28ms/step - loss: 0.0406 - acc: 0.9938 - f1_score: 0.9649 - val_loss: 1.1952 - val_acc: 0.8589 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00029: val_f1_score did not improve from 0.16915\n",
      "Epoch 30/300\n",
      "145/145 [==============================] - 5s 32ms/step - loss: 0.0262 - acc: 0.9961 - f1_score: 0.9783 - val_loss: 1.1418 - val_acc: 0.8795 - val_f1_score: 0.0366\n",
      "\n",
      "Epoch 00030: val_f1_score did not improve from 0.16915\n",
      "Epoch 31/300\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.0267 - acc: 0.9958 - f1_score: 0.9768 - val_loss: 1.1962 - val_acc: 0.8490 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00031: val_f1_score did not improve from 0.16915\n",
      "Epoch 32/300\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.0311 - acc: 0.9955 - f1_score: 0.9744 - val_loss: 1.1857 - val_acc: 0.8673 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00032: val_f1_score did not improve from 0.16915\n",
      "Epoch 33/300\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.0245 - acc: 0.9961 - f1_score: 0.9787 - val_loss: 1.1869 - val_acc: 0.8696 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00033: val_f1_score did not improve from 0.16915\n",
      "Epoch 34/300\n",
      "145/145 [==============================] - 6s 41ms/step - loss: 0.0268 - acc: 0.9957 - f1_score: 0.9763 - val_loss: 1.2012 - val_acc: 0.8566 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00034: val_f1_score did not improve from 0.16915\n",
      "Epoch 35/300\n",
      "145/145 [==============================] - 5s 36ms/step - loss: 0.0290 - acc: 0.9953 - f1_score: 0.9742 - val_loss: 1.1754 - val_acc: 0.8741 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00035: val_f1_score did not improve from 0.16915\n",
      "Epoch 36/300\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.0262 - acc: 0.9958 - f1_score: 0.9771 - val_loss: 1.1797 - val_acc: 0.8642 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00036: val_f1_score did not improve from 0.16915\n",
      "Epoch 37/300\n",
      "145/145 [==============================] - 6s 41ms/step - loss: 0.0315 - acc: 0.9953 - f1_score: 0.9741 - val_loss: 1.1771 - val_acc: 0.8680 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00037: val_f1_score did not improve from 0.16915\n",
      "Epoch 38/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0174 - acc: 0.9975 - f1_score: 0.9861 - val_loss: 1.1847 - val_acc: 0.8688 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00038: val_f1_score did not improve from 0.16915\n",
      "Epoch 39/300\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.0216 - acc: 0.9966 - f1_score: 0.9813 - val_loss: 1.1954 - val_acc: 0.8635 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00039: val_f1_score did not improve from 0.16915\n",
      "Epoch 40/300\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.0241 - acc: 0.9963 - f1_score: 0.9794 - val_loss: 1.2035 - val_acc: 0.8543 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00040: val_f1_score did not improve from 0.16915\n",
      "Epoch 41/300\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.0195 - acc: 0.9969 - f1_score: 0.9831 - val_loss: 1.1850 - val_acc: 0.8589 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00041: val_f1_score did not improve from 0.16915\n",
      "Epoch 42/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0272 - acc: 0.9960 - f1_score: 0.9775 - val_loss: 1.2041 - val_acc: 0.8574 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00042: val_f1_score did not improve from 0.16915\n",
      "Epoch 43/300\n",
      "145/145 [==============================] - 6s 41ms/step - loss: 0.0197 - acc: 0.9973 - f1_score: 0.9849 - val_loss: 1.1420 - val_acc: 0.8558 - val_f1_score: 0.1043\n",
      "\n",
      "Epoch 00043: val_f1_score did not improve from 0.16915\n",
      "Epoch 44/300\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 0.0209 - acc: 0.9966 - f1_score: 0.9818 - val_loss: 1.2037 - val_acc: 0.8619 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00044: val_f1_score did not improve from 0.16915\n",
      "Epoch 00044: early stopping\n",
      "(0.18918918918918917, 0.0)\n",
      "(0.2322863403944485, 1.0695893e-07)\n",
      "0.4630839859573319\n",
      "1314 (19394,)\n",
      "28908\n",
      "(None, 1, 1) coeff (None, 5, 30) amplitude\n",
      "Epoch 1/300\n",
      "145/145 [==============================] - 15s 53ms/step - loss: 0.8316 - acc: 0.8569 - f1_score: 0.2434 - val_loss: 0.9041 - val_acc: 0.8331 - val_f1_score: 0.2510\n",
      "\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.25095, saving model to ./models/lag_15_iter_0_split_7_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_10-100_f1_no_fpr_test.hdf5\n",
      "Epoch 2/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.4626 - acc: 0.9421 - f1_score: 0.6034 - val_loss: 1.0331 - val_acc: 0.8093 - val_f1_score: 0.0891\n",
      "\n",
      "Epoch 00002: val_f1_score did not improve from 0.25095\n",
      "Epoch 3/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.3354 - acc: 0.9514 - f1_score: 0.7099 - val_loss: 1.1405 - val_acc: 0.8127 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_f1_score did not improve from 0.25095\n",
      "Epoch 4/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.2259 - acc: 0.9677 - f1_score: 0.8090 - val_loss: 1.0881 - val_acc: 0.7805 - val_f1_score: 0.0848\n",
      "\n",
      "Epoch 00004: val_f1_score did not improve from 0.25095\n",
      "Epoch 5/300\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 0.1739 - acc: 0.9735 - f1_score: 0.8523 - val_loss: 1.1408 - val_acc: 0.8068 - val_f1_score: 0.0172\n",
      "\n",
      "Epoch 00005: val_f1_score did not improve from 0.25095\n",
      "Epoch 6/300\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.1356 - acc: 0.9793 - f1_score: 0.8841 - val_loss: 1.1105 - val_acc: 0.7907 - val_f1_score: 0.0886\n",
      "\n",
      "Epoch 00006: val_f1_score did not improve from 0.25095\n",
      "Epoch 7/300\n",
      "145/145 [==============================] - 6s 41ms/step - loss: 0.1060 - acc: 0.9845 - f1_score: 0.9129 - val_loss: 1.1470 - val_acc: 0.7881 - val_f1_score: 0.1135\n",
      "\n",
      "Epoch 00007: val_f1_score did not improve from 0.25095\n",
      "Epoch 8/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0886 - acc: 0.9874 - f1_score: 0.9284 - val_loss: 1.0930 - val_acc: 0.8314 - val_f1_score: 0.1233\n",
      "\n",
      "Epoch 00008: val_f1_score did not improve from 0.25095\n",
      "Epoch 9/300\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.0690 - acc: 0.9896 - f1_score: 0.9421 - val_loss: 1.1327 - val_acc: 0.8492 - val_f1_score: 0.0532\n",
      "\n",
      "Epoch 00009: val_f1_score did not improve from 0.25095\n",
      "Epoch 10/300\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.0739 - acc: 0.9886 - f1_score: 0.9352 - val_loss: 1.1697 - val_acc: 0.8169 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00010: val_f1_score did not improve from 0.25095\n",
      "Epoch 11/300\n",
      "145/145 [==============================] - 5s 36ms/step - loss: 0.0458 - acc: 0.9927 - f1_score: 0.9589 - val_loss: 1.0854 - val_acc: 0.8525 - val_f1_score: 0.0440\n",
      "\n",
      "Epoch 00011: val_f1_score did not improve from 0.25095\n",
      "Epoch 12/300\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.0537 - acc: 0.9915 - f1_score: 0.9546 - val_loss: 1.1013 - val_acc: 0.8246 - val_f1_score: 0.1551\n",
      "\n",
      "Epoch 00012: val_f1_score did not improve from 0.25095\n",
      "Epoch 13/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0501 - acc: 0.9924 - f1_score: 0.9578 - val_loss: 1.1657 - val_acc: 0.8407 - val_f1_score: 0.0105\n",
      "\n",
      "Epoch 00013: val_f1_score did not improve from 0.25095\n",
      "Epoch 14/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0444 - acc: 0.9930 - f1_score: 0.9623 - val_loss: 1.0761 - val_acc: 0.8500 - val_f1_score: 0.1843\n",
      "\n",
      "Epoch 00014: val_f1_score did not improve from 0.25095\n",
      "Epoch 15/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0385 - acc: 0.9940 - f1_score: 0.9662 - val_loss: 1.1348 - val_acc: 0.8424 - val_f1_score: 0.0510\n",
      "\n",
      "Epoch 00015: val_f1_score did not improve from 0.25095\n",
      "Epoch 16/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0384 - acc: 0.9940 - f1_score: 0.9661 - val_loss: 1.0629 - val_acc: 0.8669 - val_f1_score: 0.1949\n",
      "\n",
      "Epoch 00016: val_f1_score did not improve from 0.25095\n",
      "Epoch 17/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0474 - acc: 0.9931 - f1_score: 0.9611 - val_loss: 1.0076 - val_acc: 0.8568 - val_f1_score: 0.2422\n",
      "\n",
      "Epoch 00017: val_f1_score did not improve from 0.25095\n",
      "Epoch 18/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0362 - acc: 0.9948 - f1_score: 0.9704 - val_loss: 1.0780 - val_acc: 0.8373 - val_f1_score: 0.1652\n",
      "\n",
      "Epoch 00018: val_f1_score did not improve from 0.25095\n",
      "Epoch 19/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0327 - acc: 0.9948 - f1_score: 0.9718 - val_loss: 1.0633 - val_acc: 0.8331 - val_f1_score: 0.2394\n",
      "\n",
      "Epoch 00019: val_f1_score did not improve from 0.25095\n",
      "Epoch 20/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0343 - acc: 0.9949 - f1_score: 0.9708 - val_loss: 1.1959 - val_acc: 0.8441 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00020: val_f1_score did not improve from 0.25095\n",
      "Epoch 21/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0362 - acc: 0.9948 - f1_score: 0.9697 - val_loss: 1.0688 - val_acc: 0.8712 - val_f1_score: 0.1461\n",
      "\n",
      "Epoch 00021: val_f1_score did not improve from 0.25095\n",
      "Epoch 22/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0340 - acc: 0.9946 - f1_score: 0.9698 - val_loss: 0.9927 - val_acc: 0.8610 - val_f1_score: 0.2679\n",
      "\n",
      "Epoch 00022: val_f1_score improved from 0.25095 to 0.26786, saving model to ./models/lag_15_iter_0_split_7_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_10-100_f1_no_fpr_test.hdf5\n",
      "Epoch 23/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0281 - acc: 0.9958 - f1_score: 0.9763 - val_loss: 1.0854 - val_acc: 0.8593 - val_f1_score: 0.1531\n",
      "\n",
      "Epoch 00023: val_f1_score did not improve from 0.26786\n",
      "Epoch 24/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0293 - acc: 0.9952 - f1_score: 0.9744 - val_loss: 1.0866 - val_acc: 0.8610 - val_f1_score: 0.1183\n",
      "\n",
      "Epoch 00024: val_f1_score did not improve from 0.26786\n",
      "Epoch 25/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0222 - acc: 0.9968 - f1_score: 0.9824 - val_loss: 1.1723 - val_acc: 0.8415 - val_f1_score: 0.0508\n",
      "\n",
      "Epoch 00025: val_f1_score did not improve from 0.26786\n",
      "Epoch 26/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0343 - acc: 0.9946 - f1_score: 0.9706 - val_loss: 1.0220 - val_acc: 0.8636 - val_f1_score: 0.3207\n",
      "\n",
      "Epoch 00026: val_f1_score improved from 0.26786 to 0.32068, saving model to ./models/lag_15_iter_0_split_7_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_10-100_f1_no_fpr_test.hdf5\n",
      "Epoch 27/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0278 - acc: 0.9959 - f1_score: 0.9769 - val_loss: 1.1188 - val_acc: 0.8441 - val_f1_score: 0.1560\n",
      "\n",
      "Epoch 00027: val_f1_score did not improve from 0.32068\n",
      "Epoch 28/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0329 - acc: 0.9948 - f1_score: 0.9720 - val_loss: 1.0547 - val_acc: 0.8347 - val_f1_score: 0.2529\n",
      "\n",
      "Epoch 00028: val_f1_score did not improve from 0.32068\n",
      "Epoch 29/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0194 - acc: 0.9971 - f1_score: 0.9842 - val_loss: 1.0816 - val_acc: 0.8178 - val_f1_score: 0.1825\n",
      "\n",
      "Epoch 00029: val_f1_score did not improve from 0.32068\n",
      "Epoch 30/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0188 - acc: 0.9970 - f1_score: 0.9840 - val_loss: 1.0327 - val_acc: 0.8602 - val_f1_score: 0.2731\n",
      "\n",
      "Epoch 00030: val_f1_score did not improve from 0.32068\n",
      "Epoch 31/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0267 - acc: 0.9962 - f1_score: 0.9787 - val_loss: 1.0597 - val_acc: 0.8492 - val_f1_score: 0.2328\n",
      "\n",
      "Epoch 00031: val_f1_score did not improve from 0.32068\n",
      "Epoch 32/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0207 - acc: 0.9968 - f1_score: 0.9824 - val_loss: 1.0886 - val_acc: 0.8551 - val_f1_score: 0.2120\n",
      "\n",
      "Epoch 00032: val_f1_score did not improve from 0.32068\n",
      "Epoch 33/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0220 - acc: 0.9964 - f1_score: 0.9803 - val_loss: 0.9663 - val_acc: 0.8568 - val_f1_score: 0.3764\n",
      "\n",
      "Epoch 00033: val_f1_score improved from 0.32068 to 0.37638, saving model to ./models/lag_15_iter_0_split_7_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_10-100_f1_no_fpr_test.hdf5\n",
      "Epoch 34/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0288 - acc: 0.9953 - f1_score: 0.9743 - val_loss: 1.0729 - val_acc: 0.8661 - val_f1_score: 0.2404\n",
      "\n",
      "Epoch 00034: val_f1_score did not improve from 0.37638\n",
      "Epoch 35/300\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 0.0189 - acc: 0.9970 - f1_score: 0.9833 - val_loss: 1.1182 - val_acc: 0.8500 - val_f1_score: 0.1281\n",
      "\n",
      "Epoch 00035: val_f1_score did not improve from 0.37638\n",
      "Epoch 36/300\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.0209 - acc: 0.9969 - f1_score: 0.9822 - val_loss: 1.0390 - val_acc: 0.8610 - val_f1_score: 0.2264\n",
      "\n",
      "Epoch 00036: val_f1_score did not improve from 0.37638\n",
      "Epoch 37/300\n",
      "145/145 [==============================] - 5s 36ms/step - loss: 0.0207 - acc: 0.9966 - f1_score: 0.9815 - val_loss: 1.0957 - val_acc: 0.8432 - val_f1_score: 0.1629\n",
      "\n",
      "Epoch 00037: val_f1_score did not improve from 0.37638\n",
      "Epoch 38/300\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 0.0177 - acc: 0.9971 - f1_score: 0.9843 - val_loss: 1.1101 - val_acc: 0.8229 - val_f1_score: 0.1739\n",
      "\n",
      "Epoch 00038: val_f1_score did not improve from 0.37638\n",
      "Epoch 39/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0159 - acc: 0.9977 - f1_score: 0.9871 - val_loss: 0.9856 - val_acc: 0.8314 - val_f1_score: 0.3018\n",
      "\n",
      "Epoch 00039: val_f1_score did not improve from 0.37638\n",
      "Epoch 40/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0242 - acc: 0.9962 - f1_score: 0.9792 - val_loss: 1.1625 - val_acc: 0.8271 - val_f1_score: 0.0811\n",
      "\n",
      "Epoch 00040: val_f1_score did not improve from 0.37638\n",
      "Epoch 41/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0197 - acc: 0.9969 - f1_score: 0.9825 - val_loss: 1.1125 - val_acc: 0.8347 - val_f1_score: 0.1014\n",
      "\n",
      "Epoch 00041: val_f1_score did not improve from 0.37638\n",
      "Epoch 42/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0186 - acc: 0.9972 - f1_score: 0.9847 - val_loss: 1.1603 - val_acc: 0.8339 - val_f1_score: 0.1091\n",
      "\n",
      "Epoch 00042: val_f1_score did not improve from 0.37638\n",
      "Epoch 43/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0193 - acc: 0.9972 - f1_score: 0.9847 - val_loss: 1.1264 - val_acc: 0.8441 - val_f1_score: 0.1858\n",
      "\n",
      "Epoch 00043: val_f1_score did not improve from 0.37638\n",
      "Epoch 44/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0195 - acc: 0.9971 - f1_score: 0.9840 - val_loss: 1.0717 - val_acc: 0.8390 - val_f1_score: 0.1880\n",
      "\n",
      "Epoch 00044: val_f1_score did not improve from 0.37638\n",
      "Epoch 45/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0188 - acc: 0.9973 - f1_score: 0.9851 - val_loss: 1.0481 - val_acc: 0.8797 - val_f1_score: 0.2970\n",
      "\n",
      "Epoch 00045: val_f1_score did not improve from 0.37638\n",
      "Epoch 46/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0175 - acc: 0.9973 - f1_score: 0.9852 - val_loss: 1.0989 - val_acc: 0.8559 - val_f1_score: 0.2202\n",
      "\n",
      "Epoch 00046: val_f1_score did not improve from 0.37638\n",
      "Epoch 47/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0163 - acc: 0.9974 - f1_score: 0.9857 - val_loss: 1.1216 - val_acc: 0.8568 - val_f1_score: 0.2283\n",
      "\n",
      "Epoch 00047: val_f1_score did not improve from 0.37638\n",
      "Epoch 48/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0140 - acc: 0.9979 - f1_score: 0.9886 - val_loss: 1.0759 - val_acc: 0.8610 - val_f1_score: 0.2743\n",
      "\n",
      "Epoch 00048: val_f1_score did not improve from 0.37638\n",
      "Epoch 49/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0204 - acc: 0.9969 - f1_score: 0.9827 - val_loss: 1.1737 - val_acc: 0.8610 - val_f1_score: 0.0575\n",
      "\n",
      "Epoch 00049: val_f1_score did not improve from 0.37638\n",
      "Epoch 50/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0136 - acc: 0.9977 - f1_score: 0.9870 - val_loss: 1.1254 - val_acc: 0.8517 - val_f1_score: 0.2222\n",
      "\n",
      "Epoch 00050: val_f1_score did not improve from 0.37638\n",
      "Epoch 51/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0168 - acc: 0.9975 - f1_score: 0.9863 - val_loss: 1.0687 - val_acc: 0.8669 - val_f1_score: 0.2765\n",
      "\n",
      "Epoch 00051: val_f1_score did not improve from 0.37638\n",
      "Epoch 52/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0093 - acc: 0.9985 - f1_score: 0.9921 - val_loss: 1.1090 - val_acc: 0.8576 - val_f1_score: 0.2500\n",
      "\n",
      "Epoch 00052: val_f1_score did not improve from 0.37638\n",
      "Epoch 53/300\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.0140 - acc: 0.9977 - f1_score: 0.9872 - val_loss: 1.0267 - val_acc: 0.8712 - val_f1_score: 0.3028\n",
      "\n",
      "Epoch 00053: val_f1_score did not improve from 0.37638\n",
      "Epoch 54/300\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.0139 - acc: 0.9977 - f1_score: 0.9873 - val_loss: 1.0770 - val_acc: 0.8703 - val_f1_score: 0.2537\n",
      "\n",
      "Epoch 00054: val_f1_score did not improve from 0.37638\n",
      "Epoch 55/300\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.0141 - acc: 0.9979 - f1_score: 0.9885 - val_loss: 1.1555 - val_acc: 0.8542 - val_f1_score: 0.0851\n",
      "\n",
      "Epoch 00055: val_f1_score did not improve from 0.37638\n",
      "Epoch 56/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0134 - acc: 0.9981 - f1_score: 0.9893 - val_loss: 1.0474 - val_acc: 0.8525 - val_f1_score: 0.2689\n",
      "\n",
      "Epoch 00056: val_f1_score did not improve from 0.37638\n",
      "Epoch 57/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0171 - acc: 0.9975 - f1_score: 0.9860 - val_loss: 1.1245 - val_acc: 0.8627 - val_f1_score: 0.1474\n",
      "\n",
      "Epoch 00057: val_f1_score did not improve from 0.37638\n",
      "Epoch 58/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0122 - acc: 0.9982 - f1_score: 0.9903 - val_loss: 1.0783 - val_acc: 0.8542 - val_f1_score: 0.2712\n",
      "\n",
      "Epoch 00058: val_f1_score did not improve from 0.37638\n",
      "Epoch 59/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0139 - acc: 0.9980 - f1_score: 0.9889 - val_loss: 1.0791 - val_acc: 0.8644 - val_f1_score: 0.2793\n",
      "\n",
      "Epoch 00059: val_f1_score did not improve from 0.37638\n",
      "Epoch 60/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0140 - acc: 0.9978 - f1_score: 0.9882 - val_loss: 1.0902 - val_acc: 0.8619 - val_f1_score: 0.2201\n",
      "\n",
      "Epoch 00060: val_f1_score did not improve from 0.37638\n",
      "Epoch 61/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0139 - acc: 0.9977 - f1_score: 0.9879 - val_loss: 1.1511 - val_acc: 0.8271 - val_f1_score: 0.0811\n",
      "\n",
      "Epoch 00061: val_f1_score did not improve from 0.37638\n",
      "Epoch 62/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0138 - acc: 0.9978 - f1_score: 0.9881 - val_loss: 1.1333 - val_acc: 0.8610 - val_f1_score: 0.1087\n",
      "\n",
      "Epoch 00062: val_f1_score did not improve from 0.37638\n",
      "Epoch 63/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0085 - acc: 0.9987 - f1_score: 0.9927 - val_loss: 1.0600 - val_acc: 0.8695 - val_f1_score: 0.1809\n",
      "\n",
      "Epoch 00063: val_f1_score did not improve from 0.37638\n",
      "Epoch 64/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0097 - acc: 0.9984 - f1_score: 0.9915 - val_loss: 1.0151 - val_acc: 0.8644 - val_f1_score: 0.2661\n",
      "\n",
      "Epoch 00064: val_f1_score did not improve from 0.37638\n",
      "Epoch 65/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0153 - acc: 0.9977 - f1_score: 0.9873 - val_loss: 1.0361 - val_acc: 0.8686 - val_f1_score: 0.2132\n",
      "\n",
      "Epoch 00065: val_f1_score did not improve from 0.37638\n",
      "Epoch 66/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0154 - acc: 0.9976 - f1_score: 0.9864 - val_loss: 1.0821 - val_acc: 0.8686 - val_f1_score: 0.2654\n",
      "\n",
      "Epoch 00066: val_f1_score did not improve from 0.37638\n",
      "Epoch 67/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0117 - acc: 0.9982 - f1_score: 0.9899 - val_loss: 1.0741 - val_acc: 0.8797 - val_f1_score: 0.2755\n",
      "\n",
      "Epoch 00067: val_f1_score did not improve from 0.37638\n",
      "Epoch 68/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0119 - acc: 0.9982 - f1_score: 0.9899 - val_loss: 0.9472 - val_acc: 0.8805 - val_f1_score: 0.3188\n",
      "\n",
      "Epoch 00068: val_f1_score did not improve from 0.37638\n",
      "Epoch 69/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0105 - acc: 0.9984 - f1_score: 0.9913 - val_loss: 1.0931 - val_acc: 0.8746 - val_f1_score: 0.2292\n",
      "\n",
      "Epoch 00069: val_f1_score did not improve from 0.37638\n",
      "Epoch 70/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0131 - acc: 0.9978 - f1_score: 0.9877 - val_loss: 1.0107 - val_acc: 0.8644 - val_f1_score: 0.3103\n",
      "\n",
      "Epoch 00070: val_f1_score did not improve from 0.37638\n",
      "Epoch 71/300\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.0137 - acc: 0.9980 - f1_score: 0.9888 - val_loss: 1.1163 - val_acc: 0.8517 - val_f1_score: 0.2291\n",
      "\n",
      "Epoch 00071: val_f1_score did not improve from 0.37638\n",
      "Epoch 72/300\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.0066 - acc: 0.9990 - f1_score: 0.9946 - val_loss: 1.1208 - val_acc: 0.8424 - val_f1_score: 0.2185\n",
      "\n",
      "Epoch 00072: val_f1_score did not improve from 0.37638\n",
      "Epoch 73/300\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.0083 - acc: 0.9988 - f1_score: 0.9934 - val_loss: 1.1087 - val_acc: 0.8686 - val_f1_score: 0.2439\n",
      "\n",
      "Epoch 00073: val_f1_score did not improve from 0.37638\n",
      "Epoch 00073: early stopping\n",
      "(0.29820051413881754, 2.559598e-06)\n",
      "(0.24143070044709392, 0.0)\n",
      "0.5996749860535061\n",
      "1313 (16413,)\n",
      "28886\n",
      "(None, 1, 1) coeff (None, 5, 30) amplitude\n",
      "Epoch 1/300\n",
      "145/145 [==============================] - 15s 54ms/step - loss: 0.8189 - acc: 0.8495 - f1_score: 0.2822 - val_loss: 0.9758 - val_acc: 0.9069 - val_f1_score: 0.1698\n",
      "\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.16976, saving model to ./models/lag_15_iter_0_split_8_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_10-100_f1_no_fpr_test.hdf5\n",
      "Epoch 2/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.4162 - acc: 0.9474 - f1_score: 0.6485 - val_loss: 1.0479 - val_acc: 0.9200 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_f1_score did not improve from 0.16976\n",
      "Epoch 3/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.3059 - acc: 0.9581 - f1_score: 0.7412 - val_loss: 1.0534 - val_acc: 0.9227 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_f1_score did not improve from 0.16976\n",
      "Epoch 4/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.2433 - acc: 0.9667 - f1_score: 0.7944 - val_loss: 1.0120 - val_acc: 0.9108 - val_f1_score: 0.1228\n",
      "\n",
      "Epoch 00004: val_f1_score did not improve from 0.16976\n",
      "Epoch 5/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.1858 - acc: 0.9745 - f1_score: 0.8453 - val_loss: 1.0601 - val_acc: 0.9019 - val_f1_score: 0.0678\n",
      "\n",
      "Epoch 00005: val_f1_score did not improve from 0.16976\n",
      "Epoch 6/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.1598 - acc: 0.9775 - f1_score: 0.8663 - val_loss: 1.0279 - val_acc: 0.9158 - val_f1_score: 0.1238\n",
      "\n",
      "Epoch 00006: val_f1_score did not improve from 0.16976\n",
      "Epoch 7/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.1273 - acc: 0.9818 - f1_score: 0.8956 - val_loss: 1.0641 - val_acc: 0.9019 - val_f1_score: 0.0678\n",
      "\n",
      "Epoch 00007: val_f1_score did not improve from 0.16976\n",
      "Epoch 8/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.1175 - acc: 0.9835 - f1_score: 0.9027 - val_loss: 1.0869 - val_acc: 0.9054 - val_f1_score: 0.0062\n",
      "\n",
      "Epoch 00008: val_f1_score did not improve from 0.16976\n",
      "Epoch 9/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.1075 - acc: 0.9842 - f1_score: 0.9089 - val_loss: 1.0631 - val_acc: 0.9206 - val_f1_score: 0.0565\n",
      "\n",
      "Epoch 00009: val_f1_score did not improve from 0.16976\n",
      "Epoch 10/300\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 0.0877 - acc: 0.9873 - f1_score: 0.9258 - val_loss: 1.0801 - val_acc: 0.9072 - val_f1_score: 0.0602\n",
      "\n",
      "Epoch 00010: val_f1_score did not improve from 0.16976\n",
      "Epoch 11/300\n",
      "145/145 [==============================] - 5s 36ms/step - loss: 0.0851 - acc: 0.9875 - f1_score: 0.9281 - val_loss: 1.0765 - val_acc: 0.8855 - val_f1_score: 0.0984\n",
      "\n",
      "Epoch 00011: val_f1_score did not improve from 0.16976\n",
      "Epoch 12/300\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 0.0828 - acc: 0.9877 - f1_score: 0.9312 - val_loss: 1.0735 - val_acc: 0.9144 - val_f1_score: 0.0464\n",
      "\n",
      "Epoch 00012: val_f1_score did not improve from 0.16976\n",
      "Epoch 13/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0628 - acc: 0.9905 - f1_score: 0.9483 - val_loss: 1.0576 - val_acc: 0.9132 - val_f1_score: 0.0875\n",
      "\n",
      "Epoch 00013: val_f1_score did not improve from 0.16976\n",
      "Epoch 14/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0612 - acc: 0.9912 - f1_score: 0.9487 - val_loss: 1.0748 - val_acc: 0.9188 - val_f1_score: 0.0488\n",
      "\n",
      "Epoch 00014: val_f1_score did not improve from 0.16976\n",
      "Epoch 15/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0562 - acc: 0.9917 - f1_score: 0.9543 - val_loss: 1.0749 - val_acc: 0.9301 - val_f1_score: 0.0167\n",
      "\n",
      "Epoch 00015: val_f1_score did not improve from 0.16976\n",
      "Epoch 16/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0470 - acc: 0.9929 - f1_score: 0.9616 - val_loss: 1.0894 - val_acc: 0.9081 - val_f1_score: 0.0550\n",
      "\n",
      "Epoch 00016: val_f1_score did not improve from 0.16976\n",
      "Epoch 17/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0499 - acc: 0.9923 - f1_score: 0.9568 - val_loss: 1.0724 - val_acc: 0.9156 - val_f1_score: 0.0658\n",
      "\n",
      "Epoch 00017: val_f1_score did not improve from 0.16976\n",
      "Epoch 18/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0487 - acc: 0.9926 - f1_score: 0.9594 - val_loss: 1.0775 - val_acc: 0.9069 - val_f1_score: 0.0486\n",
      "\n",
      "Epoch 00018: val_f1_score did not improve from 0.16976\n",
      "Epoch 19/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0501 - acc: 0.9921 - f1_score: 0.9572 - val_loss: 1.0791 - val_acc: 0.9138 - val_f1_score: 0.0397\n",
      "\n",
      "Epoch 00019: val_f1_score did not improve from 0.16976\n",
      "Epoch 20/300\n",
      "145/145 [==============================] - 7s 45ms/step - loss: 0.0425 - acc: 0.9933 - f1_score: 0.9627 - val_loss: 1.0884 - val_acc: 0.8959 - val_f1_score: 0.0591\n",
      "\n",
      "Epoch 00020: val_f1_score did not improve from 0.16976\n",
      "Epoch 21/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.0487 - acc: 0.9929 - f1_score: 0.9594 - val_loss: 1.0758 - val_acc: 0.8956 - val_f1_score: 0.0930\n",
      "\n",
      "Epoch 00021: val_f1_score did not improve from 0.16976\n",
      "Epoch 22/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0384 - acc: 0.9942 - f1_score: 0.9677 - val_loss: 1.0748 - val_acc: 0.9025 - val_f1_score: 0.0682\n",
      "\n",
      "Epoch 00022: val_f1_score did not improve from 0.16976\n",
      "Epoch 23/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0356 - acc: 0.9948 - f1_score: 0.9708 - val_loss: 1.0706 - val_acc: 0.9072 - val_f1_score: 0.0769\n",
      "\n",
      "Epoch 00023: val_f1_score did not improve from 0.16976\n",
      "Epoch 24/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0351 - acc: 0.9947 - f1_score: 0.9712 - val_loss: 1.0766 - val_acc: 0.9292 - val_f1_score: 0.0556\n",
      "\n",
      "Epoch 00024: val_f1_score did not improve from 0.16976\n",
      "Epoch 25/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.0307 - acc: 0.9950 - f1_score: 0.9721 - val_loss: 1.0728 - val_acc: 0.9343 - val_f1_score: 0.0433\n",
      "\n",
      "Epoch 00025: val_f1_score did not improve from 0.16976\n",
      "Epoch 26/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.0346 - acc: 0.9949 - f1_score: 0.9717 - val_loss: 1.0751 - val_acc: 0.9203 - val_f1_score: 0.0563\n",
      "\n",
      "Epoch 00026: val_f1_score did not improve from 0.16976\n",
      "Epoch 27/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0331 - acc: 0.9953 - f1_score: 0.9735 - val_loss: 1.0781 - val_acc: 0.9182 - val_f1_score: 0.0550\n",
      "\n",
      "Epoch 00027: val_f1_score did not improve from 0.16976\n",
      "Epoch 28/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.0309 - acc: 0.9953 - f1_score: 0.9742 - val_loss: 1.0604 - val_acc: 0.9170 - val_f1_score: 0.0852\n",
      "\n",
      "Epoch 00028: val_f1_score did not improve from 0.16976\n",
      "Epoch 29/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0373 - acc: 0.9940 - f1_score: 0.9678 - val_loss: 1.0787 - val_acc: 0.9093 - val_f1_score: 0.0615\n",
      "\n",
      "Epoch 00029: val_f1_score did not improve from 0.16976\n",
      "Epoch 30/300\n",
      "145/145 [==============================] - 7s 45ms/step - loss: 0.0286 - acc: 0.9959 - f1_score: 0.9770 - val_loss: 1.0725 - val_acc: 0.9197 - val_f1_score: 0.0816\n",
      "\n",
      "Epoch 00030: val_f1_score did not improve from 0.16976\n",
      "Epoch 31/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.0327 - acc: 0.9947 - f1_score: 0.9712 - val_loss: 1.0584 - val_acc: 0.9084 - val_f1_score: 0.1397\n",
      "\n",
      "Epoch 00031: val_f1_score did not improve from 0.16976\n",
      "Epoch 32/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0268 - acc: 0.9958 - f1_score: 0.9773 - val_loss: 1.0736 - val_acc: 0.9254 - val_f1_score: 0.0528\n",
      "\n",
      "Epoch 00032: val_f1_score did not improve from 0.16976\n",
      "Epoch 33/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0296 - acc: 0.9955 - f1_score: 0.9752 - val_loss: 1.0793 - val_acc: 0.9040 - val_f1_score: 0.0638\n",
      "\n",
      "Epoch 00033: val_f1_score did not improve from 0.16976\n",
      "Epoch 34/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0239 - acc: 0.9963 - f1_score: 0.9801 - val_loss: 1.0715 - val_acc: 0.9301 - val_f1_score: 0.0486\n",
      "\n",
      "Epoch 00034: val_f1_score did not improve from 0.16976\n",
      "Epoch 35/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.0241 - acc: 0.9961 - f1_score: 0.9785 - val_loss: 1.0768 - val_acc: 0.9239 - val_f1_score: 0.0519\n",
      "\n",
      "Epoch 00035: val_f1_score did not improve from 0.16976\n",
      "Epoch 36/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0314 - acc: 0.9952 - f1_score: 0.9737 - val_loss: 1.0601 - val_acc: 0.9197 - val_f1_score: 0.0940\n",
      "\n",
      "Epoch 00036: val_f1_score did not improve from 0.16976\n",
      "Epoch 37/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0350 - acc: 0.9946 - f1_score: 0.9703 - val_loss: 1.0701 - val_acc: 0.9251 - val_f1_score: 0.0597\n",
      "\n",
      "Epoch 00037: val_f1_score did not improve from 0.16976\n",
      "Epoch 38/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0225 - acc: 0.9968 - f1_score: 0.9815 - val_loss: 1.0810 - val_acc: 0.9108 - val_f1_score: 0.0798\n",
      "\n",
      "Epoch 00038: val_f1_score did not improve from 0.16976\n",
      "Epoch 39/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.0267 - acc: 0.9958 - f1_score: 0.9777 - val_loss: 1.0556 - val_acc: 0.9382 - val_f1_score: 0.0796\n",
      "\n",
      "Epoch 00039: val_f1_score did not improve from 0.16976\n",
      "Epoch 40/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.0225 - acc: 0.9967 - f1_score: 0.9821 - val_loss: 1.0542 - val_acc: 0.9331 - val_f1_score: 0.0816\n",
      "\n",
      "Epoch 00040: val_f1_score did not improve from 0.16976\n",
      "Epoch 41/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.0223 - acc: 0.9963 - f1_score: 0.9801 - val_loss: 1.0564 - val_acc: 0.9173 - val_f1_score: 0.1146\n",
      "\n",
      "Epoch 00041: val_f1_score did not improve from 0.16976\n",
      "Epoch 00041: early stopping\n",
      "(0.17293233082706766, 0.0023719152)\n",
      "(0.19055509527754763, 0.0052997908)\n",
      "0.7674654907975461\n",
      "1316 (16855,)\n",
      "28952\n",
      "(None, 1, 1) coeff (None, 5, 30) amplitude\n",
      "Epoch 1/300\n",
      "145/145 [==============================] - 15s 54ms/step - loss: 0.8252 - acc: 0.8366 - f1_score: 0.2773 - val_loss: 1.0163 - val_acc: 0.9331 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.00000, saving model to ./models/lag_15_iter_0_split_9_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_10-100_f1_no_fpr_test.hdf5\n",
      "Epoch 2/300\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.4849 - acc: 0.9385 - f1_score: 0.5926 - val_loss: 1.0475 - val_acc: 0.9241 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_f1_score did not improve from 0.00000\n",
      "Epoch 3/300\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.3161 - acc: 0.9580 - f1_score: 0.7326 - val_loss: 1.0638 - val_acc: 0.9130 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_f1_score did not improve from 0.00000\n",
      "Epoch 4/300\n",
      "145/145 [==============================] - 6s 41ms/step - loss: 0.2345 - acc: 0.9680 - f1_score: 0.8050 - val_loss: 1.0504 - val_acc: 0.9217 - val_f1_score: 0.0231\n",
      "\n",
      "Epoch 00004: val_f1_score improved from 0.00000 to 0.02308, saving model to ./models/lag_15_iter_0_split_9_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_10-100_f1_no_fpr_test.hdf5\n",
      "Epoch 5/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.1764 - acc: 0.9756 - f1_score: 0.8553 - val_loss: 1.0246 - val_acc: 0.9158 - val_f1_score: 0.0930\n",
      "\n",
      "Epoch 00005: val_f1_score improved from 0.02308 to 0.09302, saving model to ./models/lag_15_iter_0_split_9_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_10-100_f1_no_fpr_test.hdf5\n",
      "Epoch 6/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.1623 - acc: 0.9756 - f1_score: 0.8609 - val_loss: 0.9715 - val_acc: 0.9248 - val_f1_score: 0.2469\n",
      "\n",
      "Epoch 00006: val_f1_score improved from 0.09302 to 0.24691, saving model to ./models/lag_15_iter_0_split_9_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_10-100_f1_no_fpr_test.hdf5\n",
      "Epoch 7/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.1141 - acc: 0.9835 - f1_score: 0.9048 - val_loss: 1.0487 - val_acc: 0.8967 - val_f1_score: 0.0822\n",
      "\n",
      "Epoch 00007: val_f1_score did not improve from 0.24691\n",
      "Epoch 8/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0827 - acc: 0.9877 - f1_score: 0.9323 - val_loss: 1.0473 - val_acc: 0.9220 - val_f1_score: 0.0996\n",
      "\n",
      "Epoch 00008: val_f1_score did not improve from 0.24691\n",
      "Epoch 9/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0714 - acc: 0.9892 - f1_score: 0.9398 - val_loss: 1.0133 - val_acc: 0.9146 - val_f1_score: 0.1829\n",
      "\n",
      "Epoch 00009: val_f1_score did not improve from 0.24691\n",
      "Epoch 10/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0793 - acc: 0.9886 - f1_score: 0.9360 - val_loss: 1.0578 - val_acc: 0.8924 - val_f1_score: 0.0935\n",
      "\n",
      "Epoch 00010: val_f1_score did not improve from 0.24691\n",
      "Epoch 11/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0637 - acc: 0.9898 - f1_score: 0.9463 - val_loss: 1.0980 - val_acc: 0.8982 - val_f1_score: 0.0179\n",
      "\n",
      "Epoch 00011: val_f1_score did not improve from 0.24691\n",
      "Epoch 12/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0652 - acc: 0.9901 - f1_score: 0.9459 - val_loss: 1.0826 - val_acc: 0.9044 - val_f1_score: 0.0312\n",
      "\n",
      "Epoch 00012: val_f1_score did not improve from 0.24691\n",
      "Epoch 13/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0609 - acc: 0.9910 - f1_score: 0.9505 - val_loss: 1.1077 - val_acc: 0.8711 - val_f1_score: 0.0279\n",
      "\n",
      "Epoch 00013: val_f1_score did not improve from 0.24691\n",
      "Epoch 14/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0524 - acc: 0.9920 - f1_score: 0.9551 - val_loss: 1.0623 - val_acc: 0.9084 - val_f1_score: 0.0690\n",
      "\n",
      "Epoch 00014: val_f1_score did not improve from 0.24691\n",
      "Epoch 15/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.0483 - acc: 0.9926 - f1_score: 0.9583 - val_loss: 0.9673 - val_acc: 0.9134 - val_f1_score: 0.3096\n",
      "\n",
      "Epoch 00015: val_f1_score improved from 0.24691 to 0.30958, saving model to ./models/lag_15_iter_0_split_9_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_10-100_f1_no_fpr_test.hdf5\n",
      "Epoch 16/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0525 - acc: 0.9922 - f1_score: 0.9570 - val_loss: 1.1124 - val_acc: 0.8949 - val_f1_score: 0.0285\n",
      "\n",
      "Epoch 00016: val_f1_score did not improve from 0.30958\n",
      "Epoch 17/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.0439 - acc: 0.9930 - f1_score: 0.9623 - val_loss: 1.0484 - val_acc: 0.8942 - val_f1_score: 0.1853\n",
      "\n",
      "Epoch 00017: val_f1_score did not improve from 0.30958\n",
      "Epoch 18/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0405 - acc: 0.9941 - f1_score: 0.9669 - val_loss: 1.0761 - val_acc: 0.8967 - val_f1_score: 0.0872\n",
      "\n",
      "Epoch 00018: val_f1_score did not improve from 0.30958\n",
      "Epoch 19/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.0483 - acc: 0.9928 - f1_score: 0.9596 - val_loss: 1.0927 - val_acc: 0.9118 - val_f1_score: 0.0069\n",
      "\n",
      "Epoch 00019: val_f1_score did not improve from 0.30958\n",
      "Epoch 20/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0401 - acc: 0.9941 - f1_score: 0.9662 - val_loss: 1.0531 - val_acc: 0.9186 - val_f1_score: 0.1484\n",
      "\n",
      "Epoch 00020: val_f1_score did not improve from 0.30958\n",
      "Epoch 21/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0441 - acc: 0.9933 - f1_score: 0.9628 - val_loss: 1.1024 - val_acc: 0.8881 - val_f1_score: 0.0371\n",
      "\n",
      "Epoch 00021: val_f1_score did not improve from 0.30958\n",
      "Epoch 22/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.0313 - acc: 0.9953 - f1_score: 0.9738 - val_loss: 1.0887 - val_acc: 0.8890 - val_f1_score: 0.0769\n",
      "\n",
      "Epoch 00022: val_f1_score did not improve from 0.30958\n",
      "Epoch 23/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0365 - acc: 0.9940 - f1_score: 0.9675 - val_loss: 1.0584 - val_acc: 0.9124 - val_f1_score: 0.0955\n",
      "\n",
      "Epoch 00023: val_f1_score did not improve from 0.30958\n",
      "Epoch 24/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0382 - acc: 0.9941 - f1_score: 0.9669 - val_loss: 1.0980 - val_acc: 0.8961 - val_f1_score: 0.0399\n",
      "\n",
      "Epoch 00024: val_f1_score did not improve from 0.30958\n",
      "Epoch 25/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.0323 - acc: 0.9952 - f1_score: 0.9728 - val_loss: 1.1149 - val_acc: 0.8927 - val_f1_score: 0.0114\n",
      "\n",
      "Epoch 00025: val_f1_score did not improve from 0.30958\n",
      "Epoch 26/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.0329 - acc: 0.9945 - f1_score: 0.9704 - val_loss: 1.0661 - val_acc: 0.9093 - val_f1_score: 0.1552\n",
      "\n",
      "Epoch 00026: val_f1_score did not improve from 0.30958\n",
      "Epoch 27/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0245 - acc: 0.9959 - f1_score: 0.9779 - val_loss: 1.0880 - val_acc: 0.9100 - val_f1_score: 0.0818\n",
      "\n",
      "Epoch 00027: val_f1_score did not improve from 0.30958\n",
      "Epoch 28/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0266 - acc: 0.9960 - f1_score: 0.9776 - val_loss: 1.0894 - val_acc: 0.9016 - val_f1_score: 0.0754\n",
      "\n",
      "Epoch 00028: val_f1_score did not improve from 0.30958\n",
      "Epoch 29/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.0230 - acc: 0.9963 - f1_score: 0.9802 - val_loss: 1.0466 - val_acc: 0.9075 - val_f1_score: 0.1620\n",
      "\n",
      "Epoch 00029: val_f1_score did not improve from 0.30958\n",
      "Epoch 30/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.0251 - acc: 0.9962 - f1_score: 0.9789 - val_loss: 1.1098 - val_acc: 0.9106 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00030: val_f1_score did not improve from 0.30958\n",
      "Epoch 31/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0375 - acc: 0.9941 - f1_score: 0.9685 - val_loss: 1.0844 - val_acc: 0.9053 - val_f1_score: 0.0669\n",
      "\n",
      "Epoch 00031: val_f1_score did not improve from 0.30958\n",
      "Epoch 32/300\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.0288 - acc: 0.9954 - f1_score: 0.9752 - val_loss: 1.1168 - val_acc: 0.8942 - val_f1_score: 0.0172\n",
      "\n",
      "Epoch 00032: val_f1_score did not improve from 0.30958\n",
      "Epoch 33/300\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.0255 - acc: 0.9959 - f1_score: 0.9774 - val_loss: 1.0997 - val_acc: 0.8844 - val_f1_score: 0.0602\n",
      "\n",
      "Epoch 00033: val_f1_score did not improve from 0.30958\n",
      "Epoch 34/300\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 0.0355 - acc: 0.9945 - f1_score: 0.9690 - val_loss: 1.1050 - val_acc: 0.8949 - val_f1_score: 0.0340\n",
      "\n",
      "Epoch 00034: val_f1_score did not improve from 0.30958\n",
      "Epoch 35/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0236 - acc: 0.9964 - f1_score: 0.9799 - val_loss: 1.0754 - val_acc: 0.8995 - val_f1_score: 0.1237\n",
      "\n",
      "Epoch 00035: val_f1_score did not improve from 0.30958\n",
      "Epoch 36/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0297 - acc: 0.9956 - f1_score: 0.9752 - val_loss: 1.1480 - val_acc: 0.8557 - val_f1_score: 0.0250\n",
      "\n",
      "Epoch 00036: val_f1_score did not improve from 0.30958\n",
      "Epoch 37/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0245 - acc: 0.9963 - f1_score: 0.9796 - val_loss: 1.1577 - val_acc: 0.8560 - val_f1_score: 0.0210\n",
      "\n",
      "Epoch 00037: val_f1_score did not improve from 0.30958\n",
      "Epoch 38/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0249 - acc: 0.9964 - f1_score: 0.9805 - val_loss: 1.1201 - val_acc: 0.8924 - val_f1_score: 0.0386\n",
      "\n",
      "Epoch 00038: val_f1_score did not improve from 0.30958\n",
      "Epoch 39/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0197 - acc: 0.9970 - f1_score: 0.9833 - val_loss: 1.0909 - val_acc: 0.9004 - val_f1_score: 0.0692\n",
      "\n",
      "Epoch 00039: val_f1_score did not improve from 0.30958\n",
      "Epoch 40/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0256 - acc: 0.9962 - f1_score: 0.9791 - val_loss: 1.0878 - val_acc: 0.9075 - val_f1_score: 0.0625\n",
      "\n",
      "Epoch 00040: val_f1_score did not improve from 0.30958\n",
      "Epoch 41/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0238 - acc: 0.9960 - f1_score: 0.9783 - val_loss: 1.0948 - val_acc: 0.8982 - val_f1_score: 0.0571\n",
      "\n",
      "Epoch 00041: val_f1_score did not improve from 0.30958\n",
      "Epoch 42/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0202 - acc: 0.9969 - f1_score: 0.9824 - val_loss: 1.0788 - val_acc: 0.9023 - val_f1_score: 0.1362\n",
      "\n",
      "Epoch 00042: val_f1_score did not improve from 0.30958\n",
      "Epoch 43/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0205 - acc: 0.9964 - f1_score: 0.9806 - val_loss: 1.0831 - val_acc: 0.8973 - val_f1_score: 0.0926\n",
      "\n",
      "Epoch 00043: val_f1_score did not improve from 0.30958\n",
      "Epoch 44/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0186 - acc: 0.9970 - f1_score: 0.9835 - val_loss: 1.0586 - val_acc: 0.9069 - val_f1_score: 0.1564\n",
      "\n",
      "Epoch 00044: val_f1_score did not improve from 0.30958\n",
      "Epoch 45/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.0176 - acc: 0.9973 - f1_score: 0.9851 - val_loss: 1.0716 - val_acc: 0.9066 - val_f1_score: 0.1268\n",
      "\n",
      "Epoch 00045: val_f1_score did not improve from 0.30958\n",
      "Epoch 46/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.0190 - acc: 0.9970 - f1_score: 0.9836 - val_loss: 1.1046 - val_acc: 0.8979 - val_f1_score: 0.0516\n",
      "\n",
      "Epoch 00046: val_f1_score did not improve from 0.30958\n",
      "Epoch 47/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0247 - acc: 0.9959 - f1_score: 0.9773 - val_loss: 1.1055 - val_acc: 0.8970 - val_f1_score: 0.0457\n",
      "\n",
      "Epoch 00047: val_f1_score did not improve from 0.30958\n",
      "Epoch 48/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0148 - acc: 0.9975 - f1_score: 0.9867 - val_loss: 1.0839 - val_acc: 0.8930 - val_f1_score: 0.1170\n",
      "\n",
      "Epoch 00048: val_f1_score did not improve from 0.30958\n",
      "Epoch 49/300\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 0.0200 - acc: 0.9972 - f1_score: 0.9841 - val_loss: 1.0688 - val_acc: 0.8986 - val_f1_score: 0.1671\n",
      "\n",
      "Epoch 00049: val_f1_score did not improve from 0.30958\n",
      "Epoch 50/300\n",
      "145/145 [==============================] - 5s 36ms/step - loss: 0.0147 - acc: 0.9976 - f1_score: 0.9873 - val_loss: 1.0537 - val_acc: 0.8893 - val_f1_score: 0.2075\n",
      "\n",
      "Epoch 00050: val_f1_score did not improve from 0.30958\n",
      "Epoch 51/300\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 0.0223 - acc: 0.9969 - f1_score: 0.9822 - val_loss: 1.0568 - val_acc: 0.8905 - val_f1_score: 0.1950\n",
      "\n",
      "Epoch 00051: val_f1_score did not improve from 0.30958\n",
      "Epoch 52/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0175 - acc: 0.9972 - f1_score: 0.9849 - val_loss: 1.1250 - val_acc: 0.8834 - val_f1_score: 0.0357\n",
      "\n",
      "Epoch 00052: val_f1_score did not improve from 0.30958\n",
      "Epoch 53/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0190 - acc: 0.9970 - f1_score: 0.9831 - val_loss: 1.0784 - val_acc: 0.9050 - val_f1_score: 0.1397\n",
      "\n",
      "Epoch 00053: val_f1_score did not improve from 0.30958\n",
      "Epoch 54/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0187 - acc: 0.9970 - f1_score: 0.9835 - val_loss: 1.0567 - val_acc: 0.8862 - val_f1_score: 0.1745\n",
      "\n",
      "Epoch 00054: val_f1_score did not improve from 0.30958\n",
      "Epoch 55/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0172 - acc: 0.9975 - f1_score: 0.9859 - val_loss: 1.0556 - val_acc: 0.9078 - val_f1_score: 0.1717\n",
      "\n",
      "Epoch 00055: val_f1_score did not improve from 0.30958\n",
      "Epoch 00055: early stopping\n",
      "(0.2585812356979405, 1.9385523e-05)\n",
      "(0.11663286004056794, 3.6633821e-06)\n",
      "0.6726047725280854\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "use_standardization = True\n",
    "n_lag = 15\n",
    "n_groups = 10\n",
    "X_feature,X_static,X_stress_episode,X_quit_episode,X_activity_episode,X_smoking_episode,y_time,y,groups = get_X_y_groups(n_lag)\n",
    "y[y<0] = 0\n",
    "y = np.float32(y)\n",
    "indexes = get_train_test_indexes(groups,n_groups_split = n_groups,n_val_groups=5)\n",
    "final_y_time = []\n",
    "final_probs = []\n",
    "final_y = []\n",
    "final_groups = []\n",
    "bias_dict = {}\n",
    "val_results = {}\n",
    "for kk,yyyy in enumerate(indexes):\n",
    "    train_index,test_index,val_index = yyyy\n",
    "    \n",
    "    X_feature_train,X_feature_test = X_feature[train_index],X_feature[test_index]\n",
    "    X_static_train,X_static_test = X_static[train_index],X_static[test_index]\n",
    "    X_stress_episode_train,X_stress_episode_test = X_stress_episode[train_index], X_stress_episode[test_index]\n",
    "    X_quit_episode_train,X_quit_episode_test = X_quit_episode[train_index], X_quit_episode[test_index]\n",
    "    X_activity_episode_train,X_activity_episode_test = X_activity_episode[train_index], X_activity_episode[test_index]\n",
    "    X_smoking_episode_train,X_smoking_episode_test = X_smoking_episode[train_index], X_smoking_episode[test_index]\n",
    "    y_train,y_test,groups_train,groups_test,time_train,time_test = y[train_index],y[test_index],groups[train_index],groups[test_index],y_time[train_index],y_time[test_index]\n",
    "    \n",
    "    X_feature_val,X_static_val,X_stress_episode_val,X_quit_episode_val,\\\n",
    "    X_activity_episode_val,X_smoking_episode_val,y_val,groups_val,time_val = X_feature[val_index],X_static[val_index],X_stress_episode[val_index],X_quit_episode[val_index],\\\n",
    "                                                                            X_activity_episode[val_index],X_smoking_episode[val_index],y[val_index],groups[val_index],y_time[val_index]\n",
    "    \n",
    "    positive_train_index = np.where(y_train==1)[0]\n",
    "    negative_train_index = np.where(y_train==0)[0]\n",
    "    \n",
    "    len_positive = len(positive_train_index)\n",
    "    print(len_positive,y_train.shape)\n",
    "    n_iters = 0\n",
    "    test_preds = []\n",
    "    bias_pred = []\n",
    "    # for i,n_iter in enumerate(range(n_iters)):\n",
    "    #     np.random.seed(np.random.randint(109))\n",
    "    indexes_sampled = np.array(list(positive_train_index)*2+list(np.random.choice(negative_train_index,len_positive*20)))\n",
    "    print(len(indexes_sampled))\n",
    "    np.random.shuffle(indexes_sampled)\n",
    "    train_feature = X_feature_train[indexes_sampled]\n",
    "    train_static = X_static_train[indexes_sampled]\n",
    "    train_stress = X_stress_episode_train[indexes_sampled]\n",
    "    train_quit = X_quit_episode_train[indexes_sampled]\n",
    "    train_activity = X_activity_episode_train[indexes_sampled]\n",
    "    train_smoking = X_smoking_episode_train[indexes_sampled]\n",
    "    train_y = y_train[indexes_sampled]\n",
    "    model = get_model()\n",
    "#         model.summary()\n",
    "    filepath = './models/lag_'+str(n_lag)+'_iter_'+str(n_iters)+'_split_'+str(kk)+'_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_10-100_f1_no_fpr_test.hdf5'\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_f1_score', verbose=1, save_best_only=True, mode='max',save_weights_only=False)\n",
    "    es = EarlyStopping(monitor='val_f1_score', mode='max', verbose=1,patience=40)\n",
    "    callbacks_list = [es,checkpoint]\n",
    "    # train_feature,val_feature,train_static,val_static,train_stress,val_stress, \\\n",
    "    # train_smoking,val_smoking,train_quit,val_quit,train_activity,val_activity, \\\n",
    "    # train_y,val_y = train_test_split(train_feature,\n",
    "    #                                     train_static,\n",
    "    #                                     train_stress,\n",
    "    #                                     train_smoking,\n",
    "    #                                     train_quit,\n",
    "    #                                     train_activity,\n",
    "    #                                     train_y,\n",
    "    #                                     test_size=.2,stratify=train_y)\n",
    "    model.fit([train_feature,train_static,train_stress,train_activity,train_smoking,train_quit],train_y,\n",
    "        validation_data=([X_feature_test,X_static_test,X_stress_episode_test,\n",
    "                                    X_activity_episode_test,X_smoking_episode_test,X_quit_episode_test],y_test), epochs=300, batch_size=200,\n",
    "                verbose=1,callbacks=callbacks_list,shuffle=True)\n",
    "    model.load_weights(filepath)\n",
    "    test_preds.append(model.predict([X_feature_test,X_static_test,X_stress_episode_test,\n",
    "                                    X_activity_episode_test,X_smoking_episode_test,X_quit_episode_test]))\n",
    "    bias_pred.append(model.predict([X_feature_val,X_static_val,X_stress_episode_val,X_activity_episode_val,\n",
    "                                    X_smoking_episode_val,X_quit_episode_val]))\n",
    "        \n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    y_test_pred = np.concatenate([MinMaxScaler().fit_transform(a.reshape(-1,1)) for a in test_preds],axis=1).mean(axis=1)\n",
    "    bias_pred = np.concatenate([MinMaxScaler().fit_transform(a.reshape(-1,1)) for a in bias_pred],axis=1).mean(axis=1)\n",
    "    print(f1Bias_scorer_CV(bias_pred,y_val))\n",
    "    print(f1Bias_scorer_CV(y_test_pred,y_test))\n",
    "    print(roc_auc_score(y_test,y_test_pred))\n",
    "    final_y_time.extend(list(time_test))\n",
    "    final_probs.extend(list(y_test_pred))\n",
    "    final_y.extend(list(y_test))\n",
    "    final_groups.extend(list(groups_test))\n",
    "    for group_b in np.unique(groups_test):\n",
    "        bias_dict[group_b] = kk\n",
    "    val_results[kk] = [time_val,bias_pred,y_val,groups_val]\n",
    "#     print(len(np.unique(final_groups)))\n",
    "#     print(bias_dict)\n",
    "final_y_time,final_probs,final_y,final_groups = np.array(final_y_time),np.array(final_probs),np.array(final_y),np.array(final_groups)\n",
    "pickle.dump([final_y_time,final_probs,final_y,final_groups,bias_dict,val_results],open('./data/output/episode_encoded_lag_'+str(n_lag)+'_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_10-100_f1_no_fpr_test.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights(filepath)\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Model(model.input,model.get_layer('dense_552').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.predict([X_feature_test,X_static_test,X_stress_episode_test,\n",
    "                                       X_activity_episode_test,X_smoking_episode_test,X_quit_episode_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_static_test[0],X_static_test[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = './models/episode_model.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, mode='min',save_weights_only=False)\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=0,patience=40)\n",
    "callbacks_list = [es,checkpoint]\n",
    "train_feature,val_feature,train_static,val_static,train_stress,val_stress, \\\n",
    "train_smoking,val_smoking,train_quit,val_quit,train_activity,val_activity, \\\n",
    "train_y,val_y = train_test_split(train_feature,\n",
    "                                 train_static,\n",
    "                                 train_stress,\n",
    "                                 train_smoking,\n",
    "                                 train_quit,\n",
    "                                 train_activity,\n",
    "                                 train_y,\n",
    "                                 test_size=.1,stratify=train_y)\n",
    "# train_y = tf.cast(train_y, tf.float32)\n",
    "# train_x = tf.cast(train_x, tf.float32)\n",
    "# val_y = tf.cast(val_y, tf.float32)\n",
    "# val_x = tf.cast(val_x, tf.float32)\n",
    "# history = model.fit(train_x,train_y,validation_data=(val_x,val_y), epochs=200, batch_size=30,\n",
    "#                     verbose=0,callbacks=callbacks_list,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit([train_feature,train_static,train_stress,train_activity,train_smoking,train_quit],train_y,\n",
    "          validation_data=([val_feature,val_static,val_stress,val_activity,val_smoking,val_quit],val_y), epochs=200, batch_size=30,\n",
    "                    verbose=1,callbacks=callbacks_list,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,\n",
    "               np.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(final_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "filepath = './models/'+'-'.join([str(n_lag),str(n_groups)])+'-'+str(uuid.uuid4())+'.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min',save_weights_only=False)\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=0,patience=40)\n",
    "callbacks_list = [es,checkpoint]\n",
    "train_x,val_x,train_y,val_y = train_test_split(X_train,y_train,test_size=.2,stratify=y_train)\n",
    "history = model.fit(train_x,train_y,validation_data=(val_x,val_y), epochs=100, batch_size=100,verbose=1,callbacks=callbacks_list,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc,roc_auc_score,f1_score\n",
    "roc_auc_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.Variable(np.arange(10)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "51b244ab9aca612e739a0539ae1af887c58db9e180d786deb0ab1761def69c1f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('test1': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
