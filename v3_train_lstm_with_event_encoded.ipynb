{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azim/miniconda3/envs/test1/lib/python3.8/site-packages/tensorflow_addons/utils/ensure_tf_install.py:38: UserWarning: You are currently using a nightly version of TensorFlow (2.5.0-dev20210310). \n",
      "TensorFlow Addons offers no support for the nightly versions of TensorFlow. Some things might work, some other might not. \n",
      "If you encounter a bug, do not file an issue on GitHub.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime,timedelta\n",
    "from scipy.stats import iqr,skew,kurtosis,mode\n",
    "from joblib import Parallel,delayed\n",
    "import zipfile\n",
    "import shutil\n",
    "from sklearn.feature_selection import SelectKBest,f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import f1_score,r2_score,classification_report\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,RandomForestRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix,f1_score,precision_score,recall_score,accuracy_score\n",
    "import itertools\n",
    "from sklearn.model_selection import ParameterGrid, cross_val_predict, GroupKFold,GridSearchCV,StratifiedKFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "seed = 100\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from sklearn.model_selection import train_test_split,LeavePGroupsOut\n",
    "from keras.backend import expand_dims, repeat_elements\n",
    "from keras.layers import Lambda\n",
    "from tensorflow.keras.layers import Conv1D,BatchNormalization,Dropout,InputLayer,MaxPooling1D,Flatten,RepeatVector,Dense,Input,Activation,GRU,Bidirectional,LSTM\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow_addons as tfa\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[-1], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y_groups(n_lag=10):\n",
    "    data = pickle.load(open('./data/episode_encoded_lagged_data/episode_encoded_lagged_'+str(n_lag)+'_windows_standardized.p','rb'))\n",
    "\n",
    "    X_feature = np.concatenate(data.feature_final.values)\n",
    "    X_static =  np.concatenate(data.static_features.values)\n",
    "\n",
    "    X_stress_episode = np.concatenate(data.stress_episode.values)\n",
    "    X_quit_episode = np.concatenate(data.quit_episode.values)\n",
    "    X_activity_episode = np.concatenate(data.activity_episode.values)\n",
    "    X_smoking_episode = np.concatenate(data.smoking_episode.values)\n",
    "\n",
    "    y_time = data['time'].values\n",
    "    y = data['label'].values\n",
    "    groups = data['user'].values\n",
    "    \n",
    "    return X_feature,X_static,X_stress_episode,X_quit_episode,X_activity_episode,X_smoking_episode,y_time,y,groups\n",
    "\n",
    "\n",
    "def get_train_test_indexes(groups,n_groups_split = 10,n_val_groups = 5):\n",
    "    groups_unique = np.unique(groups)\n",
    "    groups_split = np.array_split(groups_unique,n_groups_split)\n",
    "    indexes = []\n",
    "    for this_groups in groups_split:\n",
    "        train_groups = np.array([a for a in groups_unique if a not in this_groups])\n",
    "        val_groups = np.random.choice(train_groups,n_val_groups)\n",
    "        train_groups = np.array([a for a in groups_unique if a not in list(this_groups)+list(val_groups)])\n",
    "        test_groups = this_groups\n",
    "        train_index,test_index = np.array([i for i,a in enumerate(groups) \n",
    "                                           if a in train_groups]),np.array([i for i,a in enumerate(groups) \n",
    "                                                                               if a in test_groups])\n",
    "        val_index = np.array([i for i,a in enumerate(groups) \n",
    "                                           if a in val_groups])\n",
    "        indexes.append([train_index,test_index,val_index])\n",
    "    return indexes\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "def f1Bias_scorer_CV(probs, y, ret_bias=True):\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(y, probs)\n",
    "\n",
    "    f1,bias = 0.0,.5\n",
    "    min_recall = .7\n",
    "    for i in range(0, len(thresholds)):\n",
    "        if not (precision[i] == 0 and recall[i] == 0) and recall[i]>min_recall:\n",
    "            f = 2 * (precision[i] * recall[i]) / (precision[i] + recall[i])\n",
    "            if f > f1:\n",
    "                f1 = f\n",
    "                bias = thresholds[i]\n",
    "\n",
    "    if ret_bias:\n",
    "        return f1, bias\n",
    "    else:\n",
    "        return f1\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    n_t,n_f = train_feature.shape[1],train_feature.shape[2]\n",
    "#     print(n_t,n_f)\n",
    "    x_input = Input(shape=(n_t,n_f))\n",
    "    x_feature = Conv1D(100,1,activation='linear')(x_input)\n",
    "    x_feature = Conv1D(100,1,activation='tanh')(x_feature)\n",
    "    x_feature = Dropout(.2)(x_feature)\n",
    "    x_feature = LSTM(20,activation='tanh',return_sequences=False)(x_feature)\n",
    "    x_feature = Dropout(.3)(x_feature)\n",
    "    x_feature = Flatten()(x_feature)\n",
    "    x_feature = Dense(10,activation='relu')(x_feature)\n",
    "    # x_final = Dense(1,activation='sigmoid')(x_feature)\n",
    "\n",
    "    n_sf = train_static.shape[1]\n",
    "    x_input_static = Input(shape=(n_sf))\n",
    "    x_static = Dense(100,activation='relu')(x_input_static)\n",
    "    x_static = Dense(10,activation='relu')(x_static)\n",
    "    n_timesteps = train_stress.shape[-2]\n",
    "    n_episodes_stress,n_episodes_quit,n_episodes_activity,n_episodes_smoking = train_stress.shape[1],train_quit.shape[1],train_activity.shape[1],train_smoking.shape[1]\n",
    "    x_alpha_stress = Dense(1,activation='sigmoid')(x_static)\n",
    "    x_alpha_stress = RepeatVector(n_timesteps)(x_alpha_stress)\n",
    "    x_alpha_stress = Lambda(lambda x: repeat_elements(expand_dims(x, axis=1), n_episodes_stress, 1))(x_alpha_stress)\n",
    "    x_alpha_quit = Dense(1,activation='sigmoid')(x_static)\n",
    "    x_alpha_quit = RepeatVector(n_timesteps)(x_alpha_quit)\n",
    "    x_alpha_quit = Lambda(lambda x: repeat_elements(expand_dims(x, axis=1), n_episodes_quit, 1))(x_alpha_quit)\n",
    "    x_alpha_activity = Dense(1,activation='sigmoid')(x_static)\n",
    "    x_alpha_activity = RepeatVector(n_timesteps)(x_alpha_activity)\n",
    "    x_alpha_activity = Lambda(lambda x: repeat_elements(expand_dims(x, axis=1), n_episodes_activity, 1))(x_alpha_activity)\n",
    "    x_alpha_smoking = Dense(1,activation='sigmoid')(x_static)\n",
    "    x_alpha_smoking = RepeatVector(n_timesteps)(x_alpha_smoking)\n",
    "    x_alpha_smoking = Lambda(lambda x: repeat_elements(expand_dims(x, axis=1), n_episodes_smoking, 1))(x_alpha_smoking)\n",
    "\n",
    "    n_dim = 3\n",
    "    x_stress = Input(shape=(n_episodes_stress,n_timesteps,n_dim))\n",
    "    stress_alpha_time = tf.math.multiply(x_alpha_stress[:,:,:,0]*-1,x_stress[:,:,:,0])\n",
    "    stress_alpha_time_exp = tf.math.exp(stress_alpha_time)\n",
    "\n",
    "    x_stress_amplitude = x_stress[:,:,:,1]\n",
    "    stress_amplitude_coeff = Dense(1,activation='sigmoid')(x_feature)\n",
    "    stress_amplitude_coeff = Lambda(lambda x: expand_dims(x, axis=2))(stress_amplitude_coeff)\n",
    "    print(stress_amplitude_coeff.shape,'coeff',x_stress_amplitude.shape,'amplitude')\n",
    "    x_stress_amplitude = tf.math.multiply(x_stress_amplitude,stress_amplitude_coeff)\n",
    "#     print(x_stress_amplitude.shape,'final')\n",
    "    \n",
    "    x_stress_duration = x_stress[:,:,:,2]\n",
    "    stress_duration_coeff = Dense(1,activation='sigmoid')(x_feature)\n",
    "    stress_duration_coeff = Lambda(lambda x: expand_dims(x, axis=2))(stress_duration_coeff)\n",
    "    x_stress_duration = tf.math.multiply(x_stress_duration,stress_duration_coeff)\n",
    "    \n",
    "    x_stress_all = tf.math.add(x_stress_amplitude,x_stress_duration)\n",
    "    \n",
    "#     print(x_stress_all.shape,stress_alpha_time_exp.shape)\n",
    "    stress_alpha_time_exp_amplitude = tf.math.multiply(stress_alpha_time_exp,x_stress_all)\n",
    "    \n",
    "#     print(stress_alpha_time_exp_amplitude.shape)\n",
    "    stress_final = tf.math.reduce_sum(stress_alpha_time_exp_amplitude,axis=1)\n",
    "#     print(stress_final.shape)\n",
    "    stress_final = Lambda(lambda x: expand_dims(x, axis=2))(stress_final)\n",
    "#     print(stress_final.shape)\n",
    "    stress_final = LSTM(10,activation='tanh',return_sequences=True)(stress_final)\n",
    "    \n",
    "    \n",
    "    \n",
    "    x_quit = Input(shape=(n_episodes_quit,n_timesteps,n_dim))\n",
    "#     quit_alpha_time = tf.math.multiply(x_alpha_quit[:,:,:,0]*-1,x_quit[:,:,:,0])\n",
    "#     quit_alpha_time_exp = tf.math.exp(quit_alpha_time)\n",
    "#     quit_alpha_time_exp_amplitude = tf.math.multiply(quit_alpha_time_exp,x_quit[:,:,:,1])\n",
    "#     quit_final = tf.math.reduce_sum(quit_alpha_time_exp_amplitude,axis=1)\n",
    "#     quit_final = Lambda(lambda x: expand_dims(x, axis=2))(quit_final)\n",
    "#     quit_final = LSTM(5,activation='tanh',return_sequences=True)(quit_final)\n",
    "\n",
    "    \n",
    "    \n",
    "    x_smoking = Input(shape=(n_episodes_smoking,n_timesteps,n_dim))\n",
    "    smoking_alpha_time = tf.math.multiply(x_alpha_smoking[:,:,:,0]*-1,x_smoking[:,:,:,0])\n",
    "    smoking_alpha_time_exp = tf.math.exp(smoking_alpha_time)\n",
    "    \n",
    "    x_smoking_amplitude = x_smoking[:,:,:,1]\n",
    "    smoking_amplitude_coeff = Dense(1,activation='sigmoid')(x_feature)\n",
    "    smoking_amplitude_coeff = Lambda(lambda x: expand_dims(x, axis=2))(smoking_amplitude_coeff)\n",
    "    x_smoking_amplitude = tf.math.multiply(x_smoking_amplitude,smoking_amplitude_coeff)\n",
    "    \n",
    "    x_smoking_duration = x_smoking[:,:,:,2]\n",
    "    smoking_duration_coeff = Dense(1,activation='sigmoid')(x_feature)\n",
    "    smoking_duration_coeff = Lambda(lambda x: expand_dims(x, axis=2))(smoking_duration_coeff)\n",
    "    x_smoking_duration = tf.math.multiply(x_smoking_duration,smoking_duration_coeff)\n",
    "    \n",
    "    x_smoking_all = tf.math.add(x_smoking_amplitude,x_smoking_duration)\n",
    "    smoking_alpha_time_exp_amplitude = tf.math.multiply(smoking_alpha_time_exp,x_smoking_all)\n",
    "    smoking_final = tf.math.reduce_sum(smoking_alpha_time_exp_amplitude,axis=1)\n",
    "    smoking_final = Lambda(lambda x: expand_dims(x, axis=2))(smoking_final)\n",
    "    smoking_final = LSTM(10,activation='tanh',return_sequences=True)(smoking_final)\n",
    "\n",
    "    \n",
    "    \n",
    "    x_activity = Input(shape=(n_episodes_activity,n_timesteps,n_dim))\n",
    "    activity_alpha_time = tf.math.multiply(x_alpha_activity[:,:,:,0]*-1,x_activity[:,:,:,0])\n",
    "    activity_alpha_time_exp = tf.math.exp(activity_alpha_time)\n",
    "    \n",
    "    x_activity_amplitude = x_activity[:,:,:,1]\n",
    "    activity_amplitude_coeff = Dense(1,activation='sigmoid')(x_feature)\n",
    "    activity_amplitude_coeff = Lambda(lambda x: expand_dims(x, axis=2))(activity_amplitude_coeff)\n",
    "    x_activity_amplitude = tf.math.multiply(x_activity_amplitude,activity_amplitude_coeff)\n",
    "    \n",
    "    x_activity_duration = x_activity[:,:,:,2]\n",
    "    activity_duration_coeff = Dense(1,activation='sigmoid')(x_feature)\n",
    "    activity_duration_coeff = Lambda(lambda x: expand_dims(x, axis=2))(activity_duration_coeff)\n",
    "#     print(activity_duration_coeff)\n",
    "    x_activity_duration = tf.math.multiply(x_activity_duration,activity_duration_coeff)\n",
    "    \n",
    "    x_activity_all = tf.math.add(x_activity_amplitude,x_activity_duration)\n",
    "    activity_alpha_time_exp_amplitude = tf.math.multiply(activity_alpha_time_exp,x_activity_all)\n",
    "    activity_final = tf.math.reduce_sum(activity_alpha_time_exp_amplitude,axis=1)\n",
    "    activity_final = Lambda(lambda x: expand_dims(x, axis=2))(activity_final)\n",
    "    activity_final = LSTM(10,activation='tanh',return_sequences=True)(activity_final)\n",
    "    \n",
    "    \n",
    "    x_episode = tf.concat([activity_final,stress_final,smoking_final],2)\n",
    "    x_episode = Conv1D(100,10,activation='relu')(x_episode)\n",
    "    x_episode = Conv1D(100,10,activation='tanh')(x_episode)\n",
    "    x_episode = LSTM(100,activation='tanh',return_sequences=True)(x_episode)\n",
    "    x_episode = LSTM(20,activation='tanh',return_sequences=False)(x_episode)\n",
    "    x_episode = Dropout(.3)(x_episode)\n",
    "    x_episode = Flatten()(x_episode)\n",
    "    x_episode = Dense(10,activation='relu')(x_episode)\n",
    "\n",
    "    merged = tf.concat([x_feature,x_episode],1)\n",
    "\n",
    "    merged = Dense(10,activation='relu')(merged)\n",
    "    output = Dense(1,activation='sigmoid')(merged)\n",
    "    # output = Activation('softmax',name='softmax')(output)\n",
    "    model = Model(inputs=[x_input,x_input_static,x_stress,x_activity,x_smoking,x_quit], outputs=[output])\n",
    "    model.compile(loss=myloss(1),metrics=['acc',tfa.metrics.F1Score(num_classes=2,average='micro',threshold=.5)])\n",
    "    return model\n",
    "# tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "def myloss(alpha=.2):\n",
    "    \n",
    "    def custom_loss(true,pred):\n",
    "        m = tf.keras.losses.BinaryCrossentropy()\n",
    "        return f1_loss(true,pred)+m(true,pred)*alpha\n",
    "    \n",
    "    \n",
    "    def f1_weighted(true, pred): #shapes (batch, 4)\n",
    "\n",
    "        #for metrics include these two lines, for loss, don't include them\n",
    "        #these are meant to round 'pred' to exactly zeros and ones\n",
    "        #predLabels = K.argmax(pred, axis=-1)\n",
    "        #pred = K.one_hot(predLabels, 4) \n",
    "\n",
    "\n",
    "        ground_positives = K.sum(true, axis=0) + K.epsilon()       # = TP + FN\n",
    "        pred_positives = K.sum(pred, axis=0) + K.epsilon()         # = TP + FP\n",
    "        true_positives = K.sum(true * pred, axis=0) + K.epsilon()  # = TP\n",
    "            #all with shape (4,)\n",
    "\n",
    "        precision = true_positives / pred_positives \n",
    "        recall = true_positives / ground_positives\n",
    "            #both = 1 if ground_positives == 0 or pred_positives == 0\n",
    "            #shape (4,)\n",
    "\n",
    "        f1 = 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
    "            #still with shape (4,)\n",
    "        # print(f1)\n",
    "        # weighted_f1 = f1 * ground_positives / K.sum(ground_positives) \n",
    "        weighted_f1 = K.sum(f1)\n",
    "\n",
    "\n",
    "        return 1 - weighted_f1\n",
    "\n",
    "    def f1_loss(y_true, y_pred):\n",
    "    \n",
    "        tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "        tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "        fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "        fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "        p = tp / (tp + fp + K.epsilon())\n",
    "        r = tp / (tp + fn + K.epsilon())\n",
    "        fpr = fp/(fp+tn+K.epsilon())\n",
    "        f1 = 2*p*r / (p+r+K.epsilon())\n",
    "        # f1 = tf.where(tf(f1), tf.zeros_like(f1), f1)\n",
    "        return fpr+1-K.mean(f1)\n",
    "    return custom_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280 (16489,)\n",
      "28160\n",
      "(None, 1, 1) coeff (None, 5, 30) amplitude\n",
      "Epoch 1/300\n",
      "141/141 [==============================] - 17s 57ms/step - loss: 1.2505 - acc: 0.9016 - f1_score: 0.1088 - val_loss: 1.3937 - val_acc: 0.9073 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.00000, saving model to ./models/lag_15_iter_0_split_0_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_f1_both.hdf5\n",
      "Epoch 2/300\n",
      "141/141 [==============================] - 6s 44ms/step - loss: 0.4919 - acc: 0.9593 - f1_score: 0.7364 - val_loss: 1.5300 - val_acc: 0.9159 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_f1_score did not improve from 0.00000\n",
      "Epoch 3/300\n",
      "141/141 [==============================] - 6s 44ms/step - loss: 0.2170 - acc: 0.9814 - f1_score: 0.8934 - val_loss: 1.5307 - val_acc: 0.9118 - val_f1_score: 0.0789\n",
      "\n",
      "Epoch 00003: val_f1_score improved from 0.00000 to 0.07895, saving model to ./models/lag_15_iter_0_split_0_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_f1_both.hdf5\n",
      "Epoch 4/300\n",
      "141/141 [==============================] - 6s 43ms/step - loss: 0.1579 - acc: 0.9856 - f1_score: 0.9210 - val_loss: 1.4838 - val_acc: 0.9259 - val_f1_score: 0.1637\n",
      "\n",
      "Epoch 00004: val_f1_score improved from 0.07895 to 0.16370, saving model to ./models/lag_15_iter_0_split_0_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_f1_both.hdf5\n",
      "Epoch 5/300\n",
      "141/141 [==============================] - 6s 43ms/step - loss: 0.1073 - acc: 0.9906 - f1_score: 0.9466 - val_loss: 1.5323 - val_acc: 0.9203 - val_f1_score: 0.1060\n",
      "\n",
      "Epoch 00005: val_f1_score did not improve from 0.16370\n",
      "Epoch 6/300\n",
      "141/141 [==============================] - 6s 43ms/step - loss: 0.1165 - acc: 0.9899 - f1_score: 0.9418 - val_loss: 1.7320 - val_acc: 0.9007 - val_f1_score: 0.0708\n",
      "\n",
      "Epoch 00006: val_f1_score did not improve from 0.16370\n",
      "Epoch 7/300\n",
      "141/141 [==============================] - 6s 44ms/step - loss: 0.0944 - acc: 0.9916 - f1_score: 0.9521 - val_loss: 1.6961 - val_acc: 0.9048 - val_f1_score: 0.0958\n",
      "\n",
      "Epoch 00007: val_f1_score did not improve from 0.16370\n",
      "Epoch 8/300\n",
      "141/141 [==============================] - 6s 45ms/step - loss: 0.0821 - acc: 0.9929 - f1_score: 0.9610 - val_loss: 1.7035 - val_acc: 0.9168 - val_f1_score: 0.0704\n",
      "\n",
      "Epoch 00008: val_f1_score did not improve from 0.16370\n",
      "Epoch 9/300\n",
      "141/141 [==============================] - 6s 44ms/step - loss: 0.0647 - acc: 0.9945 - f1_score: 0.9700 - val_loss: 1.6615 - val_acc: 0.9310 - val_f1_score: 0.0179\n",
      "\n",
      "Epoch 00009: val_f1_score did not improve from 0.16370\n",
      "Epoch 10/300\n",
      "141/141 [==============================] - 6s 45ms/step - loss: 0.0689 - acc: 0.9941 - f1_score: 0.9674 - val_loss: 1.6693 - val_acc: 0.9140 - val_f1_score: 0.0746\n",
      "\n",
      "Epoch 00010: val_f1_score did not improve from 0.16370\n",
      "Epoch 11/300\n",
      "141/141 [==============================] - 6s 44ms/step - loss: 0.0547 - acc: 0.9951 - f1_score: 0.9728 - val_loss: 1.7397 - val_acc: 0.9102 - val_f1_score: 0.0532\n",
      "\n",
      "Epoch 00011: val_f1_score did not improve from 0.16370\n",
      "Epoch 12/300\n",
      "141/141 [==============================] - 5s 37ms/step - loss: 0.0594 - acc: 0.9944 - f1_score: 0.9696 - val_loss: 1.7294 - val_acc: 0.9168 - val_f1_score: 0.1081\n",
      "\n",
      "Epoch 00012: val_f1_score did not improve from 0.16370\n",
      "Epoch 13/300\n",
      "141/141 [==============================] - 5s 36ms/step - loss: 0.0484 - acc: 0.9957 - f1_score: 0.9765 - val_loss: 1.7625 - val_acc: 0.9184 - val_f1_score: 0.1395\n",
      "\n",
      "Epoch 00013: val_f1_score did not improve from 0.16370\n",
      "Epoch 14/300\n",
      "141/141 [==============================] - 6s 42ms/step - loss: 0.0505 - acc: 0.9957 - f1_score: 0.9760 - val_loss: 1.8874 - val_acc: 0.9001 - val_f1_score: 0.0865\n",
      "\n",
      "Epoch 00014: val_f1_score did not improve from 0.16370\n",
      "Epoch 15/300\n",
      "141/141 [==============================] - 6s 41ms/step - loss: 0.0505 - acc: 0.9957 - f1_score: 0.9763 - val_loss: 1.7895 - val_acc: 0.9130 - val_f1_score: 0.1097\n",
      "\n",
      "Epoch 00015: val_f1_score did not improve from 0.16370\n",
      "Epoch 16/300\n",
      "141/141 [==============================] - 6s 45ms/step - loss: 0.0514 - acc: 0.9947 - f1_score: 0.9710 - val_loss: 2.0022 - val_acc: 0.8951 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00016: val_f1_score did not improve from 0.16370\n",
      "Epoch 17/300\n",
      "141/141 [==============================] - 6s 44ms/step - loss: 0.0468 - acc: 0.9958 - f1_score: 0.9767 - val_loss: 1.8838 - val_acc: 0.8843 - val_f1_score: 0.1324\n",
      "\n",
      "Epoch 00017: val_f1_score did not improve from 0.16370\n",
      "Epoch 18/300\n",
      "141/141 [==============================] - 6s 44ms/step - loss: 0.0494 - acc: 0.9953 - f1_score: 0.9746 - val_loss: 1.7815 - val_acc: 0.9143 - val_f1_score: 0.0556\n",
      "\n",
      "Epoch 00018: val_f1_score did not improve from 0.16370\n",
      "Epoch 19/300\n",
      "141/141 [==============================] - 6s 44ms/step - loss: 0.0456 - acc: 0.9958 - f1_score: 0.9769 - val_loss: 1.7545 - val_acc: 0.9149 - val_f1_score: 0.0816\n",
      "\n",
      "Epoch 00019: val_f1_score did not improve from 0.16370\n",
      "Epoch 20/300\n",
      "141/141 [==============================] - 6s 45ms/step - loss: 0.0377 - acc: 0.9965 - f1_score: 0.9812 - val_loss: 1.8189 - val_acc: 0.9187 - val_f1_score: 0.0786\n",
      "\n",
      "Epoch 00020: val_f1_score did not improve from 0.16370\n",
      "Epoch 21/300\n",
      "141/141 [==============================] - 6s 45ms/step - loss: 0.0415 - acc: 0.9962 - f1_score: 0.9781 - val_loss: 1.9374 - val_acc: 0.9039 - val_f1_score: 0.0841\n",
      "\n",
      "Epoch 00021: val_f1_score did not improve from 0.16370\n",
      "Epoch 22/300\n",
      "141/141 [==============================] - 6s 44ms/step - loss: 0.0439 - acc: 0.9959 - f1_score: 0.9781 - val_loss: 1.8948 - val_acc: 0.8925 - val_f1_score: 0.1097\n",
      "\n",
      "Epoch 00022: val_f1_score did not improve from 0.16370\n",
      "Epoch 23/300\n",
      "141/141 [==============================] - 6s 45ms/step - loss: 0.0414 - acc: 0.9961 - f1_score: 0.9784 - val_loss: 1.7817 - val_acc: 0.9149 - val_f1_score: 0.0690\n",
      "\n",
      "Epoch 00023: val_f1_score did not improve from 0.16370\n",
      "Epoch 24/300\n",
      "141/141 [==============================] - 6s 44ms/step - loss: 0.0371 - acc: 0.9966 - f1_score: 0.9822 - val_loss: 1.8166 - val_acc: 0.9089 - val_f1_score: 0.0462\n",
      "\n",
      "Epoch 00024: val_f1_score did not improve from 0.16370\n",
      "Epoch 25/300\n",
      "141/141 [==============================] - 6s 44ms/step - loss: 0.0326 - acc: 0.9972 - f1_score: 0.9843 - val_loss: 2.0070 - val_acc: 0.8913 - val_f1_score: 0.0800\n",
      "\n",
      "Epoch 00025: val_f1_score did not improve from 0.16370\n",
      "Epoch 26/300\n",
      "141/141 [==============================] - 6s 44ms/step - loss: 0.0332 - acc: 0.9970 - f1_score: 0.9836 - val_loss: 1.9504 - val_acc: 0.9004 - val_f1_score: 0.0366\n",
      "\n",
      "Epoch 00026: val_f1_score did not improve from 0.16370\n",
      "Epoch 27/300\n",
      "141/141 [==============================] - 6s 44ms/step - loss: 0.0209 - acc: 0.9981 - f1_score: 0.9897 - val_loss: 1.9132 - val_acc: 0.9108 - val_f1_score: 0.0471\n",
      "\n",
      "Epoch 00027: val_f1_score did not improve from 0.16370\n",
      "Epoch 28/300\n",
      "141/141 [==============================] - 6s 44ms/step - loss: 0.0261 - acc: 0.9975 - f1_score: 0.9858 - val_loss: 1.9345 - val_acc: 0.8988 - val_f1_score: 0.0418\n",
      "\n",
      "Epoch 00028: val_f1_score did not improve from 0.16370\n",
      "Epoch 29/300\n",
      "141/141 [==============================] - 6s 44ms/step - loss: 0.0284 - acc: 0.9977 - f1_score: 0.9875 - val_loss: 1.7749 - val_acc: 0.9184 - val_f1_score: 0.0582\n",
      "\n",
      "Epoch 00029: val_f1_score did not improve from 0.16370\n",
      "Epoch 30/300\n",
      "141/141 [==============================] - 6s 45ms/step - loss: 0.0280 - acc: 0.9976 - f1_score: 0.9866 - val_loss: 2.0840 - val_acc: 0.8799 - val_f1_score: 0.0403\n",
      "\n",
      "Epoch 00030: val_f1_score did not improve from 0.16370\n",
      "Epoch 31/300\n",
      "141/141 [==============================] - 6s 44ms/step - loss: 0.0383 - acc: 0.9967 - f1_score: 0.9815 - val_loss: 1.9985 - val_acc: 0.8840 - val_f1_score: 0.0417\n",
      "\n",
      "Epoch 00031: val_f1_score did not improve from 0.16370\n",
      "Epoch 32/300\n",
      "141/141 [==============================] - 6s 44ms/step - loss: 0.0312 - acc: 0.9975 - f1_score: 0.9863 - val_loss: 2.0455 - val_acc: 0.8928 - val_f1_score: 0.0395\n",
      "\n",
      "Epoch 00032: val_f1_score did not improve from 0.16370\n",
      "Epoch 33/300\n",
      "141/141 [==============================] - 6s 44ms/step - loss: 0.0279 - acc: 0.9977 - f1_score: 0.9873 - val_loss: 1.9608 - val_acc: 0.8938 - val_f1_score: 0.0716\n",
      "\n",
      "Epoch 00033: val_f1_score did not improve from 0.16370\n",
      "Epoch 34/300\n",
      "141/141 [==============================] - 6s 44ms/step - loss: 0.0356 - acc: 0.9970 - f1_score: 0.9836 - val_loss: 1.8695 - val_acc: 0.9108 - val_f1_score: 0.0535\n",
      "\n",
      "Epoch 00034: val_f1_score did not improve from 0.16370\n",
      "Epoch 35/300\n",
      "141/141 [==============================] - 6s 45ms/step - loss: 0.0257 - acc: 0.9975 - f1_score: 0.9867 - val_loss: 1.8524 - val_acc: 0.9127 - val_f1_score: 0.0072\n",
      "\n",
      "Epoch 00035: val_f1_score did not improve from 0.16370\n",
      "Epoch 36/300\n",
      "141/141 [==============================] - 6s 44ms/step - loss: 0.0294 - acc: 0.9973 - f1_score: 0.9852 - val_loss: 1.7979 - val_acc: 0.9067 - val_f1_score: 0.1294\n",
      "\n",
      "Epoch 00036: val_f1_score did not improve from 0.16370\n",
      "Epoch 37/300\n",
      "141/141 [==============================] - 6s 45ms/step - loss: 0.0213 - acc: 0.9982 - f1_score: 0.9902 - val_loss: 2.0647 - val_acc: 0.8768 - val_f1_score: 0.0440\n",
      "\n",
      "Epoch 00037: val_f1_score did not improve from 0.16370\n",
      "Epoch 38/300\n",
      "141/141 [==============================] - 6s 44ms/step - loss: 0.0240 - acc: 0.9976 - f1_score: 0.9868 - val_loss: 1.9766 - val_acc: 0.8988 - val_f1_score: 0.0907\n",
      "\n",
      "Epoch 00038: val_f1_score did not improve from 0.16370\n",
      "Epoch 39/300\n",
      "141/141 [==============================] - 6s 44ms/step - loss: 0.0296 - acc: 0.9976 - f1_score: 0.9862 - val_loss: 1.9382 - val_acc: 0.8976 - val_f1_score: 0.0181\n",
      "\n",
      "Epoch 00039: val_f1_score did not improve from 0.16370\n",
      "Epoch 40/300\n",
      "141/141 [==============================] - 6s 45ms/step - loss: 0.0202 - acc: 0.9983 - f1_score: 0.9902 - val_loss: 1.8904 - val_acc: 0.9143 - val_f1_score: 0.0216\n",
      "\n",
      "Epoch 00040: val_f1_score did not improve from 0.16370\n",
      "Epoch 41/300\n",
      "141/141 [==============================] - 6s 44ms/step - loss: 0.0284 - acc: 0.9974 - f1_score: 0.9861 - val_loss: 2.0040 - val_acc: 0.8875 - val_f1_score: 0.0727\n",
      "\n",
      "Epoch 00041: val_f1_score did not improve from 0.16370\n",
      "Epoch 42/300\n",
      "141/141 [==============================] - 6s 44ms/step - loss: 0.0218 - acc: 0.9981 - f1_score: 0.9895 - val_loss: 1.9544 - val_acc: 0.8957 - val_f1_score: 0.0728\n",
      "\n",
      "Epoch 00042: val_f1_score did not improve from 0.16370\n",
      "Epoch 43/300\n",
      "141/141 [==============================] - 6s 43ms/step - loss: 0.0224 - acc: 0.9980 - f1_score: 0.9889 - val_loss: 2.0406 - val_acc: 0.8887 - val_f1_score: 0.1108\n",
      "\n",
      "Epoch 00043: val_f1_score did not improve from 0.16370\n",
      "Epoch 44/300\n",
      "141/141 [==============================] - 6s 45ms/step - loss: 0.0220 - acc: 0.9980 - f1_score: 0.9894 - val_loss: 1.9034 - val_acc: 0.9014 - val_f1_score: 0.1183\n",
      "\n",
      "Epoch 00044: val_f1_score did not improve from 0.16370\n",
      "Epoch 00044: early stopping\n",
      "(0.09929942126104173, 2.014685e-06)\n",
      "(0.17132711939636042, 1.5311442e-06)\n",
      "0.4352717203184493\n",
      "1315 (19555,)\n",
      "28930\n",
      "(None, 1, 1) coeff (None, 5, 30) amplitude\n",
      "Epoch 1/300\n",
      "145/145 [==============================] - 15s 54ms/step - loss: 1.3205 - acc: 0.8967 - f1_score: 0.0792 - val_loss: 1.7452 - val_acc: 0.8516 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.00000, saving model to ./models/lag_15_iter_0_split_1_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_f1_both.hdf5\n",
      "Epoch 2/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.7626 - acc: 0.9366 - f1_score: 0.5337 - val_loss: 1.8447 - val_acc: 0.8575 - val_f1_score: 0.0968\n",
      "\n",
      "Epoch 00002: val_f1_score improved from 0.00000 to 0.09677, saving model to ./models/lag_15_iter_0_split_1_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_f1_both.hdf5\n",
      "Epoch 3/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.4909 - acc: 0.9586 - f1_score: 0.7403 - val_loss: 1.8756 - val_acc: 0.8634 - val_f1_score: 0.1202\n",
      "\n",
      "Epoch 00003: val_f1_score improved from 0.09677 to 0.12022, saving model to ./models/lag_15_iter_0_split_1_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_f1_both.hdf5\n",
      "Epoch 4/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.3054 - acc: 0.9743 - f1_score: 0.8469 - val_loss: 1.7319 - val_acc: 0.8753 - val_f1_score: 0.2462\n",
      "\n",
      "Epoch 00004: val_f1_score improved from 0.12022 to 0.24615, saving model to ./models/lag_15_iter_0_split_1_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_f1_both.hdf5\n",
      "Epoch 5/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.2395 - acc: 0.9799 - f1_score: 0.8824 - val_loss: 1.8990 - val_acc: 0.8787 - val_f1_score: 0.1921\n",
      "\n",
      "Epoch 00005: val_f1_score did not improve from 0.24615\n",
      "Epoch 6/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.1815 - acc: 0.9848 - f1_score: 0.9155 - val_loss: 1.9382 - val_acc: 0.8779 - val_f1_score: 0.2000\n",
      "\n",
      "Epoch 00006: val_f1_score did not improve from 0.24615\n",
      "Epoch 7/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.1600 - acc: 0.9865 - f1_score: 0.9236 - val_loss: 2.1618 - val_acc: 0.8405 - val_f1_score: 0.2101\n",
      "\n",
      "Epoch 00007: val_f1_score did not improve from 0.24615\n",
      "Epoch 8/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.1202 - acc: 0.9893 - f1_score: 0.9405 - val_loss: 2.1485 - val_acc: 0.8660 - val_f1_score: 0.1856\n",
      "\n",
      "Epoch 00008: val_f1_score did not improve from 0.24615\n",
      "Epoch 9/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.1222 - acc: 0.9888 - f1_score: 0.9371 - val_loss: 2.2087 - val_acc: 0.8685 - val_f1_score: 0.0828\n",
      "\n",
      "Epoch 00009: val_f1_score did not improve from 0.24615\n",
      "Epoch 10/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0969 - acc: 0.9913 - f1_score: 0.9520 - val_loss: 2.1700 - val_acc: 0.8643 - val_f1_score: 0.0805\n",
      "\n",
      "Epoch 00010: val_f1_score did not improve from 0.24615\n",
      "Epoch 11/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0771 - acc: 0.9934 - f1_score: 0.9645 - val_loss: 2.5141 - val_acc: 0.8533 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00011: val_f1_score did not improve from 0.24615\n",
      "Epoch 12/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0734 - acc: 0.9934 - f1_score: 0.9642 - val_loss: 2.3259 - val_acc: 0.8550 - val_f1_score: 0.0757\n",
      "\n",
      "Epoch 00012: val_f1_score did not improve from 0.24615\n",
      "Epoch 13/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0634 - acc: 0.9947 - f1_score: 0.9697 - val_loss: 2.6019 - val_acc: 0.8558 - val_f1_score: 0.0556\n",
      "\n",
      "Epoch 00013: val_f1_score did not improve from 0.24615\n",
      "Epoch 14/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0591 - acc: 0.9948 - f1_score: 0.9719 - val_loss: 2.6744 - val_acc: 0.8456 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00014: val_f1_score did not improve from 0.24615\n",
      "Epoch 15/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0496 - acc: 0.9953 - f1_score: 0.9748 - val_loss: 2.5396 - val_acc: 0.8448 - val_f1_score: 0.0108\n",
      "\n",
      "Epoch 00015: val_f1_score did not improve from 0.24615\n",
      "Epoch 16/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0580 - acc: 0.9950 - f1_score: 0.9706 - val_loss: 2.3244 - val_acc: 0.8694 - val_f1_score: 0.1979\n",
      "\n",
      "Epoch 00016: val_f1_score did not improve from 0.24615\n",
      "Epoch 17/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0530 - acc: 0.9956 - f1_score: 0.9754 - val_loss: 2.4084 - val_acc: 0.8651 - val_f1_score: 0.1117\n",
      "\n",
      "Epoch 00017: val_f1_score did not improve from 0.24615\n",
      "Epoch 18/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0476 - acc: 0.9961 - f1_score: 0.9780 - val_loss: 2.8170 - val_acc: 0.8584 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00018: val_f1_score did not improve from 0.24615\n",
      "Epoch 19/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0430 - acc: 0.9962 - f1_score: 0.9791 - val_loss: 2.5306 - val_acc: 0.8550 - val_f1_score: 0.0656\n",
      "\n",
      "Epoch 00019: val_f1_score did not improve from 0.24615\n",
      "Epoch 20/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0416 - acc: 0.9963 - f1_score: 0.9794 - val_loss: 2.6611 - val_acc: 0.8490 - val_f1_score: 0.0729\n",
      "\n",
      "Epoch 00020: val_f1_score did not improve from 0.24615\n",
      "Epoch 21/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0460 - acc: 0.9957 - f1_score: 0.9760 - val_loss: 2.5613 - val_acc: 0.8507 - val_f1_score: 0.0638\n",
      "\n",
      "Epoch 00021: val_f1_score did not improve from 0.24615\n",
      "Epoch 22/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0413 - acc: 0.9966 - f1_score: 0.9817 - val_loss: 2.7449 - val_acc: 0.8490 - val_f1_score: 0.0632\n",
      "\n",
      "Epoch 00022: val_f1_score did not improve from 0.24615\n",
      "Epoch 23/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0431 - acc: 0.9961 - f1_score: 0.9787 - val_loss: 2.8366 - val_acc: 0.8388 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00023: val_f1_score did not improve from 0.24615\n",
      "Epoch 24/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0389 - acc: 0.9965 - f1_score: 0.9811 - val_loss: 2.7780 - val_acc: 0.8465 - val_f1_score: 0.0524\n",
      "\n",
      "Epoch 00024: val_f1_score did not improve from 0.24615\n",
      "Epoch 25/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0370 - acc: 0.9968 - f1_score: 0.9823 - val_loss: 2.6396 - val_acc: 0.8643 - val_f1_score: 0.0361\n",
      "\n",
      "Epoch 00025: val_f1_score did not improve from 0.24615\n",
      "Epoch 26/300\n",
      "145/145 [==============================] - 6s 41ms/step - loss: 0.0327 - acc: 0.9972 - f1_score: 0.9843 - val_loss: 2.6788 - val_acc: 0.8584 - val_f1_score: 0.0670\n",
      "\n",
      "Epoch 00026: val_f1_score did not improve from 0.24615\n",
      "Epoch 27/300\n",
      "145/145 [==============================] - 5s 36ms/step - loss: 0.0392 - acc: 0.9966 - f1_score: 0.9810 - val_loss: 2.7354 - val_acc: 0.8541 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00027: val_f1_score did not improve from 0.24615\n",
      "Epoch 28/300\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.0354 - acc: 0.9969 - f1_score: 0.9834 - val_loss: 2.8647 - val_acc: 0.8584 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00028: val_f1_score did not improve from 0.24615\n",
      "Epoch 29/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0324 - acc: 0.9968 - f1_score: 0.9828 - val_loss: 3.1492 - val_acc: 0.8533 - val_f1_score: 0.0442\n",
      "\n",
      "Epoch 00029: val_f1_score did not improve from 0.24615\n",
      "Epoch 30/300\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 0.0354 - acc: 0.9968 - f1_score: 0.9822 - val_loss: 3.0117 - val_acc: 0.8533 - val_f1_score: 0.0847\n",
      "\n",
      "Epoch 00030: val_f1_score did not improve from 0.24615\n",
      "Epoch 31/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0320 - acc: 0.9971 - f1_score: 0.9843 - val_loss: 2.7631 - val_acc: 0.8567 - val_f1_score: 0.0865\n",
      "\n",
      "Epoch 00031: val_f1_score did not improve from 0.24615\n",
      "Epoch 32/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0278 - acc: 0.9976 - f1_score: 0.9860 - val_loss: 2.8253 - val_acc: 0.8558 - val_f1_score: 0.0860\n",
      "\n",
      "Epoch 00032: val_f1_score did not improve from 0.24615\n",
      "Epoch 33/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0311 - acc: 0.9974 - f1_score: 0.9853 - val_loss: 2.8234 - val_acc: 0.8550 - val_f1_score: 0.0757\n",
      "\n",
      "Epoch 00033: val_f1_score did not improve from 0.24615\n",
      "Epoch 34/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0339 - acc: 0.9970 - f1_score: 0.9834 - val_loss: 2.8724 - val_acc: 0.8490 - val_f1_score: 0.0632\n",
      "\n",
      "Epoch 00034: val_f1_score did not improve from 0.24615\n",
      "Epoch 35/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0289 - acc: 0.9975 - f1_score: 0.9860 - val_loss: 2.7981 - val_acc: 0.8550 - val_f1_score: 0.0757\n",
      "\n",
      "Epoch 00035: val_f1_score did not improve from 0.24615\n",
      "Epoch 36/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0276 - acc: 0.9976 - f1_score: 0.9869 - val_loss: 2.9664 - val_acc: 0.8490 - val_f1_score: 0.0326\n",
      "\n",
      "Epoch 00036: val_f1_score did not improve from 0.24615\n",
      "Epoch 37/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0206 - acc: 0.9981 - f1_score: 0.9899 - val_loss: 3.1448 - val_acc: 0.8397 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00037: val_f1_score did not improve from 0.24615\n",
      "Epoch 38/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0246 - acc: 0.9980 - f1_score: 0.9888 - val_loss: 3.1745 - val_acc: 0.8329 - val_f1_score: 0.0664\n",
      "\n",
      "Epoch 00038: val_f1_score did not improve from 0.24615\n",
      "Epoch 39/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0222 - acc: 0.9981 - f1_score: 0.9894 - val_loss: 3.0414 - val_acc: 0.8490 - val_f1_score: 0.0532\n",
      "\n",
      "Epoch 00039: val_f1_score did not improve from 0.24615\n",
      "Epoch 40/300\n",
      "145/145 [==============================] - 6s 41ms/step - loss: 0.0237 - acc: 0.9979 - f1_score: 0.9883 - val_loss: 2.9469 - val_acc: 0.8473 - val_f1_score: 0.0722\n",
      "\n",
      "Epoch 00040: val_f1_score did not improve from 0.24615\n",
      "Epoch 41/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0239 - acc: 0.9981 - f1_score: 0.9894 - val_loss: 2.9644 - val_acc: 0.8516 - val_f1_score: 0.0933\n",
      "\n",
      "Epoch 00041: val_f1_score did not improve from 0.24615\n",
      "Epoch 42/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0238 - acc: 0.9979 - f1_score: 0.9882 - val_loss: 3.0761 - val_acc: 0.8380 - val_f1_score: 0.1033\n",
      "\n",
      "Epoch 00042: val_f1_score did not improve from 0.24615\n",
      "Epoch 43/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0275 - acc: 0.9975 - f1_score: 0.9868 - val_loss: 3.0345 - val_acc: 0.8524 - val_f1_score: 0.0645\n",
      "\n",
      "Epoch 00043: val_f1_score did not improve from 0.24615\n",
      "Epoch 44/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0272 - acc: 0.9975 - f1_score: 0.9858 - val_loss: 2.7703 - val_acc: 0.8660 - val_f1_score: 0.1222\n",
      "\n",
      "Epoch 00044: val_f1_score did not improve from 0.24615\n",
      "Epoch 00044: early stopping\n",
      "(0.41281138790035593, 0.00069496443)\n",
      "(0.4053156146179402, 0.0007451225)\n",
      "0.6930136420008268\n",
      "1349 (17117,)\n",
      "29678\n",
      "(None, 1, 1) coeff (None, 5, 30) amplitude\n",
      "Epoch 1/300\n",
      "149/149 [==============================] - 16s 54ms/step - loss: 1.2202 - acc: 0.9111 - f1_score: 0.1138 - val_loss: 1.2451 - val_acc: 0.9292 - val_f1_score: 0.1238\n",
      "\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.12381, saving model to ./models/lag_15_iter_0_split_2_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_f1_both.hdf5\n",
      "Epoch 2/300\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 0.6475 - acc: 0.9466 - f1_score: 0.6287 - val_loss: 1.3155 - val_acc: 0.9303 - val_f1_score: 0.1084\n",
      "\n",
      "Epoch 00002: val_f1_score did not improve from 0.12381\n",
      "Epoch 3/300\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 0.3034 - acc: 0.9738 - f1_score: 0.8455 - val_loss: 1.4070 - val_acc: 0.9172 - val_f1_score: 0.1434\n",
      "\n",
      "Epoch 00003: val_f1_score improved from 0.12381 to 0.14343, saving model to ./models/lag_15_iter_0_split_2_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_f1_both.hdf5\n",
      "Epoch 4/300\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 0.1952 - acc: 0.9830 - f1_score: 0.9041 - val_loss: 1.2809 - val_acc: 0.9465 - val_f1_score: 0.3474\n",
      "\n",
      "Epoch 00004: val_f1_score improved from 0.14343 to 0.34742, saving model to ./models/lag_15_iter_0_split_2_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_f1_both.hdf5\n",
      "Epoch 5/300\n",
      "149/149 [==============================] - 6s 37ms/step - loss: 0.1233 - acc: 0.9887 - f1_score: 0.9373 - val_loss: 1.5417 - val_acc: 0.9219 - val_f1_score: 0.0645\n",
      "\n",
      "Epoch 00005: val_f1_score did not improve from 0.34742\n",
      "Epoch 6/300\n",
      "149/149 [==============================] - 6s 37ms/step - loss: 0.1082 - acc: 0.9913 - f1_score: 0.9511 - val_loss: 1.4593 - val_acc: 0.9369 - val_f1_score: 0.3109\n",
      "\n",
      "Epoch 00006: val_f1_score did not improve from 0.34742\n",
      "Epoch 7/300\n",
      "149/149 [==============================] - 5s 35ms/step - loss: 0.0978 - acc: 0.9912 - f1_score: 0.9518 - val_loss: 1.2742 - val_acc: 0.9442 - val_f1_score: 0.4177\n",
      "\n",
      "Epoch 00007: val_f1_score improved from 0.34742 to 0.41767, saving model to ./models/lag_15_iter_0_split_2_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_f1_both.hdf5\n",
      "Epoch 8/300\n",
      "149/149 [==============================] - 5s 31ms/step - loss: 0.0858 - acc: 0.9922 - f1_score: 0.9569 - val_loss: 1.4007 - val_acc: 0.9357 - val_f1_score: 0.2578\n",
      "\n",
      "Epoch 00008: val_f1_score did not improve from 0.41767\n",
      "Epoch 9/300\n",
      "149/149 [==============================] - 4s 29ms/step - loss: 0.0733 - acc: 0.9939 - f1_score: 0.9672 - val_loss: 1.4679 - val_acc: 0.9253 - val_f1_score: 0.2177\n",
      "\n",
      "Epoch 00009: val_f1_score did not improve from 0.41767\n",
      "Epoch 10/300\n",
      "149/149 [==============================] - 4s 26ms/step - loss: 0.0667 - acc: 0.9942 - f1_score: 0.9672 - val_loss: 1.4234 - val_acc: 0.9388 - val_f1_score: 0.2010\n",
      "\n",
      "Epoch 00010: val_f1_score did not improve from 0.41767\n",
      "Epoch 11/300\n",
      "149/149 [==============================] - 4s 29ms/step - loss: 0.0760 - acc: 0.9935 - f1_score: 0.9648 - val_loss: 1.7601 - val_acc: 0.8999 - val_f1_score: 0.1275\n",
      "\n",
      "Epoch 00011: val_f1_score did not improve from 0.41767\n",
      "Epoch 12/300\n",
      "149/149 [==============================] - 5s 33ms/step - loss: 0.0576 - acc: 0.9946 - f1_score: 0.9701 - val_loss: 1.5478 - val_acc: 0.9311 - val_f1_score: 0.1268\n",
      "\n",
      "Epoch 00012: val_f1_score did not improve from 0.41767\n",
      "Epoch 13/300\n",
      "149/149 [==============================] - 5s 34ms/step - loss: 0.0594 - acc: 0.9947 - f1_score: 0.9706 - val_loss: 1.8552 - val_acc: 0.8899 - val_f1_score: 0.1006\n",
      "\n",
      "Epoch 00013: val_f1_score did not improve from 0.41767\n",
      "Epoch 14/300\n",
      "149/149 [==============================] - 5s 37ms/step - loss: 0.0564 - acc: 0.9951 - f1_score: 0.9736 - val_loss: 1.8255 - val_acc: 0.9053 - val_f1_score: 0.0752\n",
      "\n",
      "Epoch 00014: val_f1_score did not improve from 0.41767\n",
      "Epoch 15/300\n",
      "149/149 [==============================] - 6s 41ms/step - loss: 0.0599 - acc: 0.9948 - f1_score: 0.9716 - val_loss: 1.6018 - val_acc: 0.9184 - val_f1_score: 0.1017\n",
      "\n",
      "Epoch 00015: val_f1_score did not improve from 0.41767\n",
      "Epoch 16/300\n",
      "149/149 [==============================] - 6s 42ms/step - loss: 0.0535 - acc: 0.9955 - f1_score: 0.9750 - val_loss: 1.7383 - val_acc: 0.9049 - val_f1_score: 0.1272\n",
      "\n",
      "Epoch 00016: val_f1_score did not improve from 0.41767\n",
      "Epoch 17/300\n",
      "149/149 [==============================] - 6s 41ms/step - loss: 0.0520 - acc: 0.9956 - f1_score: 0.9766 - val_loss: 1.7059 - val_acc: 0.9161 - val_f1_score: 0.0684\n",
      "\n",
      "Epoch 00017: val_f1_score did not improve from 0.41767\n",
      "Epoch 18/300\n",
      "149/149 [==============================] - 6s 42ms/step - loss: 0.0446 - acc: 0.9962 - f1_score: 0.9795 - val_loss: 1.5759 - val_acc: 0.9172 - val_f1_score: 0.2238\n",
      "\n",
      "Epoch 00018: val_f1_score did not improve from 0.41767\n",
      "Epoch 19/300\n",
      "149/149 [==============================] - 6s 42ms/step - loss: 0.0471 - acc: 0.9957 - f1_score: 0.9761 - val_loss: 1.6700 - val_acc: 0.9169 - val_f1_score: 0.1562\n",
      "\n",
      "Epoch 00019: val_f1_score did not improve from 0.41767\n",
      "Epoch 20/300\n",
      "149/149 [==============================] - 6s 42ms/step - loss: 0.0438 - acc: 0.9961 - f1_score: 0.9787 - val_loss: 1.7189 - val_acc: 0.9157 - val_f1_score: 0.0681\n",
      "\n",
      "Epoch 00020: val_f1_score did not improve from 0.41767\n",
      "Epoch 21/300\n",
      "149/149 [==============================] - 6s 38ms/step - loss: 0.0417 - acc: 0.9962 - f1_score: 0.9783 - val_loss: 1.7655 - val_acc: 0.9149 - val_f1_score: 0.0264\n",
      "\n",
      "Epoch 00021: val_f1_score did not improve from 0.41767\n",
      "Epoch 22/300\n",
      "149/149 [==============================] - 6s 37ms/step - loss: 0.0365 - acc: 0.9967 - f1_score: 0.9813 - val_loss: 1.9164 - val_acc: 0.8899 - val_f1_score: 0.1173\n",
      "\n",
      "Epoch 00022: val_f1_score did not improve from 0.41767\n",
      "Epoch 23/300\n",
      "149/149 [==============================] - 6s 39ms/step - loss: 0.0451 - acc: 0.9961 - f1_score: 0.9781 - val_loss: 1.7299 - val_acc: 0.9165 - val_f1_score: 0.0091\n",
      "\n",
      "Epoch 00023: val_f1_score did not improve from 0.41767\n",
      "Epoch 24/300\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 0.0503 - acc: 0.9955 - f1_score: 0.9750 - val_loss: 1.6676 - val_acc: 0.9192 - val_f1_score: 0.1463\n",
      "\n",
      "Epoch 00024: val_f1_score did not improve from 0.41767\n",
      "Epoch 25/300\n",
      "149/149 [==============================] - 6s 41ms/step - loss: 0.0321 - acc: 0.9970 - f1_score: 0.9839 - val_loss: 1.7872 - val_acc: 0.9107 - val_f1_score: 0.0569\n",
      "\n",
      "Epoch 00025: val_f1_score did not improve from 0.41767\n",
      "Epoch 26/300\n",
      "149/149 [==============================] - 6s 37ms/step - loss: 0.0350 - acc: 0.9971 - f1_score: 0.9839 - val_loss: 1.8523 - val_acc: 0.9034 - val_f1_score: 0.0456\n",
      "\n",
      "Epoch 00026: val_f1_score did not improve from 0.41767\n",
      "Epoch 27/300\n",
      "149/149 [==============================] - 6s 37ms/step - loss: 0.0335 - acc: 0.9970 - f1_score: 0.9833 - val_loss: 1.8707 - val_acc: 0.8999 - val_f1_score: 0.0299\n",
      "\n",
      "Epoch 00027: val_f1_score did not improve from 0.41767\n",
      "Epoch 28/300\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 0.0422 - acc: 0.9966 - f1_score: 0.9819 - val_loss: 1.8386 - val_acc: 0.9095 - val_f1_score: 0.0249\n",
      "\n",
      "Epoch 00028: val_f1_score did not improve from 0.41767\n",
      "Epoch 29/300\n",
      "149/149 [==============================] - 6s 42ms/step - loss: 0.0442 - acc: 0.9956 - f1_score: 0.9759 - val_loss: 1.7100 - val_acc: 0.9253 - val_f1_score: 0.0583\n",
      "\n",
      "Epoch 00029: val_f1_score did not improve from 0.41767\n",
      "Epoch 30/300\n",
      "149/149 [==============================] - 6s 37ms/step - loss: 0.0345 - acc: 0.9968 - f1_score: 0.9824 - val_loss: 1.6785 - val_acc: 0.9234 - val_f1_score: 0.0657\n",
      "\n",
      "Epoch 00030: val_f1_score did not improve from 0.41767\n",
      "Epoch 31/300\n",
      "149/149 [==============================] - 6s 37ms/step - loss: 0.0341 - acc: 0.9968 - f1_score: 0.9824 - val_loss: 1.7992 - val_acc: 0.9030 - val_f1_score: 0.0526\n",
      "\n",
      "Epoch 00031: val_f1_score did not improve from 0.41767\n",
      "Epoch 32/300\n",
      "149/149 [==============================] - 6s 41ms/step - loss: 0.0357 - acc: 0.9970 - f1_score: 0.9831 - val_loss: 1.7432 - val_acc: 0.9192 - val_f1_score: 0.0187\n",
      "\n",
      "Epoch 00032: val_f1_score did not improve from 0.41767\n",
      "Epoch 33/300\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 0.0256 - acc: 0.9977 - f1_score: 0.9875 - val_loss: 1.7663 - val_acc: 0.9103 - val_f1_score: 0.1073\n",
      "\n",
      "Epoch 00033: val_f1_score did not improve from 0.41767\n",
      "Epoch 34/300\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 0.0278 - acc: 0.9975 - f1_score: 0.9864 - val_loss: 1.7114 - val_acc: 0.9249 - val_f1_score: 0.0758\n",
      "\n",
      "Epoch 00034: val_f1_score did not improve from 0.41767\n",
      "Epoch 35/300\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 0.0296 - acc: 0.9974 - f1_score: 0.9848 - val_loss: 1.6503 - val_acc: 0.9184 - val_f1_score: 0.1970\n",
      "\n",
      "Epoch 00035: val_f1_score did not improve from 0.41767\n",
      "Epoch 36/300\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 0.0238 - acc: 0.9980 - f1_score: 0.9889 - val_loss: 1.6134 - val_acc: 0.9384 - val_f1_score: 0.0588\n",
      "\n",
      "Epoch 00036: val_f1_score did not improve from 0.41767\n",
      "Epoch 37/300\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 0.0323 - acc: 0.9973 - f1_score: 0.9852 - val_loss: 1.8590 - val_acc: 0.9069 - val_f1_score: 0.0163\n",
      "\n",
      "Epoch 00037: val_f1_score did not improve from 0.41767\n",
      "Epoch 38/300\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 0.0224 - acc: 0.9981 - f1_score: 0.9897 - val_loss: 1.8281 - val_acc: 0.9172 - val_f1_score: 0.0611\n",
      "\n",
      "Epoch 00038: val_f1_score did not improve from 0.41767\n",
      "Epoch 39/300\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 0.0318 - acc: 0.9972 - f1_score: 0.9841 - val_loss: 1.8385 - val_acc: 0.9080 - val_f1_score: 0.0981\n",
      "\n",
      "Epoch 00039: val_f1_score did not improve from 0.41767\n",
      "Epoch 40/300\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 0.0226 - acc: 0.9981 - f1_score: 0.9896 - val_loss: 1.8025 - val_acc: 0.9222 - val_f1_score: 0.0098\n",
      "\n",
      "Epoch 00040: val_f1_score did not improve from 0.41767\n",
      "Epoch 41/300\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 0.0245 - acc: 0.9981 - f1_score: 0.9894 - val_loss: 1.6400 - val_acc: 0.9346 - val_f1_score: 0.1667\n",
      "\n",
      "Epoch 00041: val_f1_score did not improve from 0.41767\n",
      "Epoch 42/300\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 0.0242 - acc: 0.9977 - f1_score: 0.9874 - val_loss: 1.8016 - val_acc: 0.9238 - val_f1_score: 0.0100\n",
      "\n",
      "Epoch 00042: val_f1_score did not improve from 0.41767\n",
      "Epoch 43/300\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 0.0271 - acc: 0.9976 - f1_score: 0.9869 - val_loss: 1.7915 - val_acc: 0.9207 - val_f1_score: 0.0096\n",
      "\n",
      "Epoch 00043: val_f1_score did not improve from 0.41767\n",
      "Epoch 44/300\n",
      "149/149 [==============================] - 7s 44ms/step - loss: 0.0238 - acc: 0.9980 - f1_score: 0.9890 - val_loss: 1.6917 - val_acc: 0.9307 - val_f1_score: 0.0526\n",
      "\n",
      "Epoch 00044: val_f1_score did not improve from 0.41767\n",
      "Epoch 45/300\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 0.0294 - acc: 0.9971 - f1_score: 0.9838 - val_loss: 1.6539 - val_acc: 0.9276 - val_f1_score: 0.1754\n",
      "\n",
      "Epoch 00045: val_f1_score did not improve from 0.41767\n",
      "Epoch 46/300\n",
      "149/149 [==============================] - 6s 41ms/step - loss: 0.0249 - acc: 0.9977 - f1_score: 0.9875 - val_loss: 1.6910 - val_acc: 0.9284 - val_f1_score: 0.0971\n",
      "\n",
      "Epoch 00046: val_f1_score did not improve from 0.41767\n",
      "Epoch 47/300\n",
      "149/149 [==============================] - 5s 36ms/step - loss: 0.0194 - acc: 0.9983 - f1_score: 0.9910 - val_loss: 1.7837 - val_acc: 0.9269 - val_f1_score: 0.0865\n",
      "\n",
      "Epoch 00047: val_f1_score did not improve from 0.41767\n",
      "Epoch 00047: early stopping\n",
      "(0.36693548387096775, 0.00029711713)\n",
      "(0.16581071166544387, 3.7139298e-06)\n",
      "0.5872056854934582\n",
      "1331 (17581,)\n",
      "29282\n",
      "(None, 1, 1) coeff (None, 5, 30) amplitude\n",
      "Epoch 1/300\n",
      "147/147 [==============================] - 15s 52ms/step - loss: 1.2425 - acc: 0.9106 - f1_score: 0.0667 - val_loss: 1.6858 - val_acc: 0.8371 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.00000, saving model to ./models/lag_15_iter_0_split_3_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_f1_both.hdf5\n",
      "Epoch 2/300\n",
      "147/147 [==============================] - 6s 42ms/step - loss: 0.5316 - acc: 0.9544 - f1_score: 0.7133 - val_loss: 1.9305 - val_acc: 0.8158 - val_f1_score: 0.0547\n",
      "\n",
      "Epoch 00002: val_f1_score improved from 0.00000 to 0.05469, saving model to ./models/lag_15_iter_0_split_3_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_f1_both.hdf5\n",
      "Epoch 3/300\n",
      "147/147 [==============================] - 6s 41ms/step - loss: 0.2872 - acc: 0.9764 - f1_score: 0.8624 - val_loss: 2.0003 - val_acc: 0.8615 - val_f1_score: 0.0714\n",
      "\n",
      "Epoch 00003: val_f1_score improved from 0.05469 to 0.07143, saving model to ./models/lag_15_iter_0_split_3_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_f1_both.hdf5\n",
      "Epoch 4/300\n",
      "147/147 [==============================] - 6s 42ms/step - loss: 0.1930 - acc: 0.9836 - f1_score: 0.9062 - val_loss: 2.0044 - val_acc: 0.8425 - val_f1_score: 0.1481\n",
      "\n",
      "Epoch 00004: val_f1_score improved from 0.07143 to 0.14815, saving model to ./models/lag_15_iter_0_split_3_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_f1_both.hdf5\n",
      "Epoch 5/300\n",
      "147/147 [==============================] - 6s 42ms/step - loss: 0.1581 - acc: 0.9869 - f1_score: 0.9244 - val_loss: 2.1375 - val_acc: 0.8044 - val_f1_score: 0.2463\n",
      "\n",
      "Epoch 00005: val_f1_score improved from 0.14815 to 0.24633, saving model to ./models/lag_15_iter_0_split_3_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_f1_both.hdf5\n",
      "Epoch 6/300\n",
      "147/147 [==============================] - 6s 42ms/step - loss: 0.1321 - acc: 0.9883 - f1_score: 0.9362 - val_loss: 2.1367 - val_acc: 0.8470 - val_f1_score: 0.0651\n",
      "\n",
      "Epoch 00006: val_f1_score did not improve from 0.24633\n",
      "Epoch 7/300\n",
      "147/147 [==============================] - 6s 41ms/step - loss: 0.1044 - acc: 0.9916 - f1_score: 0.9528 - val_loss: 2.1476 - val_acc: 0.8387 - val_f1_score: 0.0702\n",
      "\n",
      "Epoch 00007: val_f1_score did not improve from 0.24633\n",
      "Epoch 8/300\n",
      "147/147 [==============================] - 6s 43ms/step - loss: 0.0917 - acc: 0.9924 - f1_score: 0.9583 - val_loss: 2.1571 - val_acc: 0.8524 - val_f1_score: 0.0202\n",
      "\n",
      "Epoch 00008: val_f1_score did not improve from 0.24633\n",
      "Epoch 9/300\n",
      "147/147 [==============================] - 6s 43ms/step - loss: 0.1030 - acc: 0.9912 - f1_score: 0.9511 - val_loss: 2.1542 - val_acc: 0.8554 - val_f1_score: 0.1284\n",
      "\n",
      "Epoch 00009: val_f1_score did not improve from 0.24633\n",
      "Epoch 10/300\n",
      "147/147 [==============================] - 6s 41ms/step - loss: 0.0851 - acc: 0.9926 - f1_score: 0.9579 - val_loss: 2.1390 - val_acc: 0.8440 - val_f1_score: 0.0553\n",
      "\n",
      "Epoch 00010: val_f1_score did not improve from 0.24633\n",
      "Epoch 11/300\n",
      "147/147 [==============================] - 6s 42ms/step - loss: 0.0709 - acc: 0.9937 - f1_score: 0.9649 - val_loss: 2.4673 - val_acc: 0.8120 - val_f1_score: 0.0237\n",
      "\n",
      "Epoch 00011: val_f1_score did not improve from 0.24633\n",
      "Epoch 12/300\n",
      "147/147 [==============================] - 6s 42ms/step - loss: 0.0654 - acc: 0.9946 - f1_score: 0.9695 - val_loss: 2.4696 - val_acc: 0.8280 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00012: val_f1_score did not improve from 0.24633\n",
      "Epoch 13/300\n",
      "147/147 [==============================] - 6s 42ms/step - loss: 0.0721 - acc: 0.9941 - f1_score: 0.9674 - val_loss: 2.4076 - val_acc: 0.8455 - val_f1_score: 0.0098\n",
      "\n",
      "Epoch 00013: val_f1_score did not improve from 0.24633\n",
      "Epoch 14/300\n",
      "147/147 [==============================] - 6s 42ms/step - loss: 0.0596 - acc: 0.9950 - f1_score: 0.9728 - val_loss: 2.8278 - val_acc: 0.7732 - val_f1_score: 0.0629\n",
      "\n",
      "Epoch 00014: val_f1_score did not improve from 0.24633\n",
      "Epoch 15/300\n",
      "147/147 [==============================] - 6s 42ms/step - loss: 0.0660 - acc: 0.9946 - f1_score: 0.9695 - val_loss: 2.3910 - val_acc: 0.8349 - val_f1_score: 0.0441\n",
      "\n",
      "Epoch 00015: val_f1_score did not improve from 0.24633\n",
      "Epoch 16/300\n",
      "147/147 [==============================] - 6s 42ms/step - loss: 0.0466 - acc: 0.9960 - f1_score: 0.9772 - val_loss: 2.6962 - val_acc: 0.8219 - val_f1_score: 0.0640\n",
      "\n",
      "Epoch 00016: val_f1_score did not improve from 0.24633\n",
      "Epoch 17/300\n",
      "147/147 [==============================] - 6s 42ms/step - loss: 0.0529 - acc: 0.9954 - f1_score: 0.9740 - val_loss: 2.7719 - val_acc: 0.8075 - val_f1_score: 0.0078\n",
      "\n",
      "Epoch 00017: val_f1_score did not improve from 0.24633\n",
      "Epoch 18/300\n",
      "147/147 [==============================] - 6s 43ms/step - loss: 0.0630 - acc: 0.9947 - f1_score: 0.9699 - val_loss: 2.7278 - val_acc: 0.8288 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00018: val_f1_score did not improve from 0.24633\n",
      "Epoch 19/300\n",
      "147/147 [==============================] - 6s 43ms/step - loss: 0.0573 - acc: 0.9950 - f1_score: 0.9723 - val_loss: 2.5770 - val_acc: 0.8135 - val_f1_score: 0.0613\n",
      "\n",
      "Epoch 00019: val_f1_score did not improve from 0.24633\n",
      "Epoch 20/300\n",
      "147/147 [==============================] - 6s 42ms/step - loss: 0.0447 - acc: 0.9959 - f1_score: 0.9779 - val_loss: 2.6164 - val_acc: 0.8371 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00020: val_f1_score did not improve from 0.24633\n",
      "Epoch 21/300\n",
      "147/147 [==============================] - 6s 43ms/step - loss: 0.0475 - acc: 0.9958 - f1_score: 0.9762 - val_loss: 2.8650 - val_acc: 0.8075 - val_f1_score: 0.0078\n",
      "\n",
      "Epoch 00021: val_f1_score did not improve from 0.24633\n",
      "Epoch 22/300\n",
      "147/147 [==============================] - 6s 43ms/step - loss: 0.0450 - acc: 0.9960 - f1_score: 0.9778 - val_loss: 2.5040 - val_acc: 0.8455 - val_f1_score: 0.0645\n",
      "\n",
      "Epoch 00022: val_f1_score did not improve from 0.24633\n",
      "Epoch 23/300\n",
      "147/147 [==============================] - 6s 41ms/step - loss: 0.0454 - acc: 0.9961 - f1_score: 0.9783 - val_loss: 2.6201 - val_acc: 0.8318 - val_f1_score: 0.0433\n",
      "\n",
      "Epoch 00023: val_f1_score did not improve from 0.24633\n",
      "Epoch 24/300\n",
      "147/147 [==============================] - 6s 43ms/step - loss: 0.0379 - acc: 0.9967 - f1_score: 0.9814 - val_loss: 2.7095 - val_acc: 0.8219 - val_f1_score: 0.0250\n",
      "\n",
      "Epoch 00024: val_f1_score did not improve from 0.24633\n",
      "Epoch 25/300\n",
      "147/147 [==============================] - 6s 43ms/step - loss: 0.0286 - acc: 0.9974 - f1_score: 0.9854 - val_loss: 2.7992 - val_acc: 0.8333 - val_f1_score: 0.0437\n",
      "\n",
      "Epoch 00025: val_f1_score did not improve from 0.24633\n",
      "Epoch 26/300\n",
      "147/147 [==============================] - 6s 42ms/step - loss: 0.0392 - acc: 0.9961 - f1_score: 0.9791 - val_loss: 2.8286 - val_acc: 0.8037 - val_f1_score: 0.0373\n",
      "\n",
      "Epoch 00026: val_f1_score did not improve from 0.24633\n",
      "Epoch 27/300\n",
      "147/147 [==============================] - 6s 42ms/step - loss: 0.0359 - acc: 0.9970 - f1_score: 0.9830 - val_loss: 2.5016 - val_acc: 0.8318 - val_f1_score: 0.0905\n",
      "\n",
      "Epoch 00027: val_f1_score did not improve from 0.24633\n",
      "Epoch 28/300\n",
      "147/147 [==============================] - 6s 43ms/step - loss: 0.0326 - acc: 0.9971 - f1_score: 0.9842 - val_loss: 2.6790 - val_acc: 0.8303 - val_f1_score: 0.0669\n",
      "\n",
      "Epoch 00028: val_f1_score did not improve from 0.24633\n",
      "Epoch 29/300\n",
      "147/147 [==============================] - 6s 42ms/step - loss: 0.0332 - acc: 0.9972 - f1_score: 0.9846 - val_loss: 2.6170 - val_acc: 0.8516 - val_f1_score: 0.0299\n",
      "\n",
      "Epoch 00029: val_f1_score did not improve from 0.24633\n",
      "Epoch 30/300\n",
      "147/147 [==============================] - 6s 42ms/step - loss: 0.0301 - acc: 0.9974 - f1_score: 0.9859 - val_loss: 2.8902 - val_acc: 0.7998 - val_f1_score: 0.0573\n",
      "\n",
      "Epoch 00030: val_f1_score did not improve from 0.24633\n",
      "Epoch 31/300\n",
      "147/147 [==============================] - 6s 42ms/step - loss: 0.0263 - acc: 0.9978 - f1_score: 0.9880 - val_loss: 2.9172 - val_acc: 0.8227 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00031: val_f1_score did not improve from 0.24633\n",
      "Epoch 32/300\n",
      "147/147 [==============================] - 6s 42ms/step - loss: 0.0254 - acc: 0.9976 - f1_score: 0.9867 - val_loss: 3.0753 - val_acc: 0.8014 - val_f1_score: 0.0076\n",
      "\n",
      "Epoch 00032: val_f1_score did not improve from 0.24633\n",
      "Epoch 33/300\n",
      "147/147 [==============================] - 6s 41ms/step - loss: 0.0264 - acc: 0.9975 - f1_score: 0.9863 - val_loss: 2.7675 - val_acc: 0.8447 - val_f1_score: 0.0377\n",
      "\n",
      "Epoch 00033: val_f1_score did not improve from 0.24633\n",
      "Epoch 34/300\n",
      "147/147 [==============================] - 6s 42ms/step - loss: 0.0197 - acc: 0.9982 - f1_score: 0.9901 - val_loss: 2.7275 - val_acc: 0.8364 - val_f1_score: 0.0444\n",
      "\n",
      "Epoch 00034: val_f1_score did not improve from 0.24633\n",
      "Epoch 35/300\n",
      "147/147 [==============================] - 6s 42ms/step - loss: 0.0269 - acc: 0.9977 - f1_score: 0.9873 - val_loss: 2.6813 - val_acc: 0.8265 - val_f1_score: 0.0339\n",
      "\n",
      "Epoch 00035: val_f1_score did not improve from 0.24633\n",
      "Epoch 36/300\n",
      "147/147 [==============================] - 6s 42ms/step - loss: 0.0238 - acc: 0.9981 - f1_score: 0.9896 - val_loss: 2.7785 - val_acc: 0.8371 - val_f1_score: 0.0360\n",
      "\n",
      "Epoch 00036: val_f1_score did not improve from 0.24633\n",
      "Epoch 37/300\n",
      "147/147 [==============================] - 6s 42ms/step - loss: 0.0229 - acc: 0.9978 - f1_score: 0.9880 - val_loss: 2.5169 - val_acc: 0.8470 - val_f1_score: 0.0651\n",
      "\n",
      "Epoch 00037: val_f1_score did not improve from 0.24633\n",
      "Epoch 38/300\n",
      "147/147 [==============================] - 6s 42ms/step - loss: 0.0208 - acc: 0.9978 - f1_score: 0.9875 - val_loss: 2.6779 - val_acc: 0.8379 - val_f1_score: 0.0274\n",
      "\n",
      "Epoch 00038: val_f1_score did not improve from 0.24633\n",
      "Epoch 39/300\n",
      "147/147 [==============================] - 6s 40ms/step - loss: 0.0179 - acc: 0.9983 - f1_score: 0.9907 - val_loss: 2.7111 - val_acc: 0.8554 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00039: val_f1_score did not improve from 0.24633\n",
      "Epoch 40/300\n",
      "147/147 [==============================] - 5s 37ms/step - loss: 0.0215 - acc: 0.9980 - f1_score: 0.9892 - val_loss: 2.8250 - val_acc: 0.8486 - val_f1_score: 0.0197\n",
      "\n",
      "Epoch 00040: val_f1_score did not improve from 0.24633\n",
      "Epoch 41/300\n",
      "147/147 [==============================] - 5s 37ms/step - loss: 0.0239 - acc: 0.9978 - f1_score: 0.9875 - val_loss: 2.7645 - val_acc: 0.8577 - val_f1_score: 0.1538\n",
      "\n",
      "Epoch 00041: val_f1_score did not improve from 0.24633\n",
      "Epoch 42/300\n",
      "147/147 [==============================] - 5s 35ms/step - loss: 0.0172 - acc: 0.9986 - f1_score: 0.9925 - val_loss: 2.7718 - val_acc: 0.8440 - val_f1_score: 0.0191\n",
      "\n",
      "Epoch 00042: val_f1_score did not improve from 0.24633\n",
      "Epoch 43/300\n",
      "147/147 [==============================] - 5s 31ms/step - loss: 0.0211 - acc: 0.9983 - f1_score: 0.9908 - val_loss: 3.0269 - val_acc: 0.8151 - val_f1_score: 0.0162\n",
      "\n",
      "Epoch 00043: val_f1_score did not improve from 0.24633\n",
      "Epoch 44/300\n",
      "147/147 [==============================] - 4s 30ms/step - loss: 0.0190 - acc: 0.9985 - f1_score: 0.9914 - val_loss: 2.9988 - val_acc: 0.8242 - val_f1_score: 0.0571\n",
      "\n",
      "Epoch 00044: val_f1_score did not improve from 0.24633\n",
      "Epoch 45/300\n",
      "147/147 [==============================] - 4s 29ms/step - loss: 0.0178 - acc: 0.9984 - f1_score: 0.9910 - val_loss: 2.9742 - val_acc: 0.8280 - val_f1_score: 0.0342\n",
      "\n",
      "Epoch 00045: val_f1_score did not improve from 0.24633\n",
      "Epoch 00045: early stopping\n",
      "(0.2597114317425083, 0.00028211658)\n",
      "(0.11014263074484944, 5.47551e-05)\n",
      "0.689527692015627\n",
      "1314 (17470,)\n",
      "28908\n",
      "(None, 1, 1) coeff (None, 5, 30) amplitude\n",
      "Epoch 1/300\n",
      "145/145 [==============================] - 14s 52ms/step - loss: 1.2321 - acc: 0.8960 - f1_score: 0.1017 - val_loss: 1.3024 - val_acc: 0.9170 - val_f1_score: 0.1107\n",
      "\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.11067, saving model to ./models/lag_15_iter_0_split_4_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_f1_both.hdf5\n",
      "Epoch 2/300\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 0.5272 - acc: 0.9545 - f1_score: 0.7300 - val_loss: 1.7686 - val_acc: 0.8362 - val_f1_score: 0.0593\n",
      "\n",
      "Epoch 00002: val_f1_score did not improve from 0.11067\n",
      "Epoch 3/300\n",
      "145/145 [==============================] - 5s 36ms/step - loss: 0.2472 - acc: 0.9794 - f1_score: 0.8847 - val_loss: 1.8970 - val_acc: 0.8539 - val_f1_score: 0.0660\n",
      "\n",
      "Epoch 00003: val_f1_score did not improve from 0.11067\n",
      "Epoch 4/300\n",
      "145/145 [==============================] - 5s 36ms/step - loss: 0.1906 - acc: 0.9841 - f1_score: 0.9116 - val_loss: 1.7493 - val_acc: 0.8790 - val_f1_score: 0.1458\n",
      "\n",
      "Epoch 00004: val_f1_score improved from 0.11067 to 0.14583, saving model to ./models/lag_15_iter_0_split_4_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_f1_both.hdf5\n",
      "Epoch 5/300\n",
      "145/145 [==============================] - 6s 41ms/step - loss: 0.1218 - acc: 0.9895 - f1_score: 0.9398 - val_loss: 1.9464 - val_acc: 0.8568 - val_f1_score: 0.0673\n",
      "\n",
      "Epoch 00005: val_f1_score did not improve from 0.14583\n",
      "Epoch 6/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.1114 - acc: 0.9899 - f1_score: 0.9436 - val_loss: 1.7412 - val_acc: 0.9011 - val_f1_score: 0.1126\n",
      "\n",
      "Epoch 00006: val_f1_score did not improve from 0.14583\n",
      "Epoch 7/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0935 - acc: 0.9914 - f1_score: 0.9527 - val_loss: 1.8769 - val_acc: 0.8886 - val_f1_score: 0.0679\n",
      "\n",
      "Epoch 00007: val_f1_score did not improve from 0.14583\n",
      "Epoch 8/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.1050 - acc: 0.9909 - f1_score: 0.9499 - val_loss: 2.0770 - val_acc: 0.8745 - val_f1_score: 0.0761\n",
      "\n",
      "Epoch 00008: val_f1_score did not improve from 0.14583\n",
      "Epoch 9/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0796 - acc: 0.9926 - f1_score: 0.9604 - val_loss: 2.0613 - val_acc: 0.8694 - val_f1_score: 0.1015\n",
      "\n",
      "Epoch 00009: val_f1_score did not improve from 0.14583\n",
      "Epoch 10/300\n",
      "145/145 [==============================] - 6s 41ms/step - loss: 0.0756 - acc: 0.9940 - f1_score: 0.9666 - val_loss: 1.8800 - val_acc: 0.8849 - val_f1_score: 0.0930\n",
      "\n",
      "Epoch 00010: val_f1_score did not improve from 0.14583\n",
      "Epoch 11/300\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.0583 - acc: 0.9949 - f1_score: 0.9719 - val_loss: 1.9672 - val_acc: 0.8804 - val_f1_score: 0.0471\n",
      "\n",
      "Epoch 00011: val_f1_score did not improve from 0.14583\n",
      "Epoch 12/300\n",
      "145/145 [==============================] - 5s 36ms/step - loss: 0.0541 - acc: 0.9950 - f1_score: 0.9727 - val_loss: 1.9364 - val_acc: 0.8782 - val_f1_score: 0.1709\n",
      "\n",
      "Epoch 00012: val_f1_score improved from 0.14583 to 0.17085, saving model to ./models/lag_15_iter_0_split_4_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_f1_both.hdf5\n",
      "Epoch 13/300\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.0589 - acc: 0.9949 - f1_score: 0.9721 - val_loss: 1.9701 - val_acc: 0.8723 - val_f1_score: 0.1878\n",
      "\n",
      "Epoch 00013: val_f1_score improved from 0.17085 to 0.18779, saving model to ./models/lag_15_iter_0_split_4_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_f1_both.hdf5\n",
      "Epoch 14/300\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.0600 - acc: 0.9943 - f1_score: 0.9693 - val_loss: 1.8781 - val_acc: 0.8967 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00014: val_f1_score did not improve from 0.18779\n",
      "Epoch 15/300\n",
      "145/145 [==============================] - 5s 36ms/step - loss: 0.0462 - acc: 0.9961 - f1_score: 0.9789 - val_loss: 1.8352 - val_acc: 0.8985 - val_f1_score: 0.0283\n",
      "\n",
      "Epoch 00015: val_f1_score did not improve from 0.18779\n",
      "Epoch 16/300\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 0.0456 - acc: 0.9961 - f1_score: 0.9787 - val_loss: 1.8052 - val_acc: 0.9077 - val_f1_score: 0.2089\n",
      "\n",
      "Epoch 00016: val_f1_score improved from 0.18779 to 0.20886, saving model to ./models/lag_15_iter_0_split_4_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_f1_both.hdf5\n",
      "Epoch 17/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0457 - acc: 0.9959 - f1_score: 0.9776 - val_loss: 1.6830 - val_acc: 0.9155 - val_f1_score: 0.1158\n",
      "\n",
      "Epoch 00017: val_f1_score did not improve from 0.20886\n",
      "Epoch 18/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0464 - acc: 0.9959 - f1_score: 0.9774 - val_loss: 1.9142 - val_acc: 0.8926 - val_f1_score: 0.0332\n",
      "\n",
      "Epoch 00018: val_f1_score did not improve from 0.20886\n",
      "Epoch 19/300\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.0377 - acc: 0.9964 - f1_score: 0.9805 - val_loss: 1.8811 - val_acc: 0.9151 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00019: val_f1_score did not improve from 0.20886\n",
      "Epoch 20/300\n",
      "145/145 [==============================] - 5s 36ms/step - loss: 0.0411 - acc: 0.9965 - f1_score: 0.9809 - val_loss: 2.0204 - val_acc: 0.8742 - val_f1_score: 0.1143\n",
      "\n",
      "Epoch 00020: val_f1_score did not improve from 0.20886\n",
      "Epoch 21/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0406 - acc: 0.9967 - f1_score: 0.9817 - val_loss: 2.0131 - val_acc: 0.8863 - val_f1_score: 0.0667\n",
      "\n",
      "Epoch 00021: val_f1_score did not improve from 0.20886\n",
      "Epoch 22/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0320 - acc: 0.9973 - f1_score: 0.9849 - val_loss: 1.9352 - val_acc: 0.8937 - val_f1_score: 0.0069\n",
      "\n",
      "Epoch 00022: val_f1_score did not improve from 0.20886\n",
      "Epoch 23/300\n",
      "145/145 [==============================] - 5s 36ms/step - loss: 0.0363 - acc: 0.9970 - f1_score: 0.9830 - val_loss: 2.0303 - val_acc: 0.8996 - val_f1_score: 0.0145\n",
      "\n",
      "Epoch 00023: val_f1_score did not improve from 0.20886\n",
      "Epoch 24/300\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.0379 - acc: 0.9968 - f1_score: 0.9822 - val_loss: 1.9093 - val_acc: 0.8970 - val_f1_score: 0.0141\n",
      "\n",
      "Epoch 00024: val_f1_score did not improve from 0.20886\n",
      "Epoch 25/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0326 - acc: 0.9970 - f1_score: 0.9836 - val_loss: 1.9573 - val_acc: 0.8911 - val_f1_score: 0.0979\n",
      "\n",
      "Epoch 00025: val_f1_score did not improve from 0.20886\n",
      "Epoch 26/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0347 - acc: 0.9969 - f1_score: 0.9830 - val_loss: 2.0615 - val_acc: 0.8790 - val_f1_score: 0.0575\n",
      "\n",
      "Epoch 00026: val_f1_score did not improve from 0.20886\n",
      "Epoch 27/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0355 - acc: 0.9970 - f1_score: 0.9835 - val_loss: 2.0330 - val_acc: 0.8838 - val_f1_score: 0.0308\n",
      "\n",
      "Epoch 00027: val_f1_score did not improve from 0.20886\n",
      "Epoch 28/300\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 0.0279 - acc: 0.9977 - f1_score: 0.9876 - val_loss: 1.9360 - val_acc: 0.9022 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00028: val_f1_score did not improve from 0.20886\n",
      "Epoch 29/300\n",
      "145/145 [==============================] - 5s 36ms/step - loss: 0.0286 - acc: 0.9973 - f1_score: 0.9851 - val_loss: 1.9152 - val_acc: 0.8967 - val_f1_score: 0.0541\n",
      "\n",
      "Epoch 00029: val_f1_score did not improve from 0.20886\n",
      "Epoch 30/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0281 - acc: 0.9976 - f1_score: 0.9866 - val_loss: 2.0588 - val_acc: 0.8672 - val_f1_score: 0.0625\n",
      "\n",
      "Epoch 00030: val_f1_score did not improve from 0.20886\n",
      "Epoch 31/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0249 - acc: 0.9978 - f1_score: 0.9877 - val_loss: 1.8998 - val_acc: 0.8989 - val_f1_score: 0.0420\n",
      "\n",
      "Epoch 00031: val_f1_score did not improve from 0.20886\n",
      "Epoch 32/300\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 0.0261 - acc: 0.9975 - f1_score: 0.9865 - val_loss: 1.9067 - val_acc: 0.8908 - val_f1_score: 0.1190\n",
      "\n",
      "Epoch 00032: val_f1_score did not improve from 0.20886\n",
      "Epoch 33/300\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.0280 - acc: 0.9977 - f1_score: 0.9871 - val_loss: 2.0171 - val_acc: 0.8930 - val_f1_score: 0.0397\n",
      "\n",
      "Epoch 00033: val_f1_score did not improve from 0.20886\n",
      "Epoch 34/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0250 - acc: 0.9977 - f1_score: 0.9872 - val_loss: 1.9893 - val_acc: 0.8963 - val_f1_score: 0.0277\n",
      "\n",
      "Epoch 00034: val_f1_score did not improve from 0.20886\n",
      "Epoch 35/300\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 0.0237 - acc: 0.9980 - f1_score: 0.9892 - val_loss: 1.9313 - val_acc: 0.9133 - val_f1_score: 0.0084\n",
      "\n",
      "Epoch 00035: val_f1_score did not improve from 0.20886\n",
      "Epoch 36/300\n",
      "145/145 [==============================] - 5s 36ms/step - loss: 0.0238 - acc: 0.9979 - f1_score: 0.9884 - val_loss: 2.0163 - val_acc: 0.8900 - val_f1_score: 0.1337\n",
      "\n",
      "Epoch 00036: val_f1_score did not improve from 0.20886\n",
      "Epoch 37/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0206 - acc: 0.9982 - f1_score: 0.9904 - val_loss: 2.0870 - val_acc: 0.8982 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00037: val_f1_score did not improve from 0.20886\n",
      "Epoch 38/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0259 - acc: 0.9976 - f1_score: 0.9865 - val_loss: 2.1861 - val_acc: 0.8775 - val_f1_score: 0.0460\n",
      "\n",
      "Epoch 00038: val_f1_score did not improve from 0.20886\n",
      "Epoch 39/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0185 - acc: 0.9983 - f1_score: 0.9903 - val_loss: 2.0065 - val_acc: 0.9114 - val_f1_score: 0.0400\n",
      "\n",
      "Epoch 00039: val_f1_score did not improve from 0.20886\n",
      "Epoch 40/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0210 - acc: 0.9978 - f1_score: 0.9881 - val_loss: 1.7726 - val_acc: 0.9063 - val_f1_score: 0.1699\n",
      "\n",
      "Epoch 00040: val_f1_score did not improve from 0.20886\n",
      "Epoch 41/300\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 0.0238 - acc: 0.9979 - f1_score: 0.9884 - val_loss: 1.8209 - val_acc: 0.9125 - val_f1_score: 0.1255\n",
      "\n",
      "Epoch 00041: val_f1_score did not improve from 0.20886\n",
      "Epoch 42/300\n",
      "145/145 [==============================] - 5s 36ms/step - loss: 0.0199 - acc: 0.9982 - f1_score: 0.9903 - val_loss: 1.9758 - val_acc: 0.8897 - val_f1_score: 0.0685\n",
      "\n",
      "Epoch 00042: val_f1_score did not improve from 0.20886\n",
      "Epoch 43/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0257 - acc: 0.9976 - f1_score: 0.9865 - val_loss: 1.9134 - val_acc: 0.9033 - val_f1_score: 0.1963\n",
      "\n",
      "Epoch 00043: val_f1_score did not improve from 0.20886\n",
      "Epoch 44/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0187 - acc: 0.9983 - f1_score: 0.9905 - val_loss: 1.8763 - val_acc: 0.9066 - val_f1_score: 0.1424\n",
      "\n",
      "Epoch 00044: val_f1_score did not improve from 0.20886\n",
      "Epoch 45/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0173 - acc: 0.9985 - f1_score: 0.9917 - val_loss: 2.0937 - val_acc: 0.8926 - val_f1_score: 0.0762\n",
      "\n",
      "Epoch 00045: val_f1_score did not improve from 0.20886\n",
      "Epoch 46/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0145 - acc: 0.9987 - f1_score: 0.9932 - val_loss: 2.1218 - val_acc: 0.8934 - val_f1_score: 0.0334\n",
      "\n",
      "Epoch 00046: val_f1_score did not improve from 0.20886\n",
      "Epoch 47/300\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 0.0222 - acc: 0.9982 - f1_score: 0.9902 - val_loss: 1.8135 - val_acc: 0.9280 - val_f1_score: 0.1410\n",
      "\n",
      "Epoch 00047: val_f1_score did not improve from 0.20886\n",
      "Epoch 48/300\n",
      "145/145 [==============================] - 5s 36ms/step - loss: 0.0189 - acc: 0.9983 - f1_score: 0.9905 - val_loss: 1.8016 - val_acc: 0.9177 - val_f1_score: 0.1648\n",
      "\n",
      "Epoch 00048: val_f1_score did not improve from 0.20886\n",
      "Epoch 49/300\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 0.0200 - acc: 0.9981 - f1_score: 0.9898 - val_loss: 1.8821 - val_acc: 0.9059 - val_f1_score: 0.1297\n",
      "\n",
      "Epoch 00049: val_f1_score did not improve from 0.20886\n",
      "Epoch 50/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0188 - acc: 0.9983 - f1_score: 0.9909 - val_loss: 1.8286 - val_acc: 0.9236 - val_f1_score: 0.1411\n",
      "\n",
      "Epoch 00050: val_f1_score did not improve from 0.20886\n",
      "Epoch 51/300\n",
      "145/145 [==============================] - 6s 41ms/step - loss: 0.0170 - acc: 0.9985 - f1_score: 0.9916 - val_loss: 2.0523 - val_acc: 0.9011 - val_f1_score: 0.1355\n",
      "\n",
      "Epoch 00051: val_f1_score did not improve from 0.20886\n",
      "Epoch 52/300\n",
      "145/145 [==============================] - 6s 38ms/step - loss: 0.0180 - acc: 0.9984 - f1_score: 0.9910 - val_loss: 1.9689 - val_acc: 0.9070 - val_f1_score: 0.1064\n",
      "\n",
      "Epoch 00052: val_f1_score did not improve from 0.20886\n",
      "Epoch 53/300\n",
      "145/145 [==============================] - 5s 36ms/step - loss: 0.0177 - acc: 0.9984 - f1_score: 0.9910 - val_loss: 2.1486 - val_acc: 0.8923 - val_f1_score: 0.0759\n",
      "\n",
      "Epoch 00053: val_f1_score did not improve from 0.20886\n",
      "Epoch 54/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0184 - acc: 0.9982 - f1_score: 0.9903 - val_loss: 2.0948 - val_acc: 0.9004 - val_f1_score: 0.0426\n",
      "\n",
      "Epoch 00054: val_f1_score did not improve from 0.20886\n",
      "Epoch 55/300\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 0.0170 - acc: 0.9985 - f1_score: 0.9918 - val_loss: 1.9848 - val_acc: 0.9000 - val_f1_score: 0.0687\n",
      "\n",
      "Epoch 00055: val_f1_score did not improve from 0.20886\n",
      "Epoch 56/300\n",
      "145/145 [==============================] - 5s 36ms/step - loss: 0.0141 - acc: 0.9986 - f1_score: 0.9921 - val_loss: 1.9739 - val_acc: 0.9030 - val_f1_score: 0.1262\n",
      "\n",
      "Epoch 00056: val_f1_score did not improve from 0.20886\n",
      "Epoch 00056: early stopping\n",
      "(0.13609958506224068, 2.8760024e-07)\n",
      "(0.22762814943527368, 2.1950434e-06)\n",
      "0.5612244897959184\n",
      "1315 (15545,)\n",
      "28930\n",
      "(None, 1, 1) coeff (None, 5, 30) amplitude\n",
      "Epoch 1/300\n",
      "145/145 [==============================] - 14s 52ms/step - loss: 1.4019 - acc: 0.8833 - f1_score: 0.0556 - val_loss: 1.2365 - val_acc: 0.8970 - val_f1_score: 0.1914\n",
      "\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.19139, saving model to ./models/lag_15_iter_0_split_5_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_f1_both.hdf5\n",
      "Epoch 2/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.6872 - acc: 0.9461 - f1_score: 0.6454 - val_loss: 1.2997 - val_acc: 0.9265 - val_f1_score: 0.1831\n",
      "\n",
      "Epoch 00002: val_f1_score did not improve from 0.19139\n",
      "Epoch 3/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.3546 - acc: 0.9706 - f1_score: 0.8230 - val_loss: 1.3276 - val_acc: 0.9272 - val_f1_score: 0.2007\n",
      "\n",
      "Epoch 00003: val_f1_score improved from 0.19139 to 0.20067, saving model to ./models/lag_15_iter_0_split_5_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_f1_both.hdf5\n",
      "Epoch 4/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.2263 - acc: 0.9807 - f1_score: 0.8885 - val_loss: 1.4671 - val_acc: 0.9061 - val_f1_score: 0.1630\n",
      "\n",
      "Epoch 00004: val_f1_score did not improve from 0.20067\n",
      "Epoch 5/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.1818 - acc: 0.9838 - f1_score: 0.9117 - val_loss: 1.5337 - val_acc: 0.9067 - val_f1_score: 0.1593\n",
      "\n",
      "Epoch 00005: val_f1_score did not improve from 0.20067\n",
      "Epoch 6/300\n",
      "145/145 [==============================] - 6s 41ms/step - loss: 0.1277 - acc: 0.9889 - f1_score: 0.9379 - val_loss: 1.5445 - val_acc: 0.9058 - val_f1_score: 0.1246\n",
      "\n",
      "Epoch 00006: val_f1_score did not improve from 0.20067\n",
      "Epoch 7/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.1155 - acc: 0.9901 - f1_score: 0.9449 - val_loss: 1.5875 - val_acc: 0.9098 - val_f1_score: 0.1591\n",
      "\n",
      "Epoch 00007: val_f1_score did not improve from 0.20067\n",
      "Epoch 8/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.1051 - acc: 0.9912 - f1_score: 0.9501 - val_loss: 1.6176 - val_acc: 0.9077 - val_f1_score: 0.1789\n",
      "\n",
      "Epoch 00008: val_f1_score did not improve from 0.20067\n",
      "Epoch 9/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0858 - acc: 0.9924 - f1_score: 0.9567 - val_loss: 1.6330 - val_acc: 0.8997 - val_f1_score: 0.1499\n",
      "\n",
      "Epoch 00009: val_f1_score did not improve from 0.20067\n",
      "Epoch 10/300\n",
      "145/145 [==============================] - 6s 41ms/step - loss: 0.0702 - acc: 0.9939 - f1_score: 0.9662 - val_loss: 1.7585 - val_acc: 0.8875 - val_f1_score: 0.1235\n",
      "\n",
      "Epoch 00010: val_f1_score did not improve from 0.20067\n",
      "Epoch 11/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0699 - acc: 0.9944 - f1_score: 0.9693 - val_loss: 1.5619 - val_acc: 0.9156 - val_f1_score: 0.1731\n",
      "\n",
      "Epoch 00011: val_f1_score did not improve from 0.20067\n",
      "Epoch 12/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0596 - acc: 0.9948 - f1_score: 0.9707 - val_loss: 1.5438 - val_acc: 0.9201 - val_f1_score: 0.1963\n",
      "\n",
      "Epoch 00012: val_f1_score did not improve from 0.20067\n",
      "Epoch 13/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0667 - acc: 0.9939 - f1_score: 0.9666 - val_loss: 1.5154 - val_acc: 0.9272 - val_f1_score: 0.2007\n",
      "\n",
      "Epoch 00013: val_f1_score did not improve from 0.20067\n",
      "Epoch 14/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0566 - acc: 0.9948 - f1_score: 0.9714 - val_loss: 1.6210 - val_acc: 0.9119 - val_f1_score: 0.1623\n",
      "\n",
      "Epoch 00014: val_f1_score did not improve from 0.20067\n",
      "Epoch 15/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0535 - acc: 0.9956 - f1_score: 0.9749 - val_loss: 1.6028 - val_acc: 0.9159 - val_f1_score: 0.1737\n",
      "\n",
      "Epoch 00015: val_f1_score did not improve from 0.20067\n",
      "Epoch 16/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0637 - acc: 0.9946 - f1_score: 0.9696 - val_loss: 1.5656 - val_acc: 0.9250 - val_f1_score: 0.1517\n",
      "\n",
      "Epoch 00016: val_f1_score did not improve from 0.20067\n",
      "Epoch 17/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0550 - acc: 0.9950 - f1_score: 0.9721 - val_loss: 1.6272 - val_acc: 0.9171 - val_f1_score: 0.1758\n",
      "\n",
      "Epoch 00017: val_f1_score did not improve from 0.20067\n",
      "Epoch 18/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0578 - acc: 0.9948 - f1_score: 0.9710 - val_loss: 1.6707 - val_acc: 0.9137 - val_f1_score: 0.1602\n",
      "\n",
      "Epoch 00018: val_f1_score did not improve from 0.20067\n",
      "Epoch 19/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0466 - acc: 0.9959 - f1_score: 0.9767 - val_loss: 1.6089 - val_acc: 0.9177 - val_f1_score: 0.1667\n",
      "\n",
      "Epoch 00019: val_f1_score did not improve from 0.20067\n",
      "Epoch 20/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0402 - acc: 0.9962 - f1_score: 0.9789 - val_loss: 1.6128 - val_acc: 0.9180 - val_f1_score: 0.1672\n",
      "\n",
      "Epoch 00020: val_f1_score did not improve from 0.20067\n",
      "Epoch 21/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0487 - acc: 0.9955 - f1_score: 0.9747 - val_loss: 1.7231 - val_acc: 0.9064 - val_f1_score: 0.1303\n",
      "\n",
      "Epoch 00021: val_f1_score did not improve from 0.20067\n",
      "Epoch 22/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0429 - acc: 0.9961 - f1_score: 0.9779 - val_loss: 1.5981 - val_acc: 0.9229 - val_f1_score: 0.1759\n",
      "\n",
      "Epoch 00022: val_f1_score did not improve from 0.20067\n",
      "Epoch 23/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0354 - acc: 0.9968 - f1_score: 0.9824 - val_loss: 1.5657 - val_acc: 0.9259 - val_f1_score: 0.1873\n",
      "\n",
      "Epoch 00023: val_f1_score did not improve from 0.20067\n",
      "Epoch 24/300\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.0417 - acc: 0.9959 - f1_score: 0.9775 - val_loss: 1.7046 - val_acc: 0.9107 - val_f1_score: 0.1556\n",
      "\n",
      "Epoch 00024: val_f1_score did not improve from 0.20067\n",
      "Epoch 25/300\n",
      "145/145 [==============================] - 5s 36ms/step - loss: 0.0300 - acc: 0.9973 - f1_score: 0.9856 - val_loss: 1.6363 - val_acc: 0.9229 - val_f1_score: 0.1705\n",
      "\n",
      "Epoch 00025: val_f1_score did not improve from 0.20067\n",
      "Epoch 26/300\n",
      "145/145 [==============================] - 6s 41ms/step - loss: 0.0281 - acc: 0.9975 - f1_score: 0.9862 - val_loss: 1.6990 - val_acc: 0.9153 - val_f1_score: 0.1726\n",
      "\n",
      "Epoch 00026: val_f1_score did not improve from 0.20067\n",
      "Epoch 27/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0289 - acc: 0.9975 - f1_score: 0.9856 - val_loss: 1.5851 - val_acc: 0.9229 - val_f1_score: 0.1865\n",
      "\n",
      "Epoch 00027: val_f1_score did not improve from 0.20067\n",
      "Epoch 28/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0442 - acc: 0.9958 - f1_score: 0.9773 - val_loss: 1.6932 - val_acc: 0.9159 - val_f1_score: 0.1636\n",
      "\n",
      "Epoch 00028: val_f1_score did not improve from 0.20067\n",
      "Epoch 29/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.0258 - acc: 0.9976 - f1_score: 0.9870 - val_loss: 1.6590 - val_acc: 0.9195 - val_f1_score: 0.1646\n",
      "\n",
      "Epoch 00029: val_f1_score did not improve from 0.20067\n",
      "Epoch 30/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.0350 - acc: 0.9969 - f1_score: 0.9829 - val_loss: 1.6958 - val_acc: 0.9189 - val_f1_score: 0.1250\n",
      "\n",
      "Epoch 00030: val_f1_score did not improve from 0.20067\n",
      "Epoch 31/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.0330 - acc: 0.9970 - f1_score: 0.9824 - val_loss: 1.7035 - val_acc: 0.9089 - val_f1_score: 0.1577\n",
      "\n",
      "Epoch 00031: val_f1_score did not improve from 0.20067\n",
      "Epoch 32/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.0302 - acc: 0.9972 - f1_score: 0.9846 - val_loss: 1.6984 - val_acc: 0.9208 - val_f1_score: 0.1613\n",
      "\n",
      "Epoch 00032: val_f1_score did not improve from 0.20067\n",
      "Epoch 33/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.0244 - acc: 0.9978 - f1_score: 0.9878 - val_loss: 1.7679 - val_acc: 0.9125 - val_f1_score: 0.1534\n",
      "\n",
      "Epoch 00033: val_f1_score did not improve from 0.20067\n",
      "Epoch 34/300\n",
      "145/145 [==============================] - 7s 45ms/step - loss: 0.0233 - acc: 0.9981 - f1_score: 0.9898 - val_loss: 1.7169 - val_acc: 0.9162 - val_f1_score: 0.1538\n",
      "\n",
      "Epoch 00034: val_f1_score did not improve from 0.20067\n",
      "Epoch 35/300\n",
      "145/145 [==============================] - 7s 45ms/step - loss: 0.0249 - acc: 0.9978 - f1_score: 0.9880 - val_loss: 1.6243 - val_acc: 0.9305 - val_f1_score: 0.1739\n",
      "\n",
      "Epoch 00035: val_f1_score did not improve from 0.20067\n",
      "Epoch 36/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.0246 - acc: 0.9978 - f1_score: 0.9879 - val_loss: 1.6152 - val_acc: 0.9238 - val_f1_score: 0.1667\n",
      "\n",
      "Epoch 00036: val_f1_score did not improve from 0.20067\n",
      "Epoch 37/300\n",
      "145/145 [==============================] - 7s 45ms/step - loss: 0.0266 - acc: 0.9978 - f1_score: 0.9884 - val_loss: 1.6445 - val_acc: 0.9186 - val_f1_score: 0.1577\n",
      "\n",
      "Epoch 00037: val_f1_score did not improve from 0.20067\n",
      "Epoch 38/300\n",
      "145/145 [==============================] - 7s 45ms/step - loss: 0.0311 - acc: 0.9972 - f1_score: 0.9847 - val_loss: 1.6722 - val_acc: 0.9205 - val_f1_score: 0.1818\n",
      "\n",
      "Epoch 00038: val_f1_score did not improve from 0.20067\n",
      "Epoch 39/300\n",
      "145/145 [==============================] - 7s 45ms/step - loss: 0.0267 - acc: 0.9978 - f1_score: 0.9878 - val_loss: 1.7397 - val_acc: 0.9171 - val_f1_score: 0.1500\n",
      "\n",
      "Epoch 00039: val_f1_score did not improve from 0.20067\n",
      "Epoch 40/300\n",
      "145/145 [==============================] - 7s 45ms/step - loss: 0.0226 - acc: 0.9979 - f1_score: 0.9885 - val_loss: 1.7626 - val_acc: 0.9144 - val_f1_score: 0.1511\n",
      "\n",
      "Epoch 00040: val_f1_score did not improve from 0.20067\n",
      "Epoch 41/300\n",
      "145/145 [==============================] - 7s 45ms/step - loss: 0.0232 - acc: 0.9979 - f1_score: 0.9885 - val_loss: 1.7812 - val_acc: 0.9147 - val_f1_score: 0.1716\n",
      "\n",
      "Epoch 00041: val_f1_score did not improve from 0.20067\n",
      "Epoch 42/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.0205 - acc: 0.9983 - f1_score: 0.9904 - val_loss: 1.9631 - val_acc: 0.8997 - val_f1_score: 0.1319\n",
      "\n",
      "Epoch 00042: val_f1_score did not improve from 0.20067\n",
      "Epoch 43/300\n",
      "145/145 [==============================] - 7s 45ms/step - loss: 0.0216 - acc: 0.9981 - f1_score: 0.9894 - val_loss: 1.8687 - val_acc: 0.9077 - val_f1_score: 0.1560\n",
      "\n",
      "Epoch 00043: val_f1_score did not improve from 0.20067\n",
      "Epoch 00043: early stopping\n",
      "(0.1581081081081081, 0.00050982344)\n",
      "(0.15145631067961166, 0.00043399207)\n",
      "0.6527769848623914\n",
      "1316 (18118,)\n",
      "28952\n",
      "(None, 1, 1) coeff (None, 5, 30) amplitude\n",
      "Epoch 1/300\n",
      "145/145 [==============================] - 15s 56ms/step - loss: 1.1896 - acc: 0.9116 - f1_score: 0.1073 - val_loss: 1.5173 - val_acc: 0.8734 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.00000, saving model to ./models/lag_15_iter_0_split_6_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_f1_both.hdf5\n",
      "Epoch 2/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.4521 - acc: 0.9615 - f1_score: 0.7764 - val_loss: 1.8401 - val_acc: 0.8734 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_f1_score did not improve from 0.00000\n",
      "Epoch 3/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.2120 - acc: 0.9826 - f1_score: 0.9011 - val_loss: 1.9691 - val_acc: 0.8840 - val_f1_score: 0.0073\n",
      "\n",
      "Epoch 00003: val_f1_score improved from 0.00000 to 0.00727, saving model to ./models/lag_15_iter_0_split_6_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_f1_both.hdf5\n",
      "Epoch 4/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.1560 - acc: 0.9858 - f1_score: 0.9225 - val_loss: 1.9353 - val_acc: 0.8959 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_f1_score did not improve from 0.00727\n",
      "Epoch 5/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.1072 - acc: 0.9905 - f1_score: 0.9482 - val_loss: 2.1177 - val_acc: 0.8823 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_f1_score did not improve from 0.00727\n",
      "Epoch 6/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0828 - acc: 0.9928 - f1_score: 0.9620 - val_loss: 2.0180 - val_acc: 0.8997 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_f1_score did not improve from 0.00727\n",
      "Epoch 7/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0848 - acc: 0.9929 - f1_score: 0.9607 - val_loss: 2.1547 - val_acc: 0.8840 - val_f1_score: 0.0683\n",
      "\n",
      "Epoch 00007: val_f1_score improved from 0.00727 to 0.06826, saving model to ./models/lag_15_iter_0_split_6_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_f1_both.hdf5\n",
      "Epoch 8/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0616 - acc: 0.9946 - f1_score: 0.9705 - val_loss: 2.0903 - val_acc: 0.8823 - val_f1_score: 0.0610\n",
      "\n",
      "Epoch 00008: val_f1_score did not improve from 0.06826\n",
      "Epoch 9/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.0685 - acc: 0.9940 - f1_score: 0.9670 - val_loss: 2.0267 - val_acc: 0.9010 - val_f1_score: 0.0791\n",
      "\n",
      "Epoch 00009: val_f1_score improved from 0.06826 to 0.07905, saving model to ./models/lag_15_iter_0_split_6_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_f1_both.hdf5\n",
      "Epoch 10/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0617 - acc: 0.9950 - f1_score: 0.9713 - val_loss: 2.0836 - val_acc: 0.8849 - val_f1_score: 0.0287\n",
      "\n",
      "Epoch 00010: val_f1_score did not improve from 0.07905\n",
      "Epoch 11/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0471 - acc: 0.9961 - f1_score: 0.9781 - val_loss: 2.1351 - val_acc: 0.8649 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00011: val_f1_score did not improve from 0.07905\n",
      "Epoch 12/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.0486 - acc: 0.9958 - f1_score: 0.9761 - val_loss: 2.2217 - val_acc: 0.8615 - val_f1_score: 0.0181\n",
      "\n",
      "Epoch 00012: val_f1_score did not improve from 0.07905\n",
      "Epoch 13/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.0432 - acc: 0.9966 - f1_score: 0.9812 - val_loss: 1.9769 - val_acc: 0.8772 - val_f1_score: 0.0334\n",
      "\n",
      "Epoch 00013: val_f1_score did not improve from 0.07905\n",
      "Epoch 14/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0423 - acc: 0.9962 - f1_score: 0.9794 - val_loss: 2.1301 - val_acc: 0.8823 - val_f1_score: 0.0072\n",
      "\n",
      "Epoch 00014: val_f1_score did not improve from 0.07905\n",
      "Epoch 15/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.0365 - acc: 0.9968 - f1_score: 0.9828 - val_loss: 1.9417 - val_acc: 0.9036 - val_f1_score: 0.0087\n",
      "\n",
      "Epoch 00015: val_f1_score did not improve from 0.07905\n",
      "Epoch 16/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.0495 - acc: 0.9958 - f1_score: 0.9773 - val_loss: 2.0488 - val_acc: 0.9006 - val_f1_score: 0.0250\n",
      "\n",
      "Epoch 00016: val_f1_score did not improve from 0.07905\n",
      "Epoch 17/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.0347 - acc: 0.9970 - f1_score: 0.9836 - val_loss: 2.0660 - val_acc: 0.8840 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00017: val_f1_score did not improve from 0.07905\n",
      "Epoch 18/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.0326 - acc: 0.9967 - f1_score: 0.9823 - val_loss: 2.1904 - val_acc: 0.8670 - val_f1_score: 0.0249\n",
      "\n",
      "Epoch 00018: val_f1_score did not improve from 0.07905\n",
      "Epoch 19/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0385 - acc: 0.9966 - f1_score: 0.9811 - val_loss: 2.2790 - val_acc: 0.8632 - val_f1_score: 0.0473\n",
      "\n",
      "Epoch 00019: val_f1_score did not improve from 0.07905\n",
      "Epoch 20/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.0362 - acc: 0.9966 - f1_score: 0.9813 - val_loss: 2.0419 - val_acc: 0.8908 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00020: val_f1_score did not improve from 0.07905\n",
      "Epoch 21/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0469 - acc: 0.9957 - f1_score: 0.9753 - val_loss: 2.0381 - val_acc: 0.8891 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00021: val_f1_score did not improve from 0.07905\n",
      "Epoch 22/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.0242 - acc: 0.9977 - f1_score: 0.9873 - val_loss: 2.1887 - val_acc: 0.8772 - val_f1_score: 0.0525\n",
      "\n",
      "Epoch 00022: val_f1_score did not improve from 0.07905\n",
      "Epoch 23/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0246 - acc: 0.9978 - f1_score: 0.9880 - val_loss: 2.0604 - val_acc: 0.8942 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00023: val_f1_score did not improve from 0.07905\n",
      "Epoch 24/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.0277 - acc: 0.9973 - f1_score: 0.9849 - val_loss: 2.0860 - val_acc: 0.8934 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00024: val_f1_score did not improve from 0.07905\n",
      "Epoch 25/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0325 - acc: 0.9973 - f1_score: 0.9853 - val_loss: 2.0605 - val_acc: 0.8942 - val_f1_score: 0.0604\n",
      "\n",
      "Epoch 00025: val_f1_score did not improve from 0.07905\n",
      "Epoch 26/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0288 - acc: 0.9973 - f1_score: 0.9851 - val_loss: 2.1401 - val_acc: 0.8929 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00026: val_f1_score did not improve from 0.07905\n",
      "Epoch 27/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0257 - acc: 0.9977 - f1_score: 0.9872 - val_loss: 2.1769 - val_acc: 0.8904 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00027: val_f1_score did not improve from 0.07905\n",
      "Epoch 28/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0327 - acc: 0.9971 - f1_score: 0.9837 - val_loss: 2.0780 - val_acc: 0.8934 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00028: val_f1_score did not improve from 0.07905\n",
      "Epoch 29/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0289 - acc: 0.9973 - f1_score: 0.9854 - val_loss: 1.9984 - val_acc: 0.8980 - val_f1_score: 0.0977\n",
      "\n",
      "Epoch 00029: val_f1_score improved from 0.07905 to 0.09774, saving model to ./models/lag_15_iter_0_split_6_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_f1_both.hdf5\n",
      "Epoch 30/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0278 - acc: 0.9975 - f1_score: 0.9865 - val_loss: 2.0915 - val_acc: 0.8738 - val_f1_score: 0.1586\n",
      "\n",
      "Epoch 00030: val_f1_score improved from 0.09774 to 0.15864, saving model to ./models/lag_15_iter_0_split_6_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_f1_both.hdf5\n",
      "Epoch 31/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0253 - acc: 0.9977 - f1_score: 0.9871 - val_loss: 2.1541 - val_acc: 0.8836 - val_f1_score: 0.0616\n",
      "\n",
      "Epoch 00031: val_f1_score did not improve from 0.15864\n",
      "Epoch 32/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.0291 - acc: 0.9973 - f1_score: 0.9849 - val_loss: 2.2019 - val_acc: 0.8828 - val_f1_score: 0.1097\n",
      "\n",
      "Epoch 00032: val_f1_score did not improve from 0.15864\n",
      "Epoch 33/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0333 - acc: 0.9970 - f1_score: 0.9839 - val_loss: 2.1866 - val_acc: 0.8764 - val_f1_score: 0.0762\n",
      "\n",
      "Epoch 00033: val_f1_score did not improve from 0.15864\n",
      "Epoch 34/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.0224 - acc: 0.9980 - f1_score: 0.9887 - val_loss: 2.0187 - val_acc: 0.8874 - val_f1_score: 0.1017\n",
      "\n",
      "Epoch 00034: val_f1_score did not improve from 0.15864\n",
      "Epoch 35/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.0229 - acc: 0.9975 - f1_score: 0.9858 - val_loss: 2.2514 - val_acc: 0.8870 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00035: val_f1_score did not improve from 0.15864\n",
      "Epoch 36/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0280 - acc: 0.9977 - f1_score: 0.9870 - val_loss: 2.3689 - val_acc: 0.8556 - val_f1_score: 0.0058\n",
      "\n",
      "Epoch 00036: val_f1_score did not improve from 0.15864\n",
      "Epoch 37/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0174 - acc: 0.9984 - f1_score: 0.9908 - val_loss: 2.2498 - val_acc: 0.8900 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00037: val_f1_score did not improve from 0.15864\n",
      "Epoch 38/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0257 - acc: 0.9979 - f1_score: 0.9883 - val_loss: 2.2286 - val_acc: 0.8951 - val_f1_score: 0.0159\n",
      "\n",
      "Epoch 00038: val_f1_score did not improve from 0.15864\n",
      "Epoch 39/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.0229 - acc: 0.9981 - f1_score: 0.9894 - val_loss: 2.2695 - val_acc: 0.8815 - val_f1_score: 0.0412\n",
      "\n",
      "Epoch 00039: val_f1_score did not improve from 0.15864\n",
      "Epoch 40/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0175 - acc: 0.9985 - f1_score: 0.9919 - val_loss: 2.1707 - val_acc: 0.8904 - val_f1_score: 0.0652\n",
      "\n",
      "Epoch 00040: val_f1_score did not improve from 0.15864\n",
      "Epoch 41/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0185 - acc: 0.9983 - f1_score: 0.9909 - val_loss: 2.0049 - val_acc: 0.9095 - val_f1_score: 0.0274\n",
      "\n",
      "Epoch 00041: val_f1_score did not improve from 0.15864\n",
      "Epoch 42/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0188 - acc: 0.9985 - f1_score: 0.9915 - val_loss: 2.0042 - val_acc: 0.8904 - val_f1_score: 0.0979\n",
      "\n",
      "Epoch 00042: val_f1_score did not improve from 0.15864\n",
      "Epoch 43/300\n",
      "145/145 [==============================] - 6s 41ms/step - loss: 0.0188 - acc: 0.9983 - f1_score: 0.9908 - val_loss: 2.1054 - val_acc: 0.8853 - val_f1_score: 0.0940\n",
      "\n",
      "Epoch 00043: val_f1_score did not improve from 0.15864\n",
      "Epoch 44/300\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.0205 - acc: 0.9978 - f1_score: 0.9876 - val_loss: 2.2079 - val_acc: 0.8840 - val_f1_score: 0.0870\n",
      "\n",
      "Epoch 00044: val_f1_score did not improve from 0.15864\n",
      "Epoch 45/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0177 - acc: 0.9984 - f1_score: 0.9913 - val_loss: 2.1017 - val_acc: 0.8980 - val_f1_score: 0.0323\n",
      "\n",
      "Epoch 00045: val_f1_score did not improve from 0.15864\n",
      "Epoch 46/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0123 - acc: 0.9989 - f1_score: 0.9940 - val_loss: 2.3994 - val_acc: 0.8675 - val_f1_score: 0.0488\n",
      "\n",
      "Epoch 00046: val_f1_score did not improve from 0.15864\n",
      "Epoch 47/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0225 - acc: 0.9979 - f1_score: 0.9885 - val_loss: 2.1721 - val_acc: 0.8912 - val_f1_score: 0.1233\n",
      "\n",
      "Epoch 00047: val_f1_score did not improve from 0.15864\n",
      "Epoch 48/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0272 - acc: 0.9977 - f1_score: 0.9870 - val_loss: 2.2803 - val_acc: 0.8760 - val_f1_score: 0.0519\n",
      "\n",
      "Epoch 00048: val_f1_score did not improve from 0.15864\n",
      "Epoch 49/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0168 - acc: 0.9987 - f1_score: 0.9928 - val_loss: 2.5786 - val_acc: 0.8479 - val_f1_score: 0.0324\n",
      "\n",
      "Epoch 00049: val_f1_score did not improve from 0.15864\n",
      "Epoch 50/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0180 - acc: 0.9984 - f1_score: 0.9915 - val_loss: 2.4122 - val_acc: 0.8687 - val_f1_score: 0.0374\n",
      "\n",
      "Epoch 00050: val_f1_score did not improve from 0.15864\n",
      "Epoch 51/300\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.0178 - acc: 0.9983 - f1_score: 0.9912 - val_loss: 2.3819 - val_acc: 0.8726 - val_f1_score: 0.0196\n",
      "\n",
      "Epoch 00051: val_f1_score did not improve from 0.15864\n",
      "Epoch 52/300\n",
      "145/145 [==============================] - 6s 41ms/step - loss: 0.0212 - acc: 0.9982 - f1_score: 0.9898 - val_loss: 2.1783 - val_acc: 0.8866 - val_f1_score: 0.0565\n",
      "\n",
      "Epoch 00052: val_f1_score did not improve from 0.15864\n",
      "Epoch 53/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0191 - acc: 0.9982 - f1_score: 0.9897 - val_loss: 2.1159 - val_acc: 0.9044 - val_f1_score: 0.0426\n",
      "\n",
      "Epoch 00053: val_f1_score did not improve from 0.15864\n",
      "Epoch 54/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0159 - acc: 0.9985 - f1_score: 0.9916 - val_loss: 2.3377 - val_acc: 0.8730 - val_f1_score: 0.0508\n",
      "\n",
      "Epoch 00054: val_f1_score did not improve from 0.15864\n",
      "Epoch 55/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0144 - acc: 0.9986 - f1_score: 0.9926 - val_loss: 2.3751 - val_acc: 0.8768 - val_f1_score: 0.0523\n",
      "\n",
      "Epoch 00055: val_f1_score did not improve from 0.15864\n",
      "Epoch 56/300\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.0134 - acc: 0.9989 - f1_score: 0.9941 - val_loss: 2.2123 - val_acc: 0.8845 - val_f1_score: 0.0556\n",
      "\n",
      "Epoch 00056: val_f1_score did not improve from 0.15864\n",
      "Epoch 57/300\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.0169 - acc: 0.9983 - f1_score: 0.9908 - val_loss: 2.4231 - val_acc: 0.8619 - val_f1_score: 0.0469\n",
      "\n",
      "Epoch 00057: val_f1_score did not improve from 0.15864\n",
      "Epoch 58/300\n",
      "145/145 [==============================] - 5s 35ms/step - loss: 0.0175 - acc: 0.9984 - f1_score: 0.9910 - val_loss: 2.3941 - val_acc: 0.8832 - val_f1_score: 0.0143\n",
      "\n",
      "Epoch 00058: val_f1_score did not improve from 0.15864\n",
      "Epoch 59/300\n",
      "145/145 [==============================] - 5s 32ms/step - loss: 0.0123 - acc: 0.9990 - f1_score: 0.9947 - val_loss: 2.2402 - val_acc: 0.8938 - val_f1_score: 0.1071\n",
      "\n",
      "Epoch 00059: val_f1_score did not improve from 0.15864\n",
      "Epoch 60/300\n",
      "145/145 [==============================] - 4s 27ms/step - loss: 0.0169 - acc: 0.9984 - f1_score: 0.9917 - val_loss: 2.5349 - val_acc: 0.8670 - val_f1_score: 0.0369\n",
      "\n",
      "Epoch 00060: val_f1_score did not improve from 0.15864\n",
      "Epoch 61/300\n",
      "145/145 [==============================] - 4s 28ms/step - loss: 0.0129 - acc: 0.9987 - f1_score: 0.9928 - val_loss: 2.4099 - val_acc: 0.8738 - val_f1_score: 0.0326\n",
      "\n",
      "Epoch 00061: val_f1_score did not improve from 0.15864\n",
      "Epoch 62/300\n",
      "145/145 [==============================] - 4s 25ms/step - loss: 0.0160 - acc: 0.9985 - f1_score: 0.9917 - val_loss: 2.4045 - val_acc: 0.8709 - val_f1_score: 0.0194\n",
      "\n",
      "Epoch 00062: val_f1_score did not improve from 0.15864\n",
      "Epoch 63/300\n",
      "145/145 [==============================] - 3s 23ms/step - loss: 0.0162 - acc: 0.9985 - f1_score: 0.9913 - val_loss: 2.1338 - val_acc: 0.8989 - val_f1_score: 0.1905\n",
      "\n",
      "Epoch 00063: val_f1_score improved from 0.15864 to 0.19048, saving model to ./models/lag_15_iter_0_split_6_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_f1_both.hdf5\n",
      "Epoch 64/300\n",
      "145/145 [==============================] - 4s 29ms/step - loss: 0.0126 - acc: 0.9989 - f1_score: 0.9940 - val_loss: 2.4137 - val_acc: 0.8738 - val_f1_score: 0.0511\n",
      "\n",
      "Epoch 00064: val_f1_score did not improve from 0.19048\n",
      "Epoch 65/300\n",
      "145/145 [==============================] - 5s 34ms/step - loss: 0.0137 - acc: 0.9988 - f1_score: 0.9932 - val_loss: 2.4384 - val_acc: 0.8879 - val_f1_score: 0.0571\n",
      "\n",
      "Epoch 00065: val_f1_score did not improve from 0.19048\n",
      "Epoch 66/300\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.0091 - acc: 0.9992 - f1_score: 0.9958 - val_loss: 2.1728 - val_acc: 0.9133 - val_f1_score: 0.1429\n",
      "\n",
      "Epoch 00066: val_f1_score did not improve from 0.19048\n",
      "Epoch 67/300\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.0103 - acc: 0.9991 - f1_score: 0.9951 - val_loss: 2.1246 - val_acc: 0.9150 - val_f1_score: 0.1736\n",
      "\n",
      "Epoch 00067: val_f1_score did not improve from 0.19048\n",
      "Epoch 68/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0103 - acc: 0.9991 - f1_score: 0.9953 - val_loss: 2.1730 - val_acc: 0.9112 - val_f1_score: 0.1255\n",
      "\n",
      "Epoch 00068: val_f1_score did not improve from 0.19048\n",
      "Epoch 69/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0097 - acc: 0.9991 - f1_score: 0.9953 - val_loss: 2.3137 - val_acc: 0.9014 - val_f1_score: 0.1343\n",
      "\n",
      "Epoch 00069: val_f1_score did not improve from 0.19048\n",
      "Epoch 70/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0132 - acc: 0.9989 - f1_score: 0.9943 - val_loss: 2.5062 - val_acc: 0.8853 - val_f1_score: 0.0288\n",
      "\n",
      "Epoch 00070: val_f1_score did not improve from 0.19048\n",
      "Epoch 71/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0106 - acc: 0.9991 - f1_score: 0.9950 - val_loss: 2.5822 - val_acc: 0.8968 - val_f1_score: 0.0545\n",
      "\n",
      "Epoch 00071: val_f1_score did not improve from 0.19048\n",
      "Epoch 72/300\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.0145 - acc: 0.9988 - f1_score: 0.9937 - val_loss: 2.2740 - val_acc: 0.9057 - val_f1_score: 0.0976\n",
      "\n",
      "Epoch 00072: val_f1_score did not improve from 0.19048\n",
      "Epoch 73/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0110 - acc: 0.9989 - f1_score: 0.9942 - val_loss: 2.3087 - val_acc: 0.9040 - val_f1_score: 0.0887\n",
      "\n",
      "Epoch 00073: val_f1_score did not improve from 0.19048\n",
      "Epoch 74/300\n",
      "145/145 [==============================] - 6s 41ms/step - loss: 0.0117 - acc: 0.9990 - f1_score: 0.9947 - val_loss: 2.2396 - val_acc: 0.8989 - val_f1_score: 0.1314\n",
      "\n",
      "Epoch 00074: val_f1_score did not improve from 0.19048\n",
      "Epoch 75/300\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.0081 - acc: 0.9994 - f1_score: 0.9969 - val_loss: 2.4732 - val_acc: 0.8802 - val_f1_score: 0.1296\n",
      "\n",
      "Epoch 00075: val_f1_score did not improve from 0.19048\n",
      "Epoch 76/300\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.0118 - acc: 0.9988 - f1_score: 0.9933 - val_loss: 2.4779 - val_acc: 0.8874 - val_f1_score: 0.0636\n",
      "\n",
      "Epoch 00076: val_f1_score did not improve from 0.19048\n",
      "Epoch 77/300\n",
      "145/145 [==============================] - 6s 41ms/step - loss: 0.0108 - acc: 0.9991 - f1_score: 0.9950 - val_loss: 2.4647 - val_acc: 0.8853 - val_f1_score: 0.1290\n",
      "\n",
      "Epoch 00077: val_f1_score did not improve from 0.19048\n",
      "Epoch 78/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0142 - acc: 0.9988 - f1_score: 0.9937 - val_loss: 2.9282 - val_acc: 0.8619 - val_f1_score: 0.0469\n",
      "\n",
      "Epoch 00078: val_f1_score did not improve from 0.19048\n",
      "Epoch 79/300\n",
      "145/145 [==============================] - 6s 45ms/step - loss: 0.0093 - acc: 0.9990 - f1_score: 0.9945 - val_loss: 2.7113 - val_acc: 0.8832 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00079: val_f1_score did not improve from 0.19048\n",
      "Epoch 80/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0108 - acc: 0.9990 - f1_score: 0.9946 - val_loss: 2.6083 - val_acc: 0.8857 - val_f1_score: 0.0427\n",
      "\n",
      "Epoch 00080: val_f1_score did not improve from 0.19048\n",
      "Epoch 81/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0104 - acc: 0.9991 - f1_score: 0.9953 - val_loss: 2.5105 - val_acc: 0.9019 - val_f1_score: 0.0253\n",
      "\n",
      "Epoch 00081: val_f1_score did not improve from 0.19048\n",
      "Epoch 82/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0087 - acc: 0.9993 - f1_score: 0.9962 - val_loss: 2.5515 - val_acc: 0.8832 - val_f1_score: 0.0484\n",
      "\n",
      "Epoch 00082: val_f1_score did not improve from 0.19048\n",
      "Epoch 83/300\n",
      "145/145 [==============================] - 5s 38ms/step - loss: 0.0088 - acc: 0.9993 - f1_score: 0.9961 - val_loss: 2.4210 - val_acc: 0.8755 - val_f1_score: 0.0815\n",
      "\n",
      "Epoch 00083: val_f1_score did not improve from 0.19048\n",
      "Epoch 84/300\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.0158 - acc: 0.9986 - f1_score: 0.9925 - val_loss: 2.5553 - val_acc: 0.8938 - val_f1_score: 0.0602\n",
      "\n",
      "Epoch 00084: val_f1_score did not improve from 0.19048\n",
      "Epoch 85/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0127 - acc: 0.9989 - f1_score: 0.9941 - val_loss: 2.6257 - val_acc: 0.8721 - val_f1_score: 0.0383\n",
      "\n",
      "Epoch 00085: val_f1_score did not improve from 0.19048\n",
      "Epoch 86/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0156 - acc: 0.9983 - f1_score: 0.9915 - val_loss: 2.3641 - val_acc: 0.9006 - val_f1_score: 0.0168\n",
      "\n",
      "Epoch 00086: val_f1_score did not improve from 0.19048\n",
      "Epoch 87/300\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 0.0118 - acc: 0.9991 - f1_score: 0.9948 - val_loss: 2.6603 - val_acc: 0.8806 - val_f1_score: 0.0475\n",
      "\n",
      "Epoch 00087: val_f1_score did not improve from 0.19048\n",
      "Epoch 88/300\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.0103 - acc: 0.9991 - f1_score: 0.9951 - val_loss: 2.5447 - val_acc: 0.8908 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00088: val_f1_score did not improve from 0.19048\n",
      "Epoch 89/300\n",
      "145/145 [==============================] - 6s 41ms/step - loss: 0.0084 - acc: 0.9994 - f1_score: 0.9966 - val_loss: 2.5522 - val_acc: 0.8862 - val_f1_score: 0.1067\n",
      "\n",
      "Epoch 00089: val_f1_score did not improve from 0.19048\n",
      "Epoch 90/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0059 - acc: 0.9995 - f1_score: 0.9974 - val_loss: 2.4265 - val_acc: 0.8895 - val_f1_score: 0.1772\n",
      "\n",
      "Epoch 00090: val_f1_score did not improve from 0.19048\n",
      "Epoch 91/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0129 - acc: 0.9991 - f1_score: 0.9947 - val_loss: 2.8169 - val_acc: 0.8760 - val_f1_score: 0.0641\n",
      "\n",
      "Epoch 00091: val_f1_score did not improve from 0.19048\n",
      "Epoch 92/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0094 - acc: 0.9993 - f1_score: 0.9963 - val_loss: 2.6687 - val_acc: 0.8895 - val_f1_score: 0.0511\n",
      "\n",
      "Epoch 00092: val_f1_score did not improve from 0.19048\n",
      "Epoch 93/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0075 - acc: 0.9993 - f1_score: 0.9963 - val_loss: 2.5486 - val_acc: 0.8828 - val_f1_score: 0.0676\n",
      "\n",
      "Epoch 00093: val_f1_score did not improve from 0.19048\n",
      "Epoch 94/300\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 0.0076 - acc: 0.9993 - f1_score: 0.9961 - val_loss: 2.7042 - val_acc: 0.8879 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00094: val_f1_score did not improve from 0.19048\n",
      "Epoch 95/300\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.0140 - acc: 0.9987 - f1_score: 0.9930 - val_loss: 2.5880 - val_acc: 0.8883 - val_f1_score: 0.0436\n",
      "\n",
      "Epoch 00095: val_f1_score did not improve from 0.19048\n",
      "Epoch 96/300\n",
      "145/145 [==============================] - 6s 41ms/step - loss: 0.0123 - acc: 0.9987 - f1_score: 0.9931 - val_loss: 2.4687 - val_acc: 0.8938 - val_f1_score: 0.0157\n",
      "\n",
      "Epoch 00096: val_f1_score did not improve from 0.19048\n",
      "Epoch 97/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0042 - acc: 0.9996 - f1_score: 0.9980 - val_loss: 2.7177 - val_acc: 0.8709 - val_f1_score: 0.0617\n",
      "\n",
      "Epoch 00097: val_f1_score did not improve from 0.19048\n",
      "Epoch 98/300\n",
      "145/145 [==============================] - 6s 44ms/step - loss: 0.0127 - acc: 0.9990 - f1_score: 0.9941 - val_loss: 2.7737 - val_acc: 0.8760 - val_f1_score: 0.0759\n",
      "\n",
      "Epoch 00098: val_f1_score did not improve from 0.19048\n",
      "Epoch 99/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0094 - acc: 0.9991 - f1_score: 0.9953 - val_loss: 2.4961 - val_acc: 0.8929 - val_f1_score: 0.1486\n",
      "\n",
      "Epoch 00099: val_f1_score did not improve from 0.19048\n",
      "Epoch 100/300\n",
      "145/145 [==============================] - 6s 43ms/step - loss: 0.0109 - acc: 0.9991 - f1_score: 0.9953 - val_loss: 2.4533 - val_acc: 0.9095 - val_f1_score: 0.1901\n",
      "\n",
      "Epoch 00100: val_f1_score did not improve from 0.19048\n",
      "Epoch 101/300\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 0.0068 - acc: 0.9995 - f1_score: 0.9972 - val_loss: 2.4818 - val_acc: 0.9006 - val_f1_score: 0.1333\n",
      "\n",
      "Epoch 00101: val_f1_score did not improve from 0.19048\n",
      "Epoch 102/300\n",
      "145/145 [==============================] - 5s 37ms/step - loss: 0.0058 - acc: 0.9995 - f1_score: 0.9974 - val_loss: 2.5867 - val_acc: 0.9019 - val_f1_score: 0.0648\n",
      "\n",
      "Epoch 00102: val_f1_score did not improve from 0.19048\n",
      "Epoch 103/300\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 0.0111 - acc: 0.9990 - f1_score: 0.9944 - val_loss: 2.6643 - val_acc: 0.8883 - val_f1_score: 0.1204\n",
      "\n",
      "Epoch 00103: val_f1_score did not improve from 0.19048\n",
      "Epoch 00103: early stopping\n",
      "(0.1427798810167658, 6.095518e-08)\n",
      "(0.254251012145749, 2.501395e-08)\n",
      "0.4962624898730759\n",
      "1330 (19190,)\n",
      "29260\n",
      "(None, 1, 1) coeff (None, 5, 30) amplitude\n",
      "Epoch 1/300\n",
      "147/147 [==============================] - 15s 54ms/step - loss: 1.2086 - acc: 0.9110 - f1_score: 0.1493 - val_loss: 1.3617 - val_acc: 0.9059 - val_f1_score: 0.2570\n",
      "\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.25698, saving model to ./models/lag_15_iter_0_split_7_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_f1_both.hdf5\n",
      "Epoch 2/300\n",
      "147/147 [==============================] - 6s 43ms/step - loss: 0.5890 - acc: 0.9513 - f1_score: 0.6853 - val_loss: 1.6467 - val_acc: 0.8726 - val_f1_score: 0.0426\n",
      "\n",
      "Epoch 00002: val_f1_score did not improve from 0.25698\n",
      "Epoch 3/300\n",
      "147/147 [==============================] - 6s 43ms/step - loss: 0.3484 - acc: 0.9679 - f1_score: 0.8132 - val_loss: 1.6207 - val_acc: 0.8882 - val_f1_score: 0.2100\n",
      "\n",
      "Epoch 00003: val_f1_score did not improve from 0.25698\n",
      "Epoch 4/300\n",
      "147/147 [==============================] - 6s 38ms/step - loss: 0.2364 - acc: 0.9801 - f1_score: 0.8821 - val_loss: 1.8493 - val_acc: 0.8889 - val_f1_score: 0.0819\n",
      "\n",
      "Epoch 00004: val_f1_score did not improve from 0.25698\n",
      "Epoch 5/300\n",
      "147/147 [==============================] - 5s 37ms/step - loss: 0.1571 - acc: 0.9868 - f1_score: 0.9226 - val_loss: 1.7445 - val_acc: 0.9016 - val_f1_score: 0.1366\n",
      "\n",
      "Epoch 00005: val_f1_score did not improve from 0.25698\n",
      "Epoch 6/300\n",
      "147/147 [==============================] - 6s 41ms/step - loss: 0.1419 - acc: 0.9882 - f1_score: 0.9319 - val_loss: 1.9510 - val_acc: 0.8762 - val_f1_score: 0.0741\n",
      "\n",
      "Epoch 00006: val_f1_score did not improve from 0.25698\n",
      "Epoch 7/300\n",
      "147/147 [==============================] - 6s 43ms/step - loss: 0.1123 - acc: 0.9904 - f1_score: 0.9471 - val_loss: 1.8345 - val_acc: 0.8719 - val_f1_score: 0.3271\n",
      "\n",
      "Epoch 00007: val_f1_score improved from 0.25698 to 0.32714, saving model to ./models/lag_15_iter_0_split_7_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_f1_both.hdf5\n",
      "Epoch 8/300\n",
      "147/147 [==============================] - 6s 41ms/step - loss: 0.1131 - acc: 0.9911 - f1_score: 0.9502 - val_loss: 1.8327 - val_acc: 0.8570 - val_f1_score: 0.2463\n",
      "\n",
      "Epoch 00008: val_f1_score did not improve from 0.32714\n",
      "Epoch 9/300\n",
      "147/147 [==============================] - 5s 37ms/step - loss: 0.0863 - acc: 0.9927 - f1_score: 0.9601 - val_loss: 1.8106 - val_acc: 0.8669 - val_f1_score: 0.1296\n",
      "\n",
      "Epoch 00009: val_f1_score did not improve from 0.32714\n",
      "Epoch 10/300\n",
      "147/147 [==============================] - 6s 38ms/step - loss: 0.0768 - acc: 0.9936 - f1_score: 0.9646 - val_loss: 1.8665 - val_acc: 0.8705 - val_f1_score: 0.1408\n",
      "\n",
      "Epoch 00010: val_f1_score did not improve from 0.32714\n",
      "Epoch 11/300\n",
      "147/147 [==============================] - 6s 42ms/step - loss: 0.0752 - acc: 0.9936 - f1_score: 0.9646 - val_loss: 2.0878 - val_acc: 0.8577 - val_f1_score: 0.0822\n",
      "\n",
      "Epoch 00011: val_f1_score did not improve from 0.32714\n",
      "Epoch 12/300\n",
      "147/147 [==============================] - 6s 43ms/step - loss: 0.0608 - acc: 0.9948 - f1_score: 0.9710 - val_loss: 2.0447 - val_acc: 0.8599 - val_f1_score: 0.1161\n",
      "\n",
      "Epoch 00012: val_f1_score did not improve from 0.32714\n",
      "Epoch 13/300\n",
      "147/147 [==============================] - 6s 39ms/step - loss: 0.0597 - acc: 0.9951 - f1_score: 0.9728 - val_loss: 2.0591 - val_acc: 0.8478 - val_f1_score: 0.1699\n",
      "\n",
      "Epoch 00013: val_f1_score did not improve from 0.32714\n",
      "Epoch 14/300\n",
      "147/147 [==============================] - 5s 37ms/step - loss: 0.0650 - acc: 0.9948 - f1_score: 0.9708 - val_loss: 2.1895 - val_acc: 0.8563 - val_f1_score: 0.0558\n",
      "\n",
      "Epoch 00014: val_f1_score did not improve from 0.32714\n",
      "Epoch 15/300\n",
      "147/147 [==============================] - 6s 41ms/step - loss: 0.0636 - acc: 0.9946 - f1_score: 0.9692 - val_loss: 1.9424 - val_acc: 0.8698 - val_f1_score: 0.1481\n",
      "\n",
      "Epoch 00015: val_f1_score did not improve from 0.32714\n",
      "Epoch 16/300\n",
      "147/147 [==============================] - 6s 43ms/step - loss: 0.0467 - acc: 0.9962 - f1_score: 0.9791 - val_loss: 1.9113 - val_acc: 0.8882 - val_f1_score: 0.1413\n",
      "\n",
      "Epoch 00016: val_f1_score did not improve from 0.32714\n",
      "Epoch 17/300\n",
      "147/147 [==============================] - 6s 44ms/step - loss: 0.0559 - acc: 0.9951 - f1_score: 0.9724 - val_loss: 1.7432 - val_acc: 0.8776 - val_f1_score: 0.2242\n",
      "\n",
      "Epoch 00017: val_f1_score did not improve from 0.32714\n",
      "Epoch 18/300\n",
      "147/147 [==============================] - 6s 43ms/step - loss: 0.0546 - acc: 0.9954 - f1_score: 0.9742 - val_loss: 2.1058 - val_acc: 0.8585 - val_f1_score: 0.1150\n",
      "\n",
      "Epoch 00018: val_f1_score did not improve from 0.32714\n",
      "Epoch 19/300\n",
      "147/147 [==============================] - 6s 43ms/step - loss: 0.0491 - acc: 0.9959 - f1_score: 0.9777 - val_loss: 1.9728 - val_acc: 0.8585 - val_f1_score: 0.1453\n",
      "\n",
      "Epoch 00019: val_f1_score did not improve from 0.32714\n",
      "Epoch 20/300\n",
      "147/147 [==============================] - 6s 43ms/step - loss: 0.0373 - acc: 0.9969 - f1_score: 0.9829 - val_loss: 1.8374 - val_acc: 0.8946 - val_f1_score: 0.2032\n",
      "\n",
      "Epoch 00020: val_f1_score did not improve from 0.32714\n",
      "Epoch 21/300\n",
      "147/147 [==============================] - 6s 38ms/step - loss: 0.0470 - acc: 0.9957 - f1_score: 0.9764 - val_loss: 2.1674 - val_acc: 0.8712 - val_f1_score: 0.0990\n",
      "\n",
      "Epoch 00021: val_f1_score did not improve from 0.32714\n",
      "Epoch 22/300\n",
      "147/147 [==============================] - 5s 37ms/step - loss: 0.0359 - acc: 0.9971 - f1_score: 0.9838 - val_loss: 2.2018 - val_acc: 0.8691 - val_f1_score: 0.1553\n",
      "\n",
      "Epoch 00022: val_f1_score did not improve from 0.32714\n",
      "Epoch 23/300\n",
      "147/147 [==============================] - 6s 41ms/step - loss: 0.0289 - acc: 0.9972 - f1_score: 0.9846 - val_loss: 2.3900 - val_acc: 0.8471 - val_f1_score: 0.0769\n",
      "\n",
      "Epoch 00023: val_f1_score did not improve from 0.32714\n",
      "Epoch 24/300\n",
      "147/147 [==============================] - 6s 44ms/step - loss: 0.0484 - acc: 0.9958 - f1_score: 0.9764 - val_loss: 2.3748 - val_acc: 0.8528 - val_f1_score: 0.0095\n",
      "\n",
      "Epoch 00024: val_f1_score did not improve from 0.32714\n",
      "Epoch 25/300\n",
      "147/147 [==============================] - 6s 44ms/step - loss: 0.0295 - acc: 0.9975 - f1_score: 0.9860 - val_loss: 1.9007 - val_acc: 0.8846 - val_f1_score: 0.2049\n",
      "\n",
      "Epoch 00025: val_f1_score did not improve from 0.32714\n",
      "Epoch 26/300\n",
      "147/147 [==============================] - 6s 39ms/step - loss: 0.0335 - acc: 0.9971 - f1_score: 0.9839 - val_loss: 2.2759 - val_acc: 0.8528 - val_f1_score: 0.1111\n",
      "\n",
      "Epoch 00026: val_f1_score did not improve from 0.32714\n",
      "Epoch 27/300\n",
      "147/147 [==============================] - 5s 36ms/step - loss: 0.0352 - acc: 0.9967 - f1_score: 0.9817 - val_loss: 2.1695 - val_acc: 0.8677 - val_f1_score: 0.1461\n",
      "\n",
      "Epoch 00027: val_f1_score did not improve from 0.32714\n",
      "Epoch 28/300\n",
      "147/147 [==============================] - 6s 39ms/step - loss: 0.0308 - acc: 0.9974 - f1_score: 0.9857 - val_loss: 2.1607 - val_acc: 0.8861 - val_f1_score: 0.1827\n",
      "\n",
      "Epoch 00028: val_f1_score did not improve from 0.32714\n",
      "Epoch 29/300\n",
      "147/147 [==============================] - 6s 41ms/step - loss: 0.0432 - acc: 0.9962 - f1_score: 0.9784 - val_loss: 1.9170 - val_acc: 0.9038 - val_f1_score: 0.2444\n",
      "\n",
      "Epoch 00029: val_f1_score did not improve from 0.32714\n",
      "Epoch 30/300\n",
      "147/147 [==============================] - 6s 38ms/step - loss: 0.0247 - acc: 0.9976 - f1_score: 0.9869 - val_loss: 2.2993 - val_acc: 0.8563 - val_f1_score: 0.1506\n",
      "\n",
      "Epoch 00030: val_f1_score did not improve from 0.32714\n",
      "Epoch 31/300\n",
      "147/147 [==============================] - 5s 37ms/step - loss: 0.0271 - acc: 0.9974 - f1_score: 0.9858 - val_loss: 2.2740 - val_acc: 0.8556 - val_f1_score: 0.1130\n",
      "\n",
      "Epoch 00031: val_f1_score did not improve from 0.32714\n",
      "Epoch 32/300\n",
      "147/147 [==============================] - 6s 40ms/step - loss: 0.0364 - acc: 0.9969 - f1_score: 0.9830 - val_loss: 2.1204 - val_acc: 0.8691 - val_f1_score: 0.1395\n",
      "\n",
      "Epoch 00032: val_f1_score did not improve from 0.32714\n",
      "Epoch 33/300\n",
      "147/147 [==============================] - 6s 44ms/step - loss: 0.0297 - acc: 0.9974 - f1_score: 0.9856 - val_loss: 2.1838 - val_acc: 0.8790 - val_f1_score: 0.1493\n",
      "\n",
      "Epoch 00033: val_f1_score did not improve from 0.32714\n",
      "Epoch 34/300\n",
      "147/147 [==============================] - 6s 43ms/step - loss: 0.0258 - acc: 0.9976 - f1_score: 0.9868 - val_loss: 2.2360 - val_acc: 0.8443 - val_f1_score: 0.1473\n",
      "\n",
      "Epoch 00034: val_f1_score did not improve from 0.32714\n",
      "Epoch 35/300\n",
      "147/147 [==============================] - 6s 43ms/step - loss: 0.0192 - acc: 0.9983 - f1_score: 0.9905 - val_loss: 2.1465 - val_acc: 0.8882 - val_f1_score: 0.2100\n",
      "\n",
      "Epoch 00035: val_f1_score did not improve from 0.32714\n",
      "Epoch 36/300\n",
      "147/147 [==============================] - 6s 44ms/step - loss: 0.0292 - acc: 0.9971 - f1_score: 0.9841 - val_loss: 2.3432 - val_acc: 0.8740 - val_f1_score: 0.1275\n",
      "\n",
      "Epoch 00036: val_f1_score did not improve from 0.32714\n",
      "Epoch 37/300\n",
      "147/147 [==============================] - 6s 43ms/step - loss: 0.0296 - acc: 0.9973 - f1_score: 0.9851 - val_loss: 2.3694 - val_acc: 0.8705 - val_f1_score: 0.1327\n",
      "\n",
      "Epoch 00037: val_f1_score did not improve from 0.32714\n",
      "Epoch 38/300\n",
      "147/147 [==============================] - 6s 43ms/step - loss: 0.0213 - acc: 0.9983 - f1_score: 0.9907 - val_loss: 2.3050 - val_acc: 0.8762 - val_f1_score: 0.1546\n",
      "\n",
      "Epoch 00038: val_f1_score did not improve from 0.32714\n",
      "Epoch 39/300\n",
      "147/147 [==============================] - 6s 42ms/step - loss: 0.0239 - acc: 0.9980 - f1_score: 0.9887 - val_loss: 2.3483 - val_acc: 0.8839 - val_f1_score: 0.1881\n",
      "\n",
      "Epoch 00039: val_f1_score did not improve from 0.32714\n",
      "Epoch 40/300\n",
      "147/147 [==============================] - 6s 43ms/step - loss: 0.0262 - acc: 0.9977 - f1_score: 0.9870 - val_loss: 2.3558 - val_acc: 0.8585 - val_f1_score: 0.1453\n",
      "\n",
      "Epoch 00040: val_f1_score did not improve from 0.32714\n",
      "Epoch 41/300\n",
      "147/147 [==============================] - 6s 44ms/step - loss: 0.0222 - acc: 0.9981 - f1_score: 0.9893 - val_loss: 2.3112 - val_acc: 0.8705 - val_f1_score: 0.1244\n",
      "\n",
      "Epoch 00041: val_f1_score did not improve from 0.32714\n",
      "Epoch 42/300\n",
      "147/147 [==============================] - 6s 43ms/step - loss: 0.0194 - acc: 0.9981 - f1_score: 0.9897 - val_loss: 2.3622 - val_acc: 0.8719 - val_f1_score: 0.1256\n",
      "\n",
      "Epoch 00042: val_f1_score did not improve from 0.32714\n",
      "Epoch 43/300\n",
      "147/147 [==============================] - 6s 43ms/step - loss: 0.0255 - acc: 0.9978 - f1_score: 0.9878 - val_loss: 2.5455 - val_acc: 0.8436 - val_f1_score: 0.1333\n",
      "\n",
      "Epoch 00043: val_f1_score did not improve from 0.32714\n",
      "Epoch 44/300\n",
      "147/147 [==============================] - 6s 39ms/step - loss: 0.0269 - acc: 0.9975 - f1_score: 0.9862 - val_loss: 2.3146 - val_acc: 0.8733 - val_f1_score: 0.1095\n",
      "\n",
      "Epoch 00044: val_f1_score did not improve from 0.32714\n",
      "Epoch 45/300\n",
      "147/147 [==============================] - 5s 37ms/step - loss: 0.0248 - acc: 0.9977 - f1_score: 0.9881 - val_loss: 2.4970 - val_acc: 0.8627 - val_f1_score: 0.1019\n",
      "\n",
      "Epoch 00045: val_f1_score did not improve from 0.32714\n",
      "Epoch 46/300\n",
      "147/147 [==============================] - 6s 40ms/step - loss: 0.0210 - acc: 0.9982 - f1_score: 0.9898 - val_loss: 2.3037 - val_acc: 0.8896 - val_f1_score: 0.1136\n",
      "\n",
      "Epoch 00046: val_f1_score did not improve from 0.32714\n",
      "Epoch 47/300\n",
      "147/147 [==============================] - 6s 43ms/step - loss: 0.0236 - acc: 0.9977 - f1_score: 0.9870 - val_loss: 2.4599 - val_acc: 0.8804 - val_f1_score: 0.1058\n",
      "\n",
      "Epoch 00047: val_f1_score did not improve from 0.32714\n",
      "Epoch 00047: early stopping\n",
      "(0.28350515463917525, 0.00014309029)\n",
      "(0.36220472440944884, 0.00025275067)\n",
      "0.7118472434451477\n",
      "1346 (15375,)\n",
      "29612\n",
      "(None, 1, 1) coeff (None, 5, 30) amplitude\n",
      "Epoch 1/300\n",
      "149/149 [==============================] - 16s 56ms/step - loss: 1.2240 - acc: 0.8991 - f1_score: 0.1413 - val_loss: 1.2542 - val_acc: 0.9294 - val_f1_score: 0.0611\n",
      "\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.06114, saving model to ./models/lag_15_iter_0_split_8_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_f1_both.hdf5\n",
      "Epoch 2/300\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 0.4215 - acc: 0.9637 - f1_score: 0.7851 - val_loss: 1.2414 - val_acc: 0.9438 - val_f1_score: 0.1407\n",
      "\n",
      "Epoch 00002: val_f1_score improved from 0.06114 to 0.14070, saving model to ./models/lag_15_iter_0_split_8_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_f1_both.hdf5\n",
      "Epoch 3/300\n",
      "149/149 [==============================] - 7s 44ms/step - loss: 0.2042 - acc: 0.9820 - f1_score: 0.9000 - val_loss: 1.2662 - val_acc: 0.9429 - val_f1_score: 0.2810\n",
      "\n",
      "Epoch 00003: val_f1_score improved from 0.14070 to 0.28099, saving model to ./models/lag_15_iter_0_split_8_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_f1_both.hdf5\n",
      "Epoch 4/300\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 0.1621 - acc: 0.9851 - f1_score: 0.9180 - val_loss: 1.3475 - val_acc: 0.9448 - val_f1_score: 0.2500\n",
      "\n",
      "Epoch 00004: val_f1_score did not improve from 0.28099\n",
      "Epoch 5/300\n",
      "149/149 [==============================] - 6s 40ms/step - loss: 0.1175 - acc: 0.9899 - f1_score: 0.9447 - val_loss: 1.4462 - val_acc: 0.9343 - val_f1_score: 0.0476\n",
      "\n",
      "Epoch 00005: val_f1_score did not improve from 0.28099\n",
      "Epoch 6/300\n",
      "149/149 [==============================] - 6s 38ms/step - loss: 0.0922 - acc: 0.9918 - f1_score: 0.9551 - val_loss: 1.2768 - val_acc: 0.9504 - val_f1_score: 0.3887\n",
      "\n",
      "Epoch 00006: val_f1_score improved from 0.28099 to 0.38866, saving model to ./models/lag_15_iter_0_split_8_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_f1_both.hdf5\n",
      "Epoch 7/300\n",
      "149/149 [==============================] - 6s 40ms/step - loss: 0.0842 - acc: 0.9930 - f1_score: 0.9607 - val_loss: 1.3679 - val_acc: 0.9415 - val_f1_score: 0.2583\n",
      "\n",
      "Epoch 00007: val_f1_score did not improve from 0.38866\n",
      "Epoch 8/300\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 0.0874 - acc: 0.9922 - f1_score: 0.9555 - val_loss: 1.3462 - val_acc: 0.9498 - val_f1_score: 0.3014\n",
      "\n",
      "Epoch 00008: val_f1_score did not improve from 0.38866\n",
      "Epoch 9/300\n",
      "149/149 [==============================] - 6s 44ms/step - loss: 0.0755 - acc: 0.9937 - f1_score: 0.9650 - val_loss: 1.3229 - val_acc: 0.9379 - val_f1_score: 0.2646\n",
      "\n",
      "Epoch 00009: val_f1_score did not improve from 0.38866\n",
      "Epoch 10/300\n",
      "149/149 [==============================] - 7s 44ms/step - loss: 0.0654 - acc: 0.9942 - f1_score: 0.9678 - val_loss: 1.2714 - val_acc: 0.9524 - val_f1_score: 0.3933\n",
      "\n",
      "Epoch 00010: val_f1_score improved from 0.38866 to 0.39331, saving model to ./models/lag_15_iter_0_split_8_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_f1_both.hdf5\n",
      "Epoch 11/300\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 0.0607 - acc: 0.9945 - f1_score: 0.9702 - val_loss: 1.5161 - val_acc: 0.9245 - val_f1_score: 0.1786\n",
      "\n",
      "Epoch 00011: val_f1_score did not improve from 0.39331\n",
      "Epoch 12/300\n",
      "149/149 [==============================] - 6s 39ms/step - loss: 0.0583 - acc: 0.9947 - f1_score: 0.9710 - val_loss: 1.2518 - val_acc: 0.9632 - val_f1_score: 0.4286\n",
      "\n",
      "Epoch 00012: val_f1_score improved from 0.39331 to 0.42857, saving model to ./models/lag_15_iter_0_split_8_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_f1_both.hdf5\n",
      "Epoch 13/300\n",
      "149/149 [==============================] - 6s 37ms/step - loss: 0.0557 - acc: 0.9950 - f1_score: 0.9718 - val_loss: 1.4228 - val_acc: 0.9442 - val_f1_score: 0.2411\n",
      "\n",
      "Epoch 00013: val_f1_score did not improve from 0.42857\n",
      "Epoch 14/300\n",
      "149/149 [==============================] - 6s 41ms/step - loss: 0.0467 - acc: 0.9959 - f1_score: 0.9779 - val_loss: 1.4612 - val_acc: 0.9356 - val_f1_score: 0.2519\n",
      "\n",
      "Epoch 00014: val_f1_score did not improve from 0.42857\n",
      "Epoch 15/300\n",
      "149/149 [==============================] - 7s 44ms/step - loss: 0.0443 - acc: 0.9962 - f1_score: 0.9792 - val_loss: 1.5349 - val_acc: 0.9225 - val_f1_score: 0.0709\n",
      "\n",
      "Epoch 00015: val_f1_score did not improve from 0.42857\n",
      "Epoch 16/300\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 0.0405 - acc: 0.9961 - f1_score: 0.9785 - val_loss: 1.3661 - val_acc: 0.9537 - val_f1_score: 0.2769\n",
      "\n",
      "Epoch 00016: val_f1_score did not improve from 0.42857\n",
      "Epoch 17/300\n",
      "149/149 [==============================] - 6s 38ms/step - loss: 0.0384 - acc: 0.9964 - f1_score: 0.9806 - val_loss: 1.5740 - val_acc: 0.9320 - val_f1_score: 0.1882\n",
      "\n",
      "Epoch 00017: val_f1_score did not improve from 0.42857\n",
      "Epoch 18/300\n",
      "149/149 [==============================] - 6s 38ms/step - loss: 0.0415 - acc: 0.9959 - f1_score: 0.9775 - val_loss: 1.5945 - val_acc: 0.9268 - val_f1_score: 0.1585\n",
      "\n",
      "Epoch 00018: val_f1_score did not improve from 0.42857\n",
      "Epoch 19/300\n",
      "149/149 [==============================] - 6s 42ms/step - loss: 0.0499 - acc: 0.9954 - f1_score: 0.9745 - val_loss: 1.4940 - val_acc: 0.9478 - val_f1_score: 0.2167\n",
      "\n",
      "Epoch 00019: val_f1_score did not improve from 0.42857\n",
      "Epoch 20/300\n",
      "149/149 [==============================] - 6s 38ms/step - loss: 0.0357 - acc: 0.9966 - f1_score: 0.9810 - val_loss: 1.5927 - val_acc: 0.9406 - val_f1_score: 0.1659\n",
      "\n",
      "Epoch 00020: val_f1_score did not improve from 0.42857\n",
      "Epoch 21/300\n",
      "149/149 [==============================] - 5s 36ms/step - loss: 0.0322 - acc: 0.9970 - f1_score: 0.9835 - val_loss: 1.4442 - val_acc: 0.9586 - val_f1_score: 0.2317\n",
      "\n",
      "Epoch 00021: val_f1_score did not improve from 0.42857\n",
      "Epoch 22/300\n",
      "149/149 [==============================] - 6s 42ms/step - loss: 0.0342 - acc: 0.9968 - f1_score: 0.9820 - val_loss: 1.4510 - val_acc: 0.9544 - val_f1_score: 0.2147\n",
      "\n",
      "Epoch 00022: val_f1_score did not improve from 0.42857\n",
      "Epoch 23/300\n",
      "149/149 [==============================] - 6s 41ms/step - loss: 0.0371 - acc: 0.9965 - f1_score: 0.9809 - val_loss: 1.5920 - val_acc: 0.9376 - val_f1_score: 0.1667\n",
      "\n",
      "Epoch 00023: val_f1_score did not improve from 0.42857\n",
      "Epoch 24/300\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 0.0387 - acc: 0.9966 - f1_score: 0.9813 - val_loss: 1.4499 - val_acc: 0.9455 - val_f1_score: 0.2523\n",
      "\n",
      "Epoch 00024: val_f1_score did not improve from 0.42857\n",
      "Epoch 25/300\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 0.0295 - acc: 0.9970 - f1_score: 0.9835 - val_loss: 1.5065 - val_acc: 0.9406 - val_f1_score: 0.1956\n",
      "\n",
      "Epoch 00025: val_f1_score did not improve from 0.42857\n",
      "Epoch 26/300\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 0.0311 - acc: 0.9972 - f1_score: 0.9849 - val_loss: 1.5850 - val_acc: 0.9419 - val_f1_score: 0.0535\n",
      "\n",
      "Epoch 00026: val_f1_score did not improve from 0.42857\n",
      "Epoch 27/300\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 0.0296 - acc: 0.9973 - f1_score: 0.9855 - val_loss: 1.7741 - val_acc: 0.9202 - val_f1_score: 0.0162\n",
      "\n",
      "Epoch 00027: val_f1_score did not improve from 0.42857\n",
      "Epoch 28/300\n",
      "149/149 [==============================] - 7s 44ms/step - loss: 0.0247 - acc: 0.9979 - f1_score: 0.9886 - val_loss: 1.5947 - val_acc: 0.9406 - val_f1_score: 0.1581\n",
      "\n",
      "Epoch 00028: val_f1_score did not improve from 0.42857\n",
      "Epoch 29/300\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 0.0291 - acc: 0.9975 - f1_score: 0.9862 - val_loss: 1.5378 - val_acc: 0.9425 - val_f1_score: 0.2553\n",
      "\n",
      "Epoch 00029: val_f1_score did not improve from 0.42857\n",
      "Epoch 30/300\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 0.0258 - acc: 0.9976 - f1_score: 0.9872 - val_loss: 1.5596 - val_acc: 0.9432 - val_f1_score: 0.1643\n",
      "\n",
      "Epoch 00030: val_f1_score did not improve from 0.42857\n",
      "Epoch 31/300\n",
      "149/149 [==============================] - 7s 44ms/step - loss: 0.0278 - acc: 0.9978 - f1_score: 0.9877 - val_loss: 1.5983 - val_acc: 0.9386 - val_f1_score: 0.1689\n",
      "\n",
      "Epoch 00031: val_f1_score did not improve from 0.42857\n",
      "Epoch 32/300\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 0.0274 - acc: 0.9974 - f1_score: 0.9860 - val_loss: 1.6281 - val_acc: 0.9320 - val_f1_score: 0.0961\n",
      "\n",
      "Epoch 00032: val_f1_score did not improve from 0.42857\n",
      "Epoch 33/300\n",
      "149/149 [==============================] - 6s 44ms/step - loss: 0.0263 - acc: 0.9978 - f1_score: 0.9882 - val_loss: 1.6785 - val_acc: 0.9392 - val_f1_score: 0.0513\n",
      "\n",
      "Epoch 00033: val_f1_score did not improve from 0.42857\n",
      "Epoch 34/300\n",
      "149/149 [==============================] - 7s 44ms/step - loss: 0.0263 - acc: 0.9975 - f1_score: 0.9866 - val_loss: 2.0812 - val_acc: 0.8883 - val_f1_score: 0.0503\n",
      "\n",
      "Epoch 00034: val_f1_score did not improve from 0.42857\n",
      "Epoch 35/300\n",
      "149/149 [==============================] - 7s 44ms/step - loss: 0.0257 - acc: 0.9975 - f1_score: 0.9865 - val_loss: 1.8396 - val_acc: 0.9209 - val_f1_score: 0.0474\n",
      "\n",
      "Epoch 00035: val_f1_score did not improve from 0.42857\n",
      "Epoch 36/300\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 0.0181 - acc: 0.9986 - f1_score: 0.9922 - val_loss: 1.9033 - val_acc: 0.9192 - val_f1_score: 0.0315\n",
      "\n",
      "Epoch 00036: val_f1_score did not improve from 0.42857\n",
      "Epoch 37/300\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 0.0227 - acc: 0.9977 - f1_score: 0.9876 - val_loss: 1.7992 - val_acc: 0.9278 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00037: val_f1_score did not improve from 0.42857\n",
      "Epoch 38/300\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 0.0206 - acc: 0.9980 - f1_score: 0.9888 - val_loss: 1.8415 - val_acc: 0.9251 - val_f1_score: 0.0500\n",
      "\n",
      "Epoch 00038: val_f1_score did not improve from 0.42857\n",
      "Epoch 39/300\n",
      "149/149 [==============================] - 6s 42ms/step - loss: 0.0215 - acc: 0.9980 - f1_score: 0.9888 - val_loss: 1.5415 - val_acc: 0.9415 - val_f1_score: 0.2645\n",
      "\n",
      "Epoch 00039: val_f1_score did not improve from 0.42857\n",
      "Epoch 40/300\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 0.0234 - acc: 0.9978 - f1_score: 0.9880 - val_loss: 1.7048 - val_acc: 0.9314 - val_f1_score: 0.1469\n",
      "\n",
      "Epoch 00040: val_f1_score did not improve from 0.42857\n",
      "Epoch 41/300\n",
      "149/149 [==============================] - 6s 44ms/step - loss: 0.0206 - acc: 0.9982 - f1_score: 0.9899 - val_loss: 1.7565 - val_acc: 0.9333 - val_f1_score: 0.1057\n",
      "\n",
      "Epoch 00041: val_f1_score did not improve from 0.42857\n",
      "Epoch 42/300\n",
      "149/149 [==============================] - 7s 44ms/step - loss: 0.0218 - acc: 0.9979 - f1_score: 0.9879 - val_loss: 1.6742 - val_acc: 0.9419 - val_f1_score: 0.0635\n",
      "\n",
      "Epoch 00042: val_f1_score did not improve from 0.42857\n",
      "Epoch 43/300\n",
      "149/149 [==============================] - 7s 44ms/step - loss: 0.0186 - acc: 0.9983 - f1_score: 0.9908 - val_loss: 1.7093 - val_acc: 0.9432 - val_f1_score: 0.0335\n",
      "\n",
      "Epoch 00043: val_f1_score did not improve from 0.42857\n",
      "Epoch 44/300\n",
      "149/149 [==============================] - 7s 44ms/step - loss: 0.0208 - acc: 0.9982 - f1_score: 0.9904 - val_loss: 1.7951 - val_acc: 0.9379 - val_f1_score: 0.0406\n",
      "\n",
      "Epoch 00044: val_f1_score did not improve from 0.42857\n",
      "Epoch 45/300\n",
      "149/149 [==============================] - 7s 44ms/step - loss: 0.0194 - acc: 0.9983 - f1_score: 0.9908 - val_loss: 1.6823 - val_acc: 0.9491 - val_f1_score: 0.0828\n",
      "\n",
      "Epoch 00045: val_f1_score did not improve from 0.42857\n",
      "Epoch 46/300\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 0.0219 - acc: 0.9981 - f1_score: 0.9894 - val_loss: 1.8551 - val_acc: 0.9189 - val_f1_score: 0.0536\n",
      "\n",
      "Epoch 00046: val_f1_score did not improve from 0.42857\n",
      "Epoch 47/300\n",
      "149/149 [==============================] - 7s 44ms/step - loss: 0.0151 - acc: 0.9987 - f1_score: 0.9928 - val_loss: 1.6958 - val_acc: 0.9399 - val_f1_score: 0.2407\n",
      "\n",
      "Epoch 00047: val_f1_score did not improve from 0.42857\n",
      "Epoch 48/300\n",
      "149/149 [==============================] - 6s 44ms/step - loss: 0.0178 - acc: 0.9983 - f1_score: 0.9910 - val_loss: 1.9518 - val_acc: 0.9218 - val_f1_score: 0.1185\n",
      "\n",
      "Epoch 00048: val_f1_score did not improve from 0.42857\n",
      "Epoch 49/300\n",
      "149/149 [==============================] - 7s 44ms/step - loss: 0.0193 - acc: 0.9982 - f1_score: 0.9902 - val_loss: 1.8343 - val_acc: 0.9304 - val_f1_score: 0.0450\n",
      "\n",
      "Epoch 00049: val_f1_score did not improve from 0.42857\n",
      "Epoch 50/300\n",
      "149/149 [==============================] - 7s 44ms/step - loss: 0.0124 - acc: 0.9989 - f1_score: 0.9937 - val_loss: 1.8915 - val_acc: 0.9264 - val_f1_score: 0.1181\n",
      "\n",
      "Epoch 00050: val_f1_score did not improve from 0.42857\n",
      "Epoch 51/300\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 0.0154 - acc: 0.9986 - f1_score: 0.9922 - val_loss: 1.8368 - val_acc: 0.9383 - val_f1_score: 0.0600\n",
      "\n",
      "Epoch 00051: val_f1_score did not improve from 0.42857\n",
      "Epoch 52/300\n",
      "149/149 [==============================] - 7s 44ms/step - loss: 0.0139 - acc: 0.9987 - f1_score: 0.9928 - val_loss: 1.9734 - val_acc: 0.9209 - val_f1_score: 0.0163\n",
      "\n",
      "Epoch 00052: val_f1_score did not improve from 0.42857\n",
      "Epoch 00052: early stopping\n",
      "(0.10603448275862068, 4.9780747e-06)\n",
      "(0.13232323232323231, 8.800732e-06)\n",
      "0.6536445552147241\n",
      "1313 (15072,)\n",
      "28886\n",
      "(None, 1, 1) coeff (None, 5, 30) amplitude\n",
      "Epoch 1/300\n",
      "145/145 [==============================] - ETA: 0s - loss: 1.2643 - acc: 0.9019 - f1_score: 0.0857"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "use_standardization = True\n",
    "n_lag = 15\n",
    "n_groups = 10\n",
    "X_feature,X_static,X_stress_episode,X_quit_episode,X_activity_episode,X_smoking_episode,y_time,y,groups = get_X_y_groups(n_lag)\n",
    "y[y<0] = 0\n",
    "y = np.float32(y)\n",
    "indexes = get_train_test_indexes(groups,n_groups_split = n_groups,n_val_groups=5)\n",
    "final_y_time = []\n",
    "final_probs = []\n",
    "final_y = []\n",
    "final_groups = []\n",
    "bias_dict = {}\n",
    "val_results = {}\n",
    "for kk,yyyy in enumerate(indexes):\n",
    "    train_index,test_index,val_index = yyyy\n",
    "    \n",
    "    X_feature_train,X_feature_test = X_feature[train_index],X_feature[test_index]\n",
    "    X_static_train,X_static_test = X_static[train_index],X_static[test_index]\n",
    "    X_stress_episode_train,X_stress_episode_test = X_stress_episode[train_index], X_stress_episode[test_index]\n",
    "    X_quit_episode_train,X_quit_episode_test = X_quit_episode[train_index], X_quit_episode[test_index]\n",
    "    X_activity_episode_train,X_activity_episode_test = X_activity_episode[train_index], X_activity_episode[test_index]\n",
    "    X_smoking_episode_train,X_smoking_episode_test = X_smoking_episode[train_index], X_smoking_episode[test_index]\n",
    "    y_train,y_test,groups_train,groups_test,time_train,time_test = y[train_index],y[test_index],groups[train_index],groups[test_index],y_time[train_index],y_time[test_index]\n",
    "    \n",
    "    X_feature_val,X_static_val,X_stress_episode_val,X_quit_episode_val,\\\n",
    "    X_activity_episode_val,X_smoking_episode_val,y_val,groups_val,time_val = X_feature[val_index],X_static[val_index],X_stress_episode[val_index],X_quit_episode[val_index],\\\n",
    "                                                                            X_activity_episode[val_index],X_smoking_episode[val_index],y[val_index],groups[val_index],y_time[val_index]\n",
    "    \n",
    "    positive_train_index = np.where(y_train==1)[0]\n",
    "    negative_train_index = np.where(y_train==0)[0]\n",
    "    \n",
    "    len_positive = len(positive_train_index)\n",
    "    print(len_positive,y_train.shape)\n",
    "    n_iters = 0\n",
    "    test_preds = []\n",
    "    bias_pred = []\n",
    "    # for i,n_iter in enumerate(range(n_iters)):\n",
    "    #     np.random.seed(np.random.randint(109))\n",
    "    indexes_sampled = np.array(list(positive_train_index)*2+list(np.random.choice(negative_train_index,len_positive*20)))\n",
    "    print(len(indexes_sampled))\n",
    "    np.random.shuffle(indexes_sampled)\n",
    "    train_feature = X_feature_train[indexes_sampled]\n",
    "    train_static = X_static_train[indexes_sampled]\n",
    "    train_stress = X_stress_episode_train[indexes_sampled]\n",
    "    train_quit = X_quit_episode_train[indexes_sampled]\n",
    "    train_activity = X_activity_episode_train[indexes_sampled]\n",
    "    train_smoking = X_smoking_episode_train[indexes_sampled]\n",
    "    train_y = y_train[indexes_sampled]\n",
    "    model = get_model()\n",
    "#         model.summary()\n",
    "    filepath = './models/lag_'+str(n_lag)+'_iter_'+str(n_iters)+'_split_'+str(kk)+'_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_f1_both.hdf5'\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_f1_score', verbose=1, save_best_only=True, mode='max',save_weights_only=False)\n",
    "    es = EarlyStopping(monitor='val_f1_score', mode='max', verbose=1,patience=40)\n",
    "    callbacks_list = [es,checkpoint]\n",
    "    # train_feature,val_feature,train_static,val_static,train_stress,val_stress, \\\n",
    "    # train_smoking,val_smoking,train_quit,val_quit,train_activity,val_activity, \\\n",
    "    # train_y,val_y = train_test_split(train_feature,\n",
    "    #                                     train_static,\n",
    "    #                                     train_stress,\n",
    "    #                                     train_smoking,\n",
    "    #                                     train_quit,\n",
    "    #                                     train_activity,\n",
    "    #                                     train_y,\n",
    "    #                                     test_size=.2,stratify=train_y)\n",
    "    model.fit([train_feature,train_static,train_stress,train_activity,train_smoking,train_quit],train_y,\n",
    "        validation_data=([X_feature_val,X_static_val,X_stress_episode_val,X_activity_episode_val,\n",
    "                                        X_smoking_episode_val,X_quit_episode_val],y_val), epochs=300, batch_size=200,\n",
    "                verbose=1,callbacks=callbacks_list,shuffle=True)\n",
    "    model.load_weights(filepath)\n",
    "    test_preds.append(model.predict([X_feature_test,X_static_test,X_stress_episode_test,\n",
    "                                    X_activity_episode_test,X_smoking_episode_test,X_quit_episode_test]))\n",
    "    bias_pred.append(model.predict([X_feature_val,X_static_val,X_stress_episode_val,X_activity_episode_val,\n",
    "                                    X_smoking_episode_val,X_quit_episode_val]))\n",
    "        \n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    y_test_pred = np.concatenate([MinMaxScaler().fit_transform(a.reshape(-1,1)) for a in test_preds],axis=1).mean(axis=1)\n",
    "    bias_pred = np.concatenate([MinMaxScaler().fit_transform(a.reshape(-1,1)) for a in bias_pred],axis=1).mean(axis=1)\n",
    "    print(f1Bias_scorer_CV(bias_pred,y_val))\n",
    "    print(f1Bias_scorer_CV(y_test_pred,y_test))\n",
    "    print(roc_auc_score(y_test,y_test_pred))\n",
    "    final_y_time.extend(list(time_test))\n",
    "    final_probs.extend(list(y_test_pred))\n",
    "    final_y.extend(list(y_test))\n",
    "    final_groups.extend(list(groups_test))\n",
    "    for group_b in np.unique(groups_test):\n",
    "        bias_dict[group_b] = kk\n",
    "    val_results[kk] = [time_val,bias_pred,y_val,groups_val]\n",
    "#     print(len(np.unique(final_groups)))\n",
    "#     print(bias_dict)\n",
    "final_y_time,final_probs,final_y,final_groups = np.array(final_y_time),np.array(final_probs),np.array(final_y),np.array(final_groups)\n",
    "pickle.dump([final_y_time,final_probs,final_y,final_groups,bias_dict,val_results],open('./data/output/episode_encoded_lag_'+str(n_lag)+'_episode_model_v9_new_validation_set_no_smoking_sparse_cross_entropy_f1_both.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights(filepath)\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Model(model.input,model.get_layer('dense_552').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.predict([X_feature_test,X_static_test,X_stress_episode_test,\n",
    "                                       X_activity_episode_test,X_smoking_episode_test,X_quit_episode_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_static_test[0],X_static_test[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = './models/episode_model.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, mode='min',save_weights_only=False)\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=0,patience=40)\n",
    "callbacks_list = [es,checkpoint]\n",
    "train_feature,val_feature,train_static,val_static,train_stress,val_stress, \\\n",
    "train_smoking,val_smoking,train_quit,val_quit,train_activity,val_activity, \\\n",
    "train_y,val_y = train_test_split(train_feature,\n",
    "                                 train_static,\n",
    "                                 train_stress,\n",
    "                                 train_smoking,\n",
    "                                 train_quit,\n",
    "                                 train_activity,\n",
    "                                 train_y,\n",
    "                                 test_size=.1,stratify=train_y)\n",
    "# train_y = tf.cast(train_y, tf.float32)\n",
    "# train_x = tf.cast(train_x, tf.float32)\n",
    "# val_y = tf.cast(val_y, tf.float32)\n",
    "# val_x = tf.cast(val_x, tf.float32)\n",
    "# history = model.fit(train_x,train_y,validation_data=(val_x,val_y), epochs=200, batch_size=30,\n",
    "#                     verbose=0,callbacks=callbacks_list,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit([train_feature,train_static,train_stress,train_activity,train_smoking,train_quit],train_y,\n",
    "          validation_data=([val_feature,val_static,val_stress,val_activity,val_smoking,val_quit],val_y), epochs=200, batch_size=30,\n",
    "                    verbose=1,callbacks=callbacks_list,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,\n",
    "               np.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(final_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "filepath = './models/'+'-'.join([str(n_lag),str(n_groups)])+'-'+str(uuid.uuid4())+'.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min',save_weights_only=False)\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=0,patience=40)\n",
    "callbacks_list = [es,checkpoint]\n",
    "train_x,val_x,train_y,val_y = train_test_split(X_train,y_train,test_size=.2,stratify=y_train)\n",
    "history = model.fit(train_x,train_y,validation_data=(val_x,val_y), epochs=100, batch_size=100,verbose=1,callbacks=callbacks_list,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc,roc_auc_score,f1_score\n",
    "roc_auc_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.Variable(np.arange(10)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "51b244ab9aca612e739a0539ae1af887c58db9e180d786deb0ab1761def69c1f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('test1': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
